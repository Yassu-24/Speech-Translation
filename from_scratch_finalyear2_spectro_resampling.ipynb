{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vblhh9zwb19Q",
        "outputId": "2986c998-0d88-4296-a17d-79774b31b34e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 35184, done.\u001b[K\n",
            "remote: Counting objects: 100% (105/105), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 35184 (delta 61), reused 72 (delta 47), pack-reused 35079\u001b[K\n",
            "Receiving objects: 100% (35184/35184), 25.22 MiB | 20.08 MiB/s, done.\n",
            "Resolving deltas: 100% (25548/25548), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/pytorch/fairseq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlaUVwgWJ8iz",
        "outputId": "18fbe49e-384f-4e36-ac1e-2d0ae2c24228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxeSYwoIiDK4",
        "outputId": "14b78e9f-9b36-4393-f909-6a55459f2012"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (3.0.10)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq==0.12.2)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq==0.12.2)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: numpy>=1.21.3 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.25.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2023.12.25)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq==0.12.2)\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (4.66.2)\n",
            "Collecting bitarray (from fairseq==0.12.2)\n",
            "  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2.2.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (24.0)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq==0.12.2)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (4.11.0)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq==0.12.2)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq==0.12.2)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (4.9.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq==0.12.2) (2.22)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->fairseq==0.12.2) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->fairseq==0.12.2) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building editable for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-0.editable-cp310-cp310-linux_x86_64.whl size=9394 sha256=b375a8201e67b8061f359335bb2c44ccde958e8511459234e6c42e1762f0fc95\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t4b1kb06/wheels/c6/d7/db/bc419b1daa8266aa8de2a7c4d29f62dbfa814e8701fe4695a2\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=3f4bd19dfbb64aaa6e80c60ad7dea975157b05645ce02443e3eff59b08e8278a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, colorama, sacrebleu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, nvidia-cusolver-cu12, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.9.2 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 omegaconf-2.0.6 portalocker-2.8.2 sacrebleu-2.4.2\n"
          ]
        }
      ],
      "source": [
        "!cd /content/fairseq && pip install --editable ./"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/TGT_AUDIO.zip /content/TGT_AUDIO\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mSvrUAf-cYJ",
        "outputId": "23c728de-3a62-46d2-8b49-06ded5163b99"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/TGT_AUDIO/ (stored 0%)\n",
            "  adding: content/TGT_AUDIO/train/ (stored 0%)\n",
            "  adding: content/TGT_AUDIO/train/1436.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/682.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/236.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/1102.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/1260.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/1381.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/train/482.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/500.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/train/887.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/1198.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/1090.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/985.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/524.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/10.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/48.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/1489.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/473.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/273.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/445.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/1113.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/1452.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/89.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/363.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/770.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/765.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/431.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/915.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/20.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/train/1192.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1039.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/1295.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/73.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/1121.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/88.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/1434.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/1128.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/1327.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/1361.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/300.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/train/878.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/1042.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/6.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/531.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/895.wav (deflated 34%)\n",
            "  adding: content/TGT_AUDIO/train/1214.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/191.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1089.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/611.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/547.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/1500.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/749.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/913.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/1388.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/261.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/train/876.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/714.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/17.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/758.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/192.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/819.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/516.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/885.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/308.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/150.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1170.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/294.wav (deflated 47%)\n",
            "  adding: content/TGT_AUDIO/train/1075.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/857.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/305.wav (deflated 43%)\n",
            "  adding: content/TGT_AUDIO/train/476.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/961.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/1156.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/1185.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/952.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/227.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/851.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/35.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/1277.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/8.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/1486.wav (deflated 36%)\n",
            "  adding: content/TGT_AUDIO/train/902.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/272.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/1438.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/183.wav (deflated 41%)\n",
            "  adding: content/TGT_AUDIO/train/1082.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/1326.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/448.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/409.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/1023.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/1496.wav (deflated 33%)\n",
            "  adding: content/TGT_AUDIO/train/529.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/676.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/145.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/1160.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/210.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/1071.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/223.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/327.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/31.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/716.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/585.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/1183.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/1205.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/148.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/379.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/1017.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/86.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/466.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/1318.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/1357.wav (deflated 43%)\n",
            "  adding: content/TGT_AUDIO/train/212.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/372.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/204.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/894.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/train/1447.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/871.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/1484.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/train/1029.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/557.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/252.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/396.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/441.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/674.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/560.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/742.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/1368.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/23.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/734.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/156.wav (deflated 36%)\n",
            "  adding: content/TGT_AUDIO/train/630.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/427.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/337.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/270.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/1161.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/897.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/234.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/train/9.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/186.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1424.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/741.wav (deflated 41%)\n",
            "  adding: content/TGT_AUDIO/train/167.wav (deflated 41%)\n",
            "  adding: content/TGT_AUDIO/train/1210.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/502.wav (deflated 47%)\n",
            "  adding: content/TGT_AUDIO/train/1316.wav (deflated 43%)\n",
            "  adding: content/TGT_AUDIO/train/370.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/1324.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/1460.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/87.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/542.wav (deflated 35%)\n",
            "  adding: content/TGT_AUDIO/train/954.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/436.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/1450.wav (deflated 46%)\n",
            "  adding: content/TGT_AUDIO/train/214.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/561.wav (deflated 35%)\n",
            "  adding: content/TGT_AUDIO/train/504.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/train/442.wav (deflated 37%)\n",
            "  adding: content/TGT_AUDIO/train/1506.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/1091.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/492.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/1093.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/695.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/1343.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/66.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/794.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/39.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/364.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/193.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/944.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/train/14.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/805.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/45.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1366.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/75.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/1465.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/train/345.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/1016.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/369.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/1427.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/249.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/980.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/921.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/614.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/195.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/956.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/340.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/981.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/330.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/505.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/747.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/998.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/1046.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/583.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/559.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/901.wav (deflated 41%)\n",
            "  adding: content/TGT_AUDIO/train/527.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/1152.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/1173.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/226.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/1299.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/1190.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/1225.wav (deflated 33%)\n",
            "  adding: content/TGT_AUDIO/train/818.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/405.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/train/864.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/578.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/64.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/1208.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/757.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/172.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/574.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/36.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/721.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/835.wav (deflated 34%)\n",
            "  adding: content/TGT_AUDIO/train/1245.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1037.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/1268.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/1044.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/1120.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/638.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/519.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/1253.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/1031.wav (deflated 37%)\n",
            "  adding: content/TGT_AUDIO/train/153.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/518.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/995.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/596.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/629.wav (deflated 42%)\n",
            "  adding: content/TGT_AUDIO/train/317.wav (deflated 42%)\n",
            "  adding: content/TGT_AUDIO/train/1008.wav (deflated 43%)\n",
            "  adding: content/TGT_AUDIO/train/1045.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/1317.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/401.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/877.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/592.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/1035.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/1414.wav (deflated 35%)\n",
            "  adding: content/TGT_AUDIO/train/1050.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/1278.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/299.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/1422.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/696.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/train/1138.wav (deflated 44%)\n",
            "  adding: content/TGT_AUDIO/train/994.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/532.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1222.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/77.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/1216.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/3.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/700.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/490.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/1407.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/173.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1033.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/94.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/244.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/train/977.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/train/118.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/603.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/838.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/925.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/862.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/589.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1231.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/257.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/1378.wav (deflated 34%)\n",
            "  adding: content/TGT_AUDIO/train/631.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/339.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/810.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/40.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/342.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/1467.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/1498.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/668.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/478.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/771.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/694.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/38.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/957.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/159.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/1263.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/775.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/335.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/train/71.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/426.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/22.wav (deflated 49%)\n",
            "  adding: content/TGT_AUDIO/train/293.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/790.wav (deflated 36%)\n",
            "  adding: content/TGT_AUDIO/train/464.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/216.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/1367.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/1404.wav (deflated 41%)\n",
            "  adding: content/TGT_AUDIO/train/709.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/1207.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/517.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/1389.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/1251.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/731.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/1330.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/351.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/908.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/21.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/1400.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/1105.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/train/1000.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/522.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/1283.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/196.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/683.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/680.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/377.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/768.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/319.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/712.wav (deflated 34%)\n",
            "  adding: content/TGT_AUDIO/train/1155.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/1132.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/665.wav (deflated 46%)\n",
            "  adding: content/TGT_AUDIO/train/1118.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/972.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/95.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/1202.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/858.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/49.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/608.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/13.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/1028.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/1420.wav (deflated 5%)\n",
            "  adding: content/TGT_AUDIO/train/108.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/1040.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/718.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/149.wav (deflated 37%)\n",
            "  adding: content/TGT_AUDIO/train/434.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/1471.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/99.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/180.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/1227.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/277.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/618.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/train/717.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/607.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/850.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/1303.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/162.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/287.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/301.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/927.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/691.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/train/302.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/1337.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/129.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1127.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/982.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/671.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/160.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/400.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/1176.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/144.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/90.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/623.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/480.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1281.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/646.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/699.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/1304.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/633.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/101.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/769.wav (deflated 37%)\n",
            "  adding: content/TGT_AUDIO/train/1490.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1267.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/1049.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/train/571.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/1175.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/255.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/1504.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/1466.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/1115.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/1431.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/551.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/1384.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/1435.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/1181.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/1285.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/238.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/train/681.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/816.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/423.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/774.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/30.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/1094.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/465.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/429.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/730.wav (deflated 41%)\n",
            "  adding: content/TGT_AUDIO/train/720.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/1353.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/1126.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/1224.wav (deflated 42%)\n",
            "  adding: content/TGT_AUDIO/train/1364.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/384.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/362.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/903.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/556.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1200.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/856.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/708.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/train/1097.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/205.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1290.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1398.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/508.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/413.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/96.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/847.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/134.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/52.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/290.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/536.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/130.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/243.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/312.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/462.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/19.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/999.wav (deflated 49%)\n",
            "  adding: content/TGT_AUDIO/train/760.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/526.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/267.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/2.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/1112.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/11.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/565.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/4.wav (deflated 54%)\n",
            "  adding: content/TGT_AUDIO/train/1459.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/120.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/train/1166.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/326.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/511.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/588.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/635.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/262.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/456.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/331.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/643.wav (deflated 36%)\n",
            "  adding: content/TGT_AUDIO/train/1464.wav (deflated 45%)\n",
            "  adding: content/TGT_AUDIO/train/468.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/train/137.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/1018.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/451.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/822.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/855.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/1131.wav (deflated 49%)\n",
            "  adding: content/TGT_AUDIO/train/530.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/755.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/800.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/663.wav (deflated 35%)\n",
            "  adding: content/TGT_AUDIO/train/679.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/1153.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/484.wav (deflated 35%)\n",
            "  adding: content/TGT_AUDIO/train/1116.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/1433.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/85.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/307.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/260.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/948.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/854.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/647.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/1463.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/182.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/597.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/634.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/114.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/1136.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/train/54.wav (deflated 41%)\n",
            "  adding: content/TGT_AUDIO/train/1243.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/284.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/194.wav (deflated 33%)\n",
            "  adding: content/TGT_AUDIO/train/1382.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/56.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/562.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/1262.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/117.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/1191.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/132.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/179.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/627.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/1307.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/600.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/1130.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/train/151.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/920.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/338.wav (deflated 44%)\n",
            "  adding: content/TGT_AUDIO/train/828.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/1340.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/653.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/1244.wav (deflated 57%)\n",
            "  adding: content/TGT_AUDIO/train/15.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1247.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/863.wav (deflated 37%)\n",
            "  adding: content/TGT_AUDIO/train/1509.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/33.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/1134.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/827.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/221.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/train/745.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/train/1036.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/443.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/1159.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/242.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/970.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/train/814.wav (deflated 36%)\n",
            "  adding: content/TGT_AUDIO/train/83.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/533.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1347.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/809.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/654.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/909.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/786.wav (deflated 33%)\n",
            "  adding: content/TGT_AUDIO/train/1135.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/1182.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/582.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/147.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/955.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/677.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/1423.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/495.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/826.wav (deflated 37%)\n",
            "  adding: content/TGT_AUDIO/train/291.wav (deflated 42%)\n",
            "  adding: content/TGT_AUDIO/train/1001.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/1417.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/1442.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/971.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/297.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/873.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/246.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/1259.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/1335.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/1025.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/458.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/419.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/158.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/1074.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/660.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/171.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/781.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/1125.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/728.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/1282.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/228.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/1119.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/256.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/1058.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/1440.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/133.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1177.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/1234.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/309.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/622.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/26.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/163.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/581.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1346.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/1048.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/477.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/824.wav (deflated 55%)\n",
            "  adding: content/TGT_AUDIO/train/1305.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/606.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/748.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/376.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/92.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/1331.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/348.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/791.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/931.wav (deflated 36%)\n",
            "  adding: content/TGT_AUDIO/train/138.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/84.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/528.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/1123.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/1286.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/288.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/974.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/764.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/1315.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/804.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1060.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/1213.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/515.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/918.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/296.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/642.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1399.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/612.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/train/1072.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/1332.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/1086.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/146.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/378.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/408.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/1239.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/690.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/658.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/67.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/1461.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/1196.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/187.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/train/675.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/train/1255.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/422.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/751.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/1019.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/train/184.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/1129.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/174.wav (deflated 41%)\n",
            "  adding: content/TGT_AUDIO/train/438.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/890.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/707.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/1085.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/374.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/230.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/932.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/538.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/628.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/997.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/796.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/1301.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/229.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/865.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/393.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/1068.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/1302.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/817.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/116.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/1445.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/1218.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/661.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/334.wav (deflated 37%)\n",
            "  adding: content/TGT_AUDIO/train/209.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/24.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/520.wav (deflated 37%)\n",
            "  adding: content/TGT_AUDIO/train/911.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1413.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/1061.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/1169.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/248.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/761.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/1294.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/240.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/452.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/722.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/1505.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/963.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/140.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/652.wav (deflated 43%)\n",
            "  adding: content/TGT_AUDIO/train/1494.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/136.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/321.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/1402.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/258.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/79.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/1392.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/1096.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/213.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/521.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/831.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1480.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/732.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/320.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/953.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/968.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/834.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/1269.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/733.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/231.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1350.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/990.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/1297.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/237.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/1006.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/412.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/941.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/251.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/993.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/332.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/983.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/736.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/1053.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/1066.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/train/1109.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/958.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/265.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/1425.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/870.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/1195.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/979.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/959.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/142.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/706.wav (deflated 43%)\n",
            "  adding: content/TGT_AUDIO/train/1221.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/1293.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/178.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/450.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/168.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/1188.wav (deflated 46%)\n",
            "  adding: content/TGT_AUDIO/train/613.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/548.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/141.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/843.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/888.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/1380.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/693.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/905.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/375.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/1279.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/672.wav (deflated 41%)\n",
            "  adding: content/TGT_AUDIO/train/1401.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/506.wav (deflated 37%)\n",
            "  adding: content/TGT_AUDIO/train/1373.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/639.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/353.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1257.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/962.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/1026.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/1405.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/788.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/795.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/483.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/121.wav (deflated 34%)\n",
            "  adding: content/TGT_AUDIO/train/104.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/241.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/275.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/189.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/806.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/215.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/109.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/train/965.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/train/703.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/698.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/289.wav (deflated 42%)\n",
            "  adding: content/TGT_AUDIO/train/537.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/373.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/197.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/44.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/403.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/1508.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/861.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/201.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/292.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/285.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/1354.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/1383.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/298.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/1250.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/973.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/950.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/train/322.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/812.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/803.wav (deflated 37%)\n",
            "  adding: content/TGT_AUDIO/train/1449.wav (deflated 36%)\n",
            "  adding: content/TGT_AUDIO/train/131.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/1488.wav (deflated 36%)\n",
            "  adding: content/TGT_AUDIO/train/900.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/350.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/1117.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/1393.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/281.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/575.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/1472.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/1087.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/110.wav (deflated 37%)\n",
            "  adding: content/TGT_AUDIO/train/276.wav (deflated 34%)\n",
            "  adding: content/TGT_AUDIO/train/449.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/776.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/435.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/328.wav (deflated 34%)\n",
            "  adding: content/TGT_AUDIO/train/727.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/1180.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/1.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/573.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/198.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/947.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/845.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/489.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/1432.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/636.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/1020.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/181.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/train/1144.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/1359.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/1217.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/587.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/1107.wav (deflated 33%)\n",
            "  adding: content/TGT_AUDIO/train/245.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/42.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/329.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/416.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/1426.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/789.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/1396.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/train/1355.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/57.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/1219.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1320.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/382.wav (deflated 41%)\n",
            "  adding: content/TGT_AUDIO/train/1171.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/389.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/566.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/702.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/475.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/738.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/train/1503.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1081.wav (deflated 44%)\n",
            "  adding: content/TGT_AUDIO/train/1458.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/840.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/649.wav (deflated 37%)\n",
            "  adding: content/TGT_AUDIO/train/726.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/469.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/1334.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/225.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/550.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/58.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/220.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/986.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/102.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/411.wav (deflated 41%)\n",
            "  adding: content/TGT_AUDIO/train/399.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/802.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/164.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/train/61.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/271.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/1062.wav (deflated 41%)\n",
            "  adding: content/TGT_AUDIO/train/991.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/98.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/619.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/937.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/train/467.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/1319.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/499.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/514.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/872.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/892.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/106.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/437.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/122.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/1479.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/497.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/1103.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/772.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/388.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/233.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/224.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/1157.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/1098.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/425.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1437.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/1439.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/984.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/train/152.wav (deflated 34%)\n",
            "  adding: content/TGT_AUDIO/train/1329.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/704.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/842.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/942.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/417.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/65.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/1174.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/219.wav (deflated 46%)\n",
            "  adding: content/TGT_AUDIO/train/545.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/325.wav (deflated 5%)\n",
            "  adding: content/TGT_AUDIO/train/935.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/357.wav (deflated 42%)\n",
            "  adding: content/TGT_AUDIO/train/898.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/1246.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/188.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/62.wav (deflated 47%)\n",
            "  adding: content/TGT_AUDIO/train/207.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/929.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/1142.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/1067.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/385.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/1106.wav (deflated 35%)\n",
            "  adding: content/TGT_AUDIO/train/866.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/1288.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/47.wav (deflated 34%)\n",
            "  adding: content/TGT_AUDIO/train/347.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/498.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/1321.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/590.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/759.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/939.wav (deflated 48%)\n",
            "  adding: content/TGT_AUDIO/train/926.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/879.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1351.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/711.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/525.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/594.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/424.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/1147.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/655.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/232.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/849.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/259.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/239.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/766.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/train/1451.wav (deflated 35%)\n",
            "  adding: content/TGT_AUDIO/train/1328.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/688.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/568.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/1092.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/1080.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/1441.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/78.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/1084.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/train/344.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/1162.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/651.wav (deflated 36%)\n",
            "  adding: content/TGT_AUDIO/train/280.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/869.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/763.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/874.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/323.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/471.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/447.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/852.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/177.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/605.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/684.wav (deflated 37%)\n",
            "  adding: content/TGT_AUDIO/train/12.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/617.wav (deflated 37%)\n",
            "  adding: content/TGT_AUDIO/train/55.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/1292.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/1078.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/641.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1165.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/1122.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/406.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/940.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/202.wav (deflated 36%)\n",
            "  adding: content/TGT_AUDIO/train/1167.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/783.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/27.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/157.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/1027.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/1284.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/235.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/507.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/1336.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/1408.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/398.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/883.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/692.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/919.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/1502.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/428.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/1385.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/313.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/1055.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/1476.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/1273.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/80.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1421.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/1063.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/336.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/1403.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/1271.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/50.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/51.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/815.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/train/1289.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/1375.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/381.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/432.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/286.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/1501.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/1256.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/620.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/train/535.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/1492.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/367.wav (deflated 44%)\n",
            "  adding: content/TGT_AUDIO/train/1306.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/311.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/832.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/train/34.wav (deflated 43%)\n",
            "  adding: content/TGT_AUDIO/train/354.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/923.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/739.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/839.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/446.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/544.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/493.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/936.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/632.wav (deflated 36%)\n",
            "  adding: content/TGT_AUDIO/train/1348.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/598.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/570.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/1012.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/train/128.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/train/324.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1323.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/155.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/359.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/884.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/1069.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/63.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/263.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/735.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/161.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/264.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/996.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/315.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1038.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/943.wav (deflated 46%)\n",
            "  adding: content/TGT_AUDIO/train/591.wav (deflated 44%)\n",
            "  adding: content/TGT_AUDIO/train/650.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1444.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/1228.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/1371.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/1470.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/724.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/371.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/823.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/1418.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/1030.wav (deflated 37%)\n",
            "  adding: content/TGT_AUDIO/train/211.wav (deflated 36%)\n",
            "  adding: content/TGT_AUDIO/train/624.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/124.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/992.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/1034.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/777.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/1261.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/1487.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/701.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/1111.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/1242.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/199.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/train/664.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/356.wav (deflated 35%)\n",
            "  adding: content/TGT_AUDIO/train/881.wav (deflated 5%)\n",
            "  adding: content/TGT_AUDIO/train/1360.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/1362.wav (deflated 37%)\n",
            "  adding: content/TGT_AUDIO/train/1199.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/540.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/1412.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/1226.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/938.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/1151.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/208.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/1469.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1473.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/625.wav (deflated 34%)\n",
            "  adding: content/TGT_AUDIO/train/1220.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/310.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/421.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/1141.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/859.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/1252.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/778.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1051.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/833.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/1248.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/253.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/470.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/391.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/1237.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/960.wav (deflated 41%)\n",
            "  adding: content/TGT_AUDIO/train/200.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/46.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/539.wav (deflated 42%)\n",
            "  adding: content/TGT_AUDIO/train/976.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/1124.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/987.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/390.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/250.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/217.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/1079.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/190.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/32.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/1457.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/829.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/119.wav (deflated 8%)\n",
            "  adding: content/TGT_AUDIO/train/576.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/1365.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/743.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/1149.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/349.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/1345.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/891.wav (deflated 43%)\n",
            "  adding: content/TGT_AUDIO/train/686.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/1363.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/train/773.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/91.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/165.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/1258.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/169.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/59.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/28.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/1024.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/train/81.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/train/420.wav (deflated 33%)\n",
            "  adding: content/TGT_AUDIO/train/659.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/1266.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/586.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/1197.wav (deflated 47%)\n",
            "  adding: content/TGT_AUDIO/train/785.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/1212.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/268.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/115.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/1410.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/609.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/978.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/7.wav (deflated 35%)\n",
            "  adding: content/TGT_AUDIO/train/1349.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/1209.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/train/821.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/1083.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/166.wav (deflated 35%)\n",
            "  adding: content/TGT_AUDIO/train/853.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/969.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/744.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/304.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/1099.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/825.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1443.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/1201.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/555.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/1233.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/218.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1291.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/train/697.wav (deflated 37%)\n",
            "  adding: content/TGT_AUDIO/train/1163.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/886.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/274.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/train/1448.wav (deflated 35%)\n",
            "  adding: content/TGT_AUDIO/train/750.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/1032.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/933.wav (deflated 41%)\n",
            "  adding: content/TGT_AUDIO/train/314.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/69.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/278.wav (deflated 41%)\n",
            "  adding: content/TGT_AUDIO/train/1310.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/1013.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1238.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/670.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/train/455.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/667.wav (deflated 51%)\n",
            "  adding: content/TGT_AUDIO/train/792.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/1146.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/train/1272.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/463.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/1203.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/1372.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/train/602.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/767.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/669.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/914.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/125.wav (deflated 36%)\n",
            "  adding: content/TGT_AUDIO/train/1240.wav (deflated 35%)\n",
            "  adding: content/TGT_AUDIO/train/5.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/454.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1154.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/1114.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/798.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/572.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/266.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/111.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/756.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/1015.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/53.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/train/1344.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/154.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/train/70.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/1168.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/577.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/444.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/640.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/509.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1415.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/203.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/train/1041.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/143.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/train/402.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/1070.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/train/1429.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/1215.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/139.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/830.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/295.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/1104.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/1145.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/705.wav (deflated 39%)\n",
            "  adding: content/TGT_AUDIO/train/418.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/train/206.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/279.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/37.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/1193.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/1296.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/1095.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/595.wav (deflated 40%)\n",
            "  adding: content/TGT_AUDIO/train/875.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/269.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/383.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/433.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/1446.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/1390.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/train/723.wav (deflated 37%)\n",
            "  adding: content/TGT_AUDIO/train/916.wav (deflated 6%)\n",
            "  adding: content/TGT_AUDIO/train/896.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/train/906.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/train/1052.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/train/113.wav (deflated 7%)\n",
            "  adding: content/TGT_AUDIO/train/283.wav (deflated 34%)\n",
            "  adding: content/TGT_AUDIO/train/1140.wav (deflated 41%)\n",
            "  adding: content/TGT_AUDIO/train/1005.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/train/752.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/train/1507.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/train/1229.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/train/440.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/train/787.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/train/837.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/train/1164.wav (deflated 38%)\n",
            "  adding: content/TGT_AUDIO/train/610.wav (deflated 9%)\n",
            "  adding: content/TGT_AUDIO/dev/ (stored 0%)\n",
            "  adding: content/TGT_AUDIO/dev/1646.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/dev/1598.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/dev/1608.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/dev/1545.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/dev/1538.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/dev/1590.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/dev/1618.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/dev/1552.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/dev/1615.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/dev/1560.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/dev/1517.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/dev/1559.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/dev/1600.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/dev/1544.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/dev/1611.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/dev/1633.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/dev/1525.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/dev/1619.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/dev/1578.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/dev/1533.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/dev/1659.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/dev/1554.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/dev/1519.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/dev/1607.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/dev/1643.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/dev/1580.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/dev/1585.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/dev/1589.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/dev/1635.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/dev/1641.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/dev/1532.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/dev/1529.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/dev/1642.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/dev/1631.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/dev/1568.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/dev/1591.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/dev/1547.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/dev/1628.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/dev/1597.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/dev/1613.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/dev/1524.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/dev/1647.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/dev/1527.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/dev/1574.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/dev/1561.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/dev/1553.wav (deflated 35%)\n",
            "  adding: content/TGT_AUDIO/dev/1637.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/dev/1616.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/dev/1654.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/dev/1514.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/dev/1579.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/dev/1569.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/dev/1605.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/dev/1530.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/dev/1627.wav (deflated 10%)\n",
            "  adding: content/TGT_AUDIO/dev/1614.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/dev/1549.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/dev/1550.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/dev/1644.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/dev/1621.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/dev/1567.wav (deflated 33%)\n",
            "  adding: content/TGT_AUDIO/dev/1523.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/dev/1526.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/dev/1528.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/dev/1602.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/dev/1625.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/dev/1557.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/dev/1624.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/dev/1588.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/dev/1570.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/dev/1593.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/dev/1536.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/dev/1606.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/dev/1543.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/dev/1520.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/dev/1612.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/dev/1548.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/dev/1515.wav (deflated 34%)\n",
            "  adding: content/TGT_AUDIO/dev/1655.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/dev/1632.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/dev/1540.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/dev/1521.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/dev/1565.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/dev/1539.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/dev/1595.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/dev/1599.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/dev/1510.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/dev/1645.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/dev/1575.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/dev/1638.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/dev/1542.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/dev/1648.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/dev/1576.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/dev/1541.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/dev/1518.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/dev/1657.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/dev/1531.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/dev/1564.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/dev/1650.wav (deflated 34%)\n",
            "  adding: content/TGT_AUDIO/dev/1604.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/dev/1587.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/dev/1640.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/dev/1652.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/dev/1634.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/dev/1571.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/dev/1610.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/dev/1656.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/dev/1636.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/dev/1563.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/dev/1572.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/dev/1581.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/dev/1596.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/dev/1562.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/dev/1558.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/dev/1555.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/dev/1609.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/dev/1658.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/dev/1594.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/dev/1513.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/dev/1577.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/dev/1630.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/dev/1592.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/dev/1516.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/dev/1584.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/dev/1639.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/dev/1573.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/dev/1551.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/dev/1601.wav (deflated 23%)\n",
            "  adding: content/TGT_AUDIO/dev/1622.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/dev/1603.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/dev/1535.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/dev/1546.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/dev/1651.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/dev/1617.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/dev/1583.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/dev/1566.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/dev/1649.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/dev/1620.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/dev/1522.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/dev/1626.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/ (stored 0%)\n",
            "  adding: content/TGT_AUDIO/test/1715.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1946.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1983.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/test/1867.wav (deflated 33%)\n",
            "  adding: content/TGT_AUDIO/test/1712.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1895.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1970.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/test/1734.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/test/1797.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1984.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/test/1768.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1911.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1894.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1950.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1725.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1794.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/test/1691.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/test/1853.wav (deflated 36%)\n",
            "  adding: content/TGT_AUDIO/test/1893.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1776.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1814.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/test/1934.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1833.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1941.wav (deflated 35%)\n",
            "  adding: content/TGT_AUDIO/test/1845.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1825.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/test/1963.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1909.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1773.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1976.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/test/1902.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/test/1722.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1871.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1694.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1792.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1957.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1660.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1969.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1711.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1836.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1812.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1757.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1690.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1774.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/test/1699.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/test/1977.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1891.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1826.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1666.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/test/1753.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1721.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1878.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1919.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1670.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/test/1809.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/2005.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1839.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1787.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1827.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1897.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/test/1739.wav (deflated 34%)\n",
            "  adding: content/TGT_AUDIO/test/1724.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/test/1815.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/test/2006.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1820.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/test/1923.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/test/1948.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1762.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1885.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/test/1954.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1685.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1665.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1707.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1808.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1972.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1928.wav (deflated 33%)\n",
            "  adding: content/TGT_AUDIO/test/1987.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1682.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1803.wav (deflated 33%)\n",
            "  adding: content/TGT_AUDIO/test/1858.wav (deflated 21%)\n",
            "  adding: content/TGT_AUDIO/test/2004.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1841.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/test/1955.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1877.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1813.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1850.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1816.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/test/1775.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1754.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1780.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/test/1732.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/test/1874.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/test/1741.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1838.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/test/1789.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/test/1688.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1765.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/2009.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/test/1875.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/test/1758.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1947.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/test/1664.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1745.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/test/1981.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/test/1799.wav (deflated 36%)\n",
            "  adding: content/TGT_AUDIO/test/1717.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1681.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1964.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/test/1904.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/test/1932.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1781.wav (deflated 33%)\n",
            "  adding: content/TGT_AUDIO/test/1804.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1818.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/test/1837.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1998.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1760.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1742.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1846.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/test/1782.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/test/1755.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1856.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1991.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/test/1830.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/test/1835.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1896.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1764.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/test/1737.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/test/1995.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1679.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1990.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1723.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1974.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/test/1821.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1779.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/test/1829.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/test/1704.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1914.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/test/1798.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/test/1669.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/test/1831.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1943.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1916.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1851.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1730.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1678.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1920.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1975.wav (deflated 12%)\n",
            "  adding: content/TGT_AUDIO/test/1702.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1854.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1740.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1761.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/test/1840.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/test/1869.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/test/1879.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1870.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1956.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1747.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1689.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1917.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/test/1731.wav (deflated 33%)\n",
            "  adding: content/TGT_AUDIO/test/1993.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/test/1736.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/2002.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1873.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/test/1661.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1772.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1913.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1862.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1980.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1864.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/test/1992.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1971.wav (deflated 14%)\n",
            "  adding: content/TGT_AUDIO/test/1708.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/test/1783.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1695.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1953.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/test/1925.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1883.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1788.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/test/1985.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1834.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1945.wav (deflated 22%)\n",
            "  adding: content/TGT_AUDIO/test/1674.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1672.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/test/1944.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/test/1860.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1751.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1949.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1910.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1927.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1687.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1677.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/test/1752.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1770.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/test/1986.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1686.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1805.wav (deflated 33%)\n",
            "  adding: content/TGT_AUDIO/test/1766.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/test/1905.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/test/1703.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/test/1675.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/2008.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1777.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1942.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/test/1966.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/test/1692.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1900.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/test/1714.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1756.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1849.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1901.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1857.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1918.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1709.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/test/1763.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1935.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1683.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1912.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/test/1693.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1663.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1978.wav (deflated 30%)\n",
            "  adding: content/TGT_AUDIO/test/1790.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/test/1876.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/test/1855.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1738.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1889.wav (deflated 11%)\n",
            "  adding: content/TGT_AUDIO/test/1824.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/test/1778.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/test/1952.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/test/1680.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1881.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1662.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1811.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1884.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/test/1859.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/test/1908.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1979.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1848.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1743.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/test/1807.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/test/1968.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/test/1959.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1698.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1999.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1886.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1982.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/test/1939.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/test/1997.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1938.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/test/1861.wav (deflated 32%)\n",
            "  adding: content/TGT_AUDIO/test/1710.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/test/1961.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/test/1735.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1713.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/test/1697.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1828.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/test/1847.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/test/1700.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/test/1843.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/test/1671.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1844.wav (deflated 20%)\n",
            "  adding: content/TGT_AUDIO/test/1973.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1931.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/test/1951.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/test/2007.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1748.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1929.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1823.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/test/1930.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1994.wav (deflated 33%)\n",
            "  adding: content/TGT_AUDIO/test/1863.wav (deflated 24%)\n",
            "  adding: content/TGT_AUDIO/test/2003.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1960.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1922.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/test/1892.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/test/1906.wav (deflated 13%)\n",
            "  adding: content/TGT_AUDIO/test/1868.wav (deflated 17%)\n",
            "  adding: content/TGT_AUDIO/test/1786.wav (deflated 31%)\n",
            "  adding: content/TGT_AUDIO/test/1726.wav (deflated 28%)\n",
            "  adding: content/TGT_AUDIO/test/1796.wav (deflated 16%)\n",
            "  adding: content/TGT_AUDIO/test/1880.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1701.wav (deflated 29%)\n",
            "  adding: content/TGT_AUDIO/test/1727.wav (deflated 33%)\n",
            "  adding: content/TGT_AUDIO/test/1921.wav (deflated 19%)\n",
            "  adding: content/TGT_AUDIO/test/1668.wav (deflated 25%)\n",
            "  adding: content/TGT_AUDIO/test/1744.wav (deflated 34%)\n",
            "  adding: content/TGT_AUDIO/test/2001.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/1865.wav (deflated 18%)\n",
            "  adding: content/TGT_AUDIO/test/2000.wav (deflated 26%)\n",
            "  adding: content/TGT_AUDIO/test/1958.wav (deflated 15%)\n",
            "  adding: content/TGT_AUDIO/test/1696.wav (deflated 27%)\n",
            "  adding: content/TGT_AUDIO/test/1924.wav (deflated 20%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/TGT_AUDIO.zip /content/drive/MyDrive/using_spectro/resampled_folder_22050Hz/"
      ],
      "metadata": {
        "id": "Oz18-OgR-8Jp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSCYDFCfjoVn",
        "outputId": "e1510dd8-47c9-4047-d282-a2b80225ef67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/nan_detector.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/tokenizer.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/options.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/iterative_refinement_generator.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/sequence_scorer.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/speech_generator.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/file_chunker_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/hub_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/incremental_decoding_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/trainer.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/binarizer.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/sequence_generator.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/file_io.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/quantization_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/registry.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/file_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/checkpoint_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/version.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/pdb.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/ngram_repeat_block.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/token_generation_constraints.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/search.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/hydra_train.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/validate.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/generate.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/interactive.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/score.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/hydra_validate.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/preprocess.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/eval_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/train.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/lightconv.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/fairseq_incremental_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/distributed_fairseq_model.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/transformer_from_pretrained_xlm.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/lightconv_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/fconv_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/fairseq_model.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/transformer_ulm.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/masked_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/fairseq_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/lstm.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/lstm_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/transformer_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/fconv_self_att.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/model_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/fairseq_encoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/composite_encoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/transformer_align.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/multilingual_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/fconv.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/logging\n",
            "copying fairseq/logging/metrics.py -> build/lib.linux-x86_64-cpython-310/fairseq/logging\n",
            "copying fairseq/logging/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/logging\n",
            "copying fairseq/logging/meters.py -> build/lib.linux-x86_64-cpython-310/fairseq/logging\n",
            "copying fairseq/logging/progress_bar.py -> build/lib.linux-x86_64-cpython-310/fairseq/logging\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/benchmark\n",
            "copying fairseq/benchmark/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_masked_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/benchmark\n",
            "copying fairseq/benchmark/benchmark_multihead_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_mt.py -> build/lib.linux-x86_64-cpython-310/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_model.py -> build/lib.linux-x86_64-cpython-310/fairseq/benchmark\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/shorten_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/id_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/raw_label_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/indexed_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/bucket_pad_length_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/plasma_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/padding_mask_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/transform_eos_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/transform_eos_concat_langpair_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/sort_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/noising.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/nested_dictionary_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/speech_dlm_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/mask_tokens_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/span_mask_tokens_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/concat_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/subsample_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/resampling_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/multi_corpus_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/codedataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/fasta_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/data_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/round_robin_zip_datasets.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/monolingual_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/num_samples_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/transform_eos_lang_pair_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/prepend_token_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/backtranslation_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/colorize_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/dictionary.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/add_target_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/replace_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/token_block_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/language_pair_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/pad_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/add_class_target_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/multi_corpus_sampled_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/strip_token_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/offset_tokens_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/lru_cache_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/iterators.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/prepend_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/text_compressor.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/list_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/numel_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/fairseq_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/concat_sentences_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/denoising_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/append_token_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/roll_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/lm_context_window_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/base_wrapper_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/dataclass\n",
            "copying fairseq/dataclass/configs.py -> build/lib.linux-x86_64-cpython-310/fairseq/dataclass\n",
            "copying fairseq/dataclass/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/dataclass\n",
            "copying fairseq/dataclass/constants.py -> build/lib.linux-x86_64-cpython-310/fairseq/dataclass\n",
            "copying fairseq/dataclass/initialize.py -> build/lib.linux-x86_64-cpython-310/fairseq/dataclass\n",
            "copying fairseq/dataclass/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/dataclass\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/hubert_criterion.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/speech_dlm_criterion.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy_with_ctc.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/wav2vec_criterion.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/fastspeech2_loss.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy_with_alignment.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/nat_loss.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/cross_entropy.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/masked_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy_latency_augmented.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/speech_to_speech_criterion.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/tacotron2_loss.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/sentence_ranking.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/fairseq_criterion.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/speech_ulm_criterion.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/adaptive_loss.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/model_criterion.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy_with_rdrop.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/composite_loss.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/legacy_masked_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/ctc.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/sentence_prediction_adapters.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/sentence_prediction.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/distributed\n",
            "copying fairseq/distributed/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/distributed\n",
            "copying fairseq/distributed/distributed_timeout_wrapper.py -> build/lib.linux-x86_64-cpython-310/fairseq/distributed\n",
            "copying fairseq/distributed/fully_sharded_data_parallel.py -> build/lib.linux-x86_64-cpython-310/fairseq/distributed\n",
            "copying fairseq/distributed/legacy_distributed_data_parallel.py -> build/lib.linux-x86_64-cpython-310/fairseq/distributed\n",
            "copying fairseq/distributed/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/distributed\n",
            "copying fairseq/distributed/module_proxy_wrapper.py -> build/lib.linux-x86_64-cpython-310/fairseq/distributed\n",
            "copying fairseq/distributed/tpu_distributed_data_parallel.py -> build/lib.linux-x86_64-cpython-310/fairseq/distributed\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples\n",
            "copying fairseq/examples/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/model_parallel\n",
            "copying fairseq/model_parallel/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel\n",
            "copying fairseq/model_parallel/megatron_trainer.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/dynamic_loss_scaler.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/fused_lamb.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/bmuf.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/composite.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/adadelta.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/nag.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/fp16_optimizer.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/shard.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/cpu_adam.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/adagrad.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/amp_optimizer.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/adam.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/fairseq_optimizer.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/sgd.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/adafactor.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/adamax.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/fused_adam.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/config\n",
            "copying fairseq/config/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/adaptive_input.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/lightweight_convolution.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/transformer_sentence_encoder_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/dynamic_crf_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/fp32_batch_norm.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/kmeans_vector_quantizer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/grad_multiply.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/positional_embedding.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/conv_tbc.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/ema_module.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/location_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/cross_entropy.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/transformer_layer_aug.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/transpose_last.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/positional_encoding.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/fp32_group_norm.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/gelu.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/quant_noise.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/linearized_convolution.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/fairseq_dropout.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/beamable_mm.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/vggblock.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/checkpoint_activations.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/learned_positional_embedding.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/transformer_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/layer_drop.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/same_pad.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/sparse_transformer_sentence_encoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/layer_norm.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/multihead_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/transformer_sentence_encoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/sparse_transformer_sentence_encoder_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/gumbel_vector_quantizer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/conformer_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/character_token_embedder.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/sinusoidal_positional_embedding.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/scalar_bias.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/unfold.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/rotary_positional_embedding.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/sparse_multihead_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/lstm_cell_with_zoneout.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/base_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/dynamic_convolution.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/fp32_instance_norm.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/kmeans_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/adaptive_softmax.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/espnet_multihead_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/downsampled_multihead_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/scoring\n",
            "copying fairseq/scoring/meteor.py -> build/lib.linux-x86_64-cpython-310/fairseq/scoring\n",
            "copying fairseq/scoring/chrf.py -> build/lib.linux-x86_64-cpython-310/fairseq/scoring\n",
            "copying fairseq/scoring/tokenizer.py -> build/lib.linux-x86_64-cpython-310/fairseq/scoring\n",
            "copying fairseq/scoring/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/scoring\n",
            "copying fairseq/scoring/bleu.py -> build/lib.linux-x86_64-cpython-310/fairseq/scoring\n",
            "copying fairseq/scoring/wer.py -> build/lib.linux-x86_64-cpython-310/fairseq/scoring\n",
            "copying fairseq/scoring/bertscore.py -> build/lib.linux-x86_64-cpython-310/fairseq/scoring\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/audio_classification.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/language_modeling.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/audio_pretraining.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/multilingual_translation.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/cross_lingual_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/multires_hubert_pretraining.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/translation_lev.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/frm_text_to_speech.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/online_backtranslation.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/semisupervised_translation.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/multilingual_language_modeling.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/translation_from_pretrained_xlm.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/translation_from_pretrained_bart.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/masked_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/multilingual_denoising.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/nlu_finetuning.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/speech_dlm_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/speech_to_speech.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/sentence_ranking.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/legacy_masked_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/multilingual_masked_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/audio_finetuning.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/translation.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/translation_multi_simple_epoch.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/sentence_prediction_adapters.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/simultaneous_translation.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/text_to_speech.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/hubert_pretraining.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/fairseq_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/sentence_prediction.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/span_masked_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/speech_to_text.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/speech_ulm_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/denoising.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/hubert\n",
            "copying fairseq/models/hubert/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/hubert\n",
            "copying fairseq/models/hubert/hubert_asr.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/hubert\n",
            "copying fairseq/models/hubert/hubert.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/hubert\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/multi_modality_model.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/convtransformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/s2t_conformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/xm_transformer_unity.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/hub_interface.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/xm_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/s2t_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/berard.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/s2t_wav_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/bart\n",
            "copying fairseq/models/bart/model.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/bart\n",
            "copying fairseq/models/bart/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/bart\n",
            "copying fairseq/models/bart/hub_interface.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/bart\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_legacy.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_base.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_encoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_config.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_decoder_aug.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/transformer\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/model.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/model_gottbert.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/enc_dec.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/model_camembert.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/alignment_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/hub_interface.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/model_xlmr.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/roberta\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/multires_hubert\n",
            "copying fairseq/models/multires_hubert/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/multires_hubert\n",
            "copying fairseq/models/multires_hubert/multires_hubert_asr.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/multires_hubert\n",
            "copying fairseq/models/multires_hubert/multires_hubert.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/multires_hubert\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/cmlm_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/fairseq_nat_model.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/iterative_nonautoregressive_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/nat_crf_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/insertion_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/levenshtein_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/nonautoregressive_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/levenshtein_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/nonautoregressive_ensembles.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/wav2vec2_classification.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/wav2vec2_asr.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/wav2vec2_laser.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/wav2vec.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/wav2vec2.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/wav2vec\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/huggingface\n",
            "copying fairseq/models/huggingface/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/huggingface\n",
            "copying fairseq/models/huggingface/hf_gpt2.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/huggingface\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/ema\n",
            "copying fairseq/models/ema/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/ema\n",
            "copying fairseq/models/ema/ema.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/ema\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/xmod\n",
            "copying fairseq/models/xmod/model.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/xmod\n",
            "copying fairseq/models/xmod/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/xmod\n",
            "copying fairseq/models/xmod/hub_interface.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/xmod\n",
            "copying fairseq/models/xmod/transformer_layer_xmod.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/xmod\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm\n",
            "copying fairseq/models/speech_dlm/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm\n",
            "copying fairseq/models/speech_dlm/hub_interface.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm\n",
            "copying fairseq/models/speech_dlm/speech_dlm.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/codehifigan.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/vocoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/hub_interface.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/tts_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/fastspeech2.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/tacotron2.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/hifigan.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/text_to_speech\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/s2s_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/s2s_conformer_unity.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/s2s_conformer_translatotron2.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/s2s_conformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text/modules\n",
            "copying fairseq/models/speech_to_text/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text/modules\n",
            "copying fairseq/models/speech_to_text/modules/convolution.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text/modules\n",
            "copying fairseq/models/speech_to_text/modules/emformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text/modules\n",
            "copying fairseq/models/speech_to_text/modules/augmented_memory_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm/sequence_generator\n",
            "copying fairseq/models/speech_dlm/sequence_generator/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm/sequence_generator\n",
            "copying fairseq/models/speech_dlm/sequence_generator/multichannel_sequence_generator.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm/sequence_generator\n",
            "copying fairseq/models/speech_dlm/sequence_generator/multichannel_search.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm/sequence_generator\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm/modules\n",
            "copying fairseq/models/speech_dlm/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm/modules\n",
            "copying fairseq/models/speech_dlm/modules/speech_dlm_decoder_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm/modules\n",
            "copying fairseq/models/speech_dlm/modules/speech_dlm_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/stacked_embedding.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/transformer_encoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/ctc_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/transformer_decoder_aug.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/data/legacy\n",
            "copying fairseq/data/legacy/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/legacy\n",
            "copying fairseq/data/legacy/masked_lm_dictionary.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/legacy\n",
            "copying fairseq/data/legacy/masked_lm_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/legacy\n",
            "copying fairseq/data/legacy/block_pair_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/legacy\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/bytes.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/characters.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/subword_nmt_bpe.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/fastbpe.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/byte_bpe.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/space_tokenizer.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/gpt2_bpe_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/hf_bert_bpe.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/gpt2_bpe.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/hf_byte_bpe.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/byte_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/nltk_tokenizer.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/sentencepiece_bpe.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/moses_tokenizer.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/sampled_multi_epoch_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/sampling_method.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/multilingual_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/multilingual_data_manager.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/sampled_multi_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/multilingual\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/speech_to_speech_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/speech_to_text_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/frm_text_to_speech_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/multi_modality_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/data_cfg.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/speech_to_text_joint_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/text_to_speech_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/raw_audio_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/hubert_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/audio_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/data/huffman\n",
            "copying fairseq/data/huffman/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/huffman\n",
            "copying fairseq/data/huffman/huffman_coder.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/huffman\n",
            "copying fairseq/data/huffman/huffman_mmap_indexed_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/huffman\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/data/audio/waveform_transforms\n",
            "copying fairseq/data/audio/waveform_transforms/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/waveform_transforms\n",
            "copying fairseq/data/audio/waveform_transforms/noiseaugment.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/waveform_transforms\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/data/audio/dataset_transforms\n",
            "copying fairseq/data/audio/dataset_transforms/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/dataset_transforms\n",
            "copying fairseq/data/audio/dataset_transforms/concataugment.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/dataset_transforms\n",
            "copying fairseq/data/audio/dataset_transforms/noisyoverlapaugment.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/dataset_transforms\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/specaugment.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/global_cmvn.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/delta_deltas.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/utterance_cmvn.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/feature_transforms\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt\n",
            "copying fairseq/examples/discriminative_reranking_nmt/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt\n",
            "copying fairseq/examples/discriminative_reranking_nmt/drnmt_rerank.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition\n",
            "copying fairseq/examples/speech_recognition/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition\n",
            "copying fairseq/examples/speech_recognition/w2l_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition\n",
            "copying fairseq/examples/speech_recognition/infer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation\n",
            "copying fairseq/examples/simultaneous_translation/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/truncated_bptt\n",
            "copying fairseq/examples/truncated_bptt/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/truncated_bptt\n",
            "copying fairseq/examples/truncated_bptt/transformer_xl_model.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/truncated_bptt\n",
            "copying fairseq/examples/truncated_bptt/truncated_bptt_lm_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/truncated_bptt\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/rxf\n",
            "copying fairseq/examples/rxf/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/rxf\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/wav2vec_featurize.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/vq-wav2vec_featurize.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/libri_labels.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/wav2vec_manifest.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text\n",
            "copying fairseq/examples/speech_text_joint_to_text/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec\n",
            "copying fairseq/examples/data2vec/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec\n",
            "copying fairseq/examples/data2vec/fb_convert_beit_cp.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adagrad_with_grad_clip.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adaptive_span_model.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/truncated_bptt_lm_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adaptive_span_model_wrapper.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adaptive_span_loss.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adaptive_span_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/adaptive_span\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_options.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_score_bw.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_score_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_tune.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_generate.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis\n",
            "copying fairseq/examples/speech_synthesis/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis\n",
            "copying fairseq/examples/speech_synthesis/data_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis\n",
            "copying fairseq/examples/speech_synthesis/generate_waveform.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis\n",
            "copying fairseq/examples/speech_synthesis/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech\n",
            "copying fairseq/examples/speech_to_speech/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech\n",
            "copying fairseq/examples/speech_to_speech/generate_waveform_from_code.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/fast_noisy_channel\n",
            "copying fairseq/examples/fast_noisy_channel/noisy_channel_beam_search.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/fast_noisy_channel\n",
            "copying fairseq/examples/fast_noisy_channel/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/fast_noisy_channel\n",
            "copying fairseq/examples/fast_noisy_channel/noisy_channel_translation.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/fast_noisy_channel\n",
            "copying fairseq/examples/fast_noisy_channel/noisy_channel_sequence_generator.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/fast_noisy_channel\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/models\n",
            "copying fairseq/examples/discriminative_reranking_nmt/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/models\n",
            "copying fairseq/examples/discriminative_reranking_nmt/models/discriminative_reranking_model.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/criterions\n",
            "copying fairseq/examples/discriminative_reranking_nmt/criterions/discriminative_reranking_criterion.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/criterions\n",
            "copying fairseq/examples/discriminative_reranking_nmt/criterions/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/criterions\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/tasks\n",
            "copying fairseq/examples/discriminative_reranking_nmt/tasks/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/tasks\n",
            "copying fairseq/examples/discriminative_reranking_nmt/tasks/discriminative_reranking_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/tasks\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/models\n",
            "copying fairseq/examples/speech_recognition/models/w2l_conv_glu_enc.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/models\n",
            "copying fairseq/examples/speech_recognition/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/models\n",
            "copying fairseq/examples/speech_recognition/models/vggtransformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/collaters.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/asr_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/data_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/replabels.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/data\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/criterions\n",
            "copying fairseq/examples/speech_recognition/criterions/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/criterions\n",
            "copying fairseq/examples/speech_recognition/criterions/cross_entropy_acc.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/criterions\n",
            "copying fairseq/examples/speech_recognition/criterions/ASG_loss.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/criterions\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new\n",
            "copying fairseq/examples/speech_recognition/new/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new\n",
            "copying fairseq/examples/speech_recognition/new/infer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/kaldi\n",
            "copying fairseq/examples/speech_recognition/kaldi/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/kaldi\n",
            "copying fairseq/examples/speech_recognition/kaldi/kaldi_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/kaldi\n",
            "copying fairseq/examples/speech_recognition/kaldi/kaldi_initializer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/kaldi\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/tasks\n",
            "copying fairseq/examples/speech_recognition/tasks/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/tasks\n",
            "copying fairseq/examples/speech_recognition/tasks/speech_recognition.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/tasks\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/base_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/flashlight_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/decoder_config.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/viterbi_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/decoders\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/models\n",
            "copying fairseq/examples/simultaneous_translation/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/models\n",
            "copying fairseq/examples/simultaneous_translation/models/convtransformer_simul_trans.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/models\n",
            "copying fairseq/examples/simultaneous_translation/models/transformer_monotonic_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/utils\n",
            "copying fairseq/examples/simultaneous_translation/utils/p_choose_strategy.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/utils\n",
            "copying fairseq/examples/simultaneous_translation/utils/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/utils\n",
            "copying fairseq/examples/simultaneous_translation/utils/monotonic_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/utils\n",
            "copying fairseq/examples/simultaneous_translation/utils/functions.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/utils\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/modules\n",
            "copying fairseq/examples/simultaneous_translation/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/modules\n",
            "copying fairseq/examples/simultaneous_translation/modules/monotonic_multihead_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/modules\n",
            "copying fairseq/examples/simultaneous_translation/modules/fixed_pre_decision.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/modules\n",
            "copying fairseq/examples/simultaneous_translation/modules/monotonic_transformer_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/rxf/rxf_src\n",
            "copying fairseq/examples/rxf/rxf_src/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/rxf/rxf_src\n",
            "copying fairseq/examples/rxf/rxf_src/label_smoothed_cross_entropy_r3f.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/rxf/rxf_src\n",
            "copying fairseq/examples/rxf/rxf_src/sentence_prediction_r3f.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/rxf/rxf_src\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised\n",
            "copying fairseq/examples/wav2vec/unsupervised/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised\n",
            "copying fairseq/examples/wav2vec/unsupervised/w2vu_generate.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/models\n",
            "copying fairseq/examples/wav2vec/unsupervised/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/models\n",
            "copying fairseq/examples/wav2vec/unsupervised/models/wav2vec_u.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/data\n",
            "copying fairseq/examples/wav2vec/unsupervised/data/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/data\n",
            "copying fairseq/examples/wav2vec/unsupervised/data/random_input_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/data\n",
            "copying fairseq/examples/wav2vec/unsupervised/data/extracted_features_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/data\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/tasks\n",
            "copying fairseq/examples/wav2vec/unsupervised/tasks/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/tasks\n",
            "copying fairseq/examples/wav2vec/unsupervised/tasks/unpaired_audio_text.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/tasks\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/s2t_dualinputtransformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/joint_speech_text_pretrain_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/s2t_dualinputxmtransformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/s2t_dualinputwavtransformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "copying fairseq/examples/speech_text_joint_to_text/criterions/text_guide_cross_entropy_acc.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "copying fairseq/examples/speech_text_joint_to_text/criterions/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "copying fairseq/examples/speech_text_joint_to_text/criterions/multi_modality_cross_entropy.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "copying fairseq/examples/speech_text_joint_to_text/criterions/multi_modality_compound.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "copying fairseq/examples/speech_text_joint_to_text/tasks/speech_text_joint.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "copying fairseq/examples/speech_text_joint_to_text/tasks/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "copying fairseq/examples/speech_text_joint_to_text/tasks/speech_text_denoise_pretrain.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "copying fairseq/examples/speech_text_joint_to_text/tasks/pair_denoising.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/audio_classification.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_image_classification.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_text.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/mae_image_classification.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_text_classification.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_audio.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/mae.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec2.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_vision.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/mae_image_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/modality.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/mae_finetuning_image_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/image_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/path_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/add_class_target_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/data\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/audio_classification.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/mae_image_pretraining.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/mae_image_classification.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/image_pretraining.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/multimodal.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/image_classification.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/tasks\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/modules.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/audio.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/text.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/base.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/images.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models/modalities\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/eval_f0.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/get_eval_manifest.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/eval_asr.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/eval_sp.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/evaluation\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_ljspeech_audio_manifest.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_vctk_audio_manifest.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_feature_manifest.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_common_voice_audio_manifest.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoise_and_vad_audio.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_speaker_embedding.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/vad\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/vad/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/vad\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/resample.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/demucs.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/pretrained.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/speaker_embedder\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/speaker_embedder/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/speaker_embedder\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/asr_bleu\n",
            "copying fairseq/examples/speech_to_speech/asr_bleu/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/asr_bleu\n",
            "copying fairseq/examples/speech_to_speech/asr_bleu/compute_asr_bleu.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/asr_bleu\n",
            "copying fairseq/examples/speech_to_speech/asr_bleu/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/asr_bleu\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/prep_s2ut_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/data_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/prep_sn_output_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/prep_sn_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/prep_s2spect_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/preprocessing\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/unity\n",
            "copying fairseq/examples/speech_to_speech/unity/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/unity\n",
            "copying fairseq/examples/speech_to_speech/unity/sequence_generator.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/unity\n",
            "copying fairseq/examples/speech_to_speech/unity/sequence_generator_multi_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/unity\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models\n",
            "copying fairseq/model_parallel/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models\n",
            "copying fairseq/model_parallel/models/transformer_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models\n",
            "copying fairseq/model_parallel/models/transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/criterions\n",
            "copying fairseq/model_parallel/criterions/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/criterions\n",
            "copying fairseq/model_parallel/criterions/vocab_parallel_cross_entropy.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/criterions\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/modules\n",
            "copying fairseq/model_parallel/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/modules\n",
            "copying fairseq/model_parallel/modules/transformer_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/modules\n",
            "copying fairseq/model_parallel/modules/multihead_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models/roberta\n",
            "copying fairseq/model_parallel/models/roberta/model.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models/roberta\n",
            "copying fairseq/model_parallel/models/roberta/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models/roberta\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
            "copying fairseq/model_parallel/models/pipeline_parallel_transformer/model.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
            "copying fairseq/model_parallel/models/pipeline_parallel_transformer/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
            "copying fairseq/model_parallel/models/pipeline_parallel_transformer/layers.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/cosine_lr_scheduler.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/inverse_square_root_schedule.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/polynomial_decay_schedule.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/fixed_schedule.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/step_lr_scheduler.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/triangular_lr_scheduler.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/pass_through.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/reduce_lr_on_plateau.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/fairseq_lr_scheduler.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/tri_stage_lr_scheduler.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/manual_lr_scheduler.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/modules/lightconv_layer\n",
            "copying fairseq/modules/lightconv_layer/cuda_function_gen.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/lightconv_layer\n",
            "copying fairseq/modules/lightconv_layer/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/lightconv_layer\n",
            "copying fairseq/modules/lightconv_layer/setup.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/lightconv_layer\n",
            "copying fairseq/modules/lightconv_layer/lightconv_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/lightconv_layer\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/modules/dynamicconv_layer\n",
            "copying fairseq/modules/dynamicconv_layer/cuda_function_gen.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/dynamicconv_layer\n",
            "copying fairseq/modules/dynamicconv_layer/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/dynamicconv_layer\n",
            "copying fairseq/modules/dynamicconv_layer/setup.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/dynamicconv_layer\n",
            "copying fairseq/modules/dynamicconv_layer/dynamicconv_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/dynamicconv_layer\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization\n",
            "copying fairseq/modules/quantization/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization\n",
            "copying fairseq/modules/quantization/quantization_options.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq\n",
            "copying fairseq/modules/quantization/pq/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq\n",
            "copying fairseq/modules/quantization/pq/em.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq\n",
            "copying fairseq/modules/quantization/pq/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq\n",
            "copying fairseq/modules/quantization/pq/pq.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar\n",
            "copying fairseq/modules/quantization/scalar/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar\n",
            "copying fairseq/modules/quantization/scalar/ops.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar\n",
            "copying fairseq/modules/quantization/scalar/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq/modules\n",
            "copying fairseq/modules/quantization/pq/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq/modules\n",
            "copying fairseq/modules/quantization/pq/modules/qemb.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq/modules\n",
            "copying fairseq/modules/quantization/pq/modules/qconv.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq/modules\n",
            "copying fairseq/modules/quantization/pq/modules/qlinear.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/qemb.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/qconv.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/qact.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/qlinear.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/examples/.gitignore -> build/lib.linux-x86_64-cpython-310/fairseq/examples\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/megatron_11b\n",
            "copying fairseq/examples/megatron_11b/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/megatron_11b\n",
            "copying fairseq/examples/megatron_11b/detok.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/megatron_11b\n",
            "copying fairseq/examples/discriminative_reranking_nmt/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/scripts\n",
            "copying fairseq/examples/discriminative_reranking_nmt/scripts/prep_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/scripts\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/config\n",
            "copying fairseq/examples/discriminative_reranking_nmt/config/deen.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/config\n",
            "copying fairseq/examples/speech_recognition/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/datasets\n",
            "copying fairseq/examples/speech_recognition/datasets/asr_prep_json.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/datasets\n",
            "copying fairseq/examples/speech_recognition/datasets/prepare-librispeech.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/datasets\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/utils\n",
            "copying fairseq/examples/speech_recognition/utils/wer_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/utils\n",
            "copying fairseq/examples/speech_recognition/new/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/conf\n",
            "copying fairseq/examples/speech_recognition/new/conf/infer.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/conf\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/conf/hydra\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/conf/hydra/sweeper\n",
            "copying fairseq/examples/speech_recognition/new/conf/hydra/sweeper/ax.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/conf/hydra/sweeper\n",
            "copying fairseq/examples/speech_recognition/new/conf/hydra/sweeper/ax_sil.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/conf/hydra/sweeper\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/conf/run_config\n",
            "copying fairseq/examples/speech_recognition/new/conf/run_config/fb_slurm_1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/conf/run_config\n",
            "copying fairseq/examples/speech_recognition/new/conf/run_config/fb_slurm_2g.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/conf/run_config\n",
            "copying fairseq/examples/speech_recognition/kaldi/add-self-loop-simple.cc -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/kaldi\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/kaldi/config\n",
            "copying fairseq/examples/speech_recognition/kaldi/config/kaldi_initializer.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/kaldi/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert\n",
            "copying fairseq/examples/hubert/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert\n",
            "copying fairseq/examples/hubert/update_ckpt.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert\n",
            "copying fairseq/examples/hubert/measure_teacher_quality.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_hubert_feature_s2t.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/learn_kmeans.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_w2v2_feature.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_hubert_feature.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_km_label.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/feature_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_mfcc_feature.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/simple_kmeans\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.xlarge.L30.len -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/test_finetuned_asr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.base.L9.npy -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.base.L9.len -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.xlarge.L30.npy -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.xlarge.hypo.word -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.large.L20.len -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.large.hypo.word -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.large.L20.npy -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/6313-76958-0021.flac -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/test_feature_and_unit.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.base.L9.km500.km -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/finetune\n",
            "copying fairseq/examples/hubert/config/finetune/base_10h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/finetune\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/finetune/lm\n",
            "copying fairseq/examples/hubert/config/finetune/lm/ls_4gram.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/finetune/lm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/finetune/run\n",
            "copying fairseq/examples/hubert/config/finetune/run/submitit_reg.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/finetune/run\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/finetune/ckpt\n",
            "copying fairseq/examples/hubert/config/finetune/ckpt/it1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/finetune/ckpt\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/pretrain\n",
            "copying fairseq/examples/hubert/config/pretrain/hubert_large_librivox.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/pretrain\n",
            "copying fairseq/examples/hubert/config/pretrain/hubert_base_librispeech.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/pretrain\n",
            "copying fairseq/examples/hubert/config/pretrain/hubert_xlarge_librivox.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/pretrain\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/pretrain/data\n",
            "copying fairseq/examples/hubert/config/pretrain/data/iter2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/pretrain/data\n",
            "copying fairseq/examples/hubert/config/pretrain/data/iter1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/pretrain/data\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/pretrain/run\n",
            "copying fairseq/examples/hubert/config/pretrain/run/submitit_reg.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/pretrain/run\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode\n",
            "copying fairseq/examples/hubert/config/decode/infer_fsqlm.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode\n",
            "copying fairseq/examples/hubert/config/decode/infer_kenlm.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode\n",
            "copying fairseq/examples/hubert/config/decode/infer_viterbi.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode/run\n",
            "copying fairseq/examples/hubert/config/decode/run/submitit_slurm_8gpu.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode/run\n",
            "copying fairseq/examples/hubert/config/decode/run/submitit_slurm.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode/run\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode/ax_sweep\n",
            "copying fairseq/examples/hubert/config/decode/ax_sweep/ngram.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode/ax_sweep\n",
            "copying fairseq/examples/hubert/config/decode/ax_sweep/transformer.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode/ax_sweep\n",
            "copying fairseq/examples/simultaneous_translation/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/eval\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/eval/agents\n",
            "copying fairseq/examples/simultaneous_translation/eval/agents/simul_t2t_enja.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/eval/agents\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/tests\n",
            "copying fairseq/examples/simultaneous_translation/tests/test_text_models.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/tests\n",
            "copying fairseq/examples/simultaneous_translation/tests/test_alignment_train.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/tests\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/docs\n",
            "copying fairseq/examples/simultaneous_translation/docs/ende-mma.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/docs\n",
            "copying fairseq/examples/simultaneous_translation/docs/enja-waitk.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/docs\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/joint_alignment_translation\n",
            "copying fairseq/examples/joint_alignment_translation/prepare-wmt18en2de_no_norm_no_escape_no_agressive.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/joint_alignment_translation\n",
            "copying fairseq/examples/joint_alignment_translation/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/joint_alignment_translation\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/pay_less_attention_paper\n",
            "copying fairseq/examples/pay_less_attention_paper/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/pay_less_attention_paper\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt19\n",
            "copying fairseq/examples/wmt19/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt19\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/byte_level_bpe\n",
            "copying fairseq/examples/byte_level_bpe/gru_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/byte_level_bpe\n",
            "copying fairseq/examples/byte_level_bpe/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/byte_level_bpe\n",
            "copying fairseq/examples/byte_level_bpe/get_data.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/byte_level_bpe\n",
            "copying fairseq/examples/byte_level_bpe/get_bitext.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/byte_level_bpe\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/prep_covost_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/prep_mustc_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/data_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/seg_mustc_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/prep_mtedx_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/prep_librispeech_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text/simultaneous_translation\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text/simultaneous_translation/agents\n",
            "copying fairseq/examples/speech_to_text/simultaneous_translation/agents/fairseq_simul_st_agent.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text/simultaneous_translation/agents\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/covost_example.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/simulst_mustc_example.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/mtedx_example.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/mustc_example.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/librispeech_example.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text/docs\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/quant_noise\n",
            "copying fairseq/examples/quant_noise/transformer_quantization_config.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/quant_noise\n",
            "copying fairseq/examples/quant_noise/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/quant_noise\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/paraphraser\n",
            "copying fairseq/examples/paraphraser/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/paraphraser\n",
            "copying fairseq/examples/paraphraser/paraphrase.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/paraphraser\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/xlmr\n",
            "copying fairseq/examples/xlmr/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/xlmr\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/bart\n",
            "copying fairseq/examples/bart/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/bart\n",
            "copying fairseq/examples/bart/README.summarization.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/bart\n",
            "copying fairseq/examples/bart/summarize.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/bart\n",
            "copying fairseq/examples/bart/README.glue.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/bart\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mbart\n",
            "copying fairseq/examples/mbart/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mbart\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/camembert\n",
            "copying fairseq/examples/camembert/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/camembert\n",
            "copying fairseq/examples/truncated_bptt/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/truncated_bptt\n",
            "copying fairseq/examples/rxf/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/rxf\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/multilingual_fairseq_gen.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/finetune_multilingual_model.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/ML50_langs.txt -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/train_multilingual_model.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_ted_and_extract.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/check_valid_test_overlaps.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/check_iswlt_test_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_lotus.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_wmt20.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_af_xh.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/remove_valid_test_in_train.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_iitb.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_flores_data.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_wat19_my.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_wmt19_and_before.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/check_self_overlaps.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/preprocess_ML50_v1.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_iwslt_and_extract.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/requirement.txt -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/dedup_all.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_ML50_v1.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/binarize.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts/utils\n",
            "copying fairseq/examples/multilingual/data_scripts/utils/dedup.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts/utils\n",
            "copying fairseq/examples/multilingual/data_scripts/utils/fasttext_multi_filter.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts/utils\n",
            "copying fairseq/examples/multilingual/data_scripts/utils/strip_sgm.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts/utils\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100\n",
            "copying fairseq/examples/m2m_100/tok.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100\n",
            "copying fairseq/examples/m2m_100/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100\n",
            "copying fairseq/examples/m2m_100/install_dependecies.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/process_data\n",
            "copying fairseq/examples/m2m_100/process_data/clean_histogram.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/process_data\n",
            "copying fairseq/examples/m2m_100/process_data/dedup_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/process_data\n",
            "copying fairseq/examples/m2m_100/process_data/remove_too_much_punc.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/process_data\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/tokenize_indic.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/tokenize_thai.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/tokenize_zh.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/seg_ko.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/seg_ja.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/tokenizer_ar.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers/thirdparty\n",
            "copying fairseq/examples/m2m_100/tokenizers/thirdparty/.gitignore -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers/thirdparty\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.race.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/multiprocessing_bpe_encoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.custom_classification.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/preprocess_RACE.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.pretraining.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/preprocess_GLUE_tasks.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.glue.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/preprocess_RACE.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/fb_multilingual\n",
            "copying fairseq/examples/roberta/fb_multilingual/README.multilingual.pretraining.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/fb_multilingual\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/pretraining\n",
            "copying fairseq/examples/roberta/config/pretraining/base.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/pretraining\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/local.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/slurm_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/slurm_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/slurm_4.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/pretraining/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/sst_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/mnli.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/qnli.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/sts_b.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/mrpc.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/qqp.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/rte.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/cola.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning/run_config\n",
            "copying fairseq/examples/roberta/config/finetuning/run_config/local.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning/run_config\n",
            "copying fairseq/examples/roberta/config/finetuning/run_config/slurm_1g.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning/run_config\n",
            "copying fairseq/examples/roberta/config/finetuning/run_config/slurm_1g_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/wsc_criterion.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/wsc_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/wsc_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/wsc\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/commonsense_qa\n",
            "copying fairseq/examples/roberta/commonsense_qa/commonsense_qa_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/commonsense_qa\n",
            "copying fairseq/examples/roberta/commonsense_qa/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/commonsense_qa\n",
            "copying fairseq/examples/roberta/commonsense_qa/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/commonsense_qa\n",
            "copying fairseq/examples/roberta/commonsense_qa/download_cqa_data.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/commonsense_qa\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/conv_seq2seq\n",
            "copying fairseq/examples/conv_seq2seq/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/conv_seq2seq\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/stories\n",
            "copying fairseq/examples/stories/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/stories\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/flores101\n",
            "copying fairseq/examples/flores101/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/flores101\n",
            "copying fairseq/examples/flores101/flores_logo.png -> build/lib.linux-x86_64-cpython-310/fairseq/examples/flores101\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/womens_bios\n",
            "copying fairseq/examples/womens_bios/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/womens_bios\n",
            "copying fairseq/examples/womens_bios/query_occupations_from_wikidata.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/womens_bios\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/nonautoregressive_translation\n",
            "copying fairseq/examples/nonautoregressive_translation/scripts.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/nonautoregressive_translation\n",
            "copying fairseq/examples/nonautoregressive_translation/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/nonautoregressive_translation\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/xformers\n",
            "copying fairseq/examples/xformers/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/xformers\n",
            "copying fairseq/examples/wav2vec/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/xlsr\n",
            "copying fairseq/examples/wav2vec/xlsr/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/xlsr\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/xlsr/scripts\n",
            "copying fairseq/examples/wav2vec/xlsr/scripts/eval_speaker_clf_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/xlsr/scripts\n",
            "copying fairseq/examples/wav2vec/xlsr/scripts/gen_audio_embedding.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/xlsr/scripts\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/xlsr/config\n",
            "copying fairseq/examples/wav2vec/xlsr/config/finetune.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/xlsr/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/scripts\n",
            "copying fairseq/examples/wav2vec/scripts/binarize_manifest.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/filter_lexicon.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/phonemize_with_sil.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/copy_labels.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/normalize_text.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/vads.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wav2vec_cluster_faiss.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/pca.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/prepare_timit.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/normalize_and_filter_text.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wav2vec_apply_cluster_faiss.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/prepare_audio_v2.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/g2p_wrd_to_phn.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/merge_clusters.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/filter_tsv.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/mean_pool.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wav2vec_extract_features.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/remove_silence.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/prepare_text.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wrd_to_ltr.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/apply_pca.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/ltr_to_wrd.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/prepare_audio.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_matched/test.uid -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_matched/train_text.uid -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_matched/valid.uid -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_matched/train.uid -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/test.uid -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/train_text.uid -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/valid.uid -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/train.uid -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/gan/w2vu.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/gan/w2vu2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/gan\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/generate\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/generate/viterbi.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/generate\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/finetuning\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/finetuning/w2v_finetune.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/finetuning\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/path.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/cmd.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/decode_phone.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/decode_word_step1.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/decode_word_step2.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/train.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/train_lda_mllt.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/train_sat.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/train_deltas.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/score.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/train_subset_lgbeam.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/show_wer.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/unsup_select.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_lang_word.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_data_from_w2v.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_lm.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/decode.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/copy_aligned_text.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/unsup_select_decode.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_lang.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/unsup_select_decode_word.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_conformer_large_librivox.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_conformer_base_librispeech.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox_tpu-pod.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_base_librispeech.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox_tpu.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/pretraining\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_960h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10m_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_100h_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_10h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_960h_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_100h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_960h_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_100h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_100h_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_960h_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_100h_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10m.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10m_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h_aws_v100.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_4.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_10m.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_1h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10m_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_960h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_4g.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_1_old.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_4g_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_2g.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_8.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_16.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/speech_text_joint_to_text/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/data\n",
            "copying fairseq/examples/speech_text_joint_to_text/data/pair_denoising_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/data\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/docs\n",
            "copying fairseq/examples/speech_text_joint_to_text/docs/pre-training.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/docs\n",
            "copying fairseq/examples/speech_text_joint_to_text/docs/iwslt2021.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/docs\n",
            "copying fairseq/examples/speech_text_joint_to_text/docs/ende-mustc.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/docs\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/configs\n",
            "copying fairseq/examples/speech_text_joint_to_text/configs/mustc_noise.list -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/configs\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/scripts\n",
            "copying fairseq/examples/speech_text_joint_to_text/scripts/g2p_encode.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/scripts\n",
            "copying fairseq/examples/speech_text_joint_to_text/scripts/convert_model.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/scripts\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/sacrebleu.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/tokenized_bleu.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/prepare-wmt18en2de.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/deduplicate_lines.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/extract_bt_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/prepare-de-monolingual.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/backtranslation\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/unsupervised_quality_estimation\n",
            "copying fairseq/examples/unsupervised_quality_estimation/meteor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/unsupervised_quality_estimation\n",
            "copying fairseq/examples/unsupervised_quality_estimation/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/unsupervised_quality_estimation\n",
            "copying fairseq/examples/unsupervised_quality_estimation/repeat_lines.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/unsupervised_quality_estimation\n",
            "copying fairseq/examples/unsupervised_quality_estimation/aggregate_scores.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/unsupervised_quality_estimation\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection\n",
            "copying fairseq/examples/attention_head_selection/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src\n",
            "copying fairseq/examples/attention_head_selection/src/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src\n",
            "copying fairseq/examples/attention_head_selection/src/speech_to_text_head_selection.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/models\n",
            "copying fairseq/examples/attention_head_selection/src/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/models\n",
            "copying fairseq/examples/attention_head_selection/src/models/head_selection_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/models\n",
            "copying fairseq/examples/attention_head_selection/src/models/head_selection_s2t_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/data\n",
            "copying fairseq/examples/attention_head_selection/src/data/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/data\n",
            "copying fairseq/examples/attention_head_selection/src/data/speech_to_text_dataset_with_domain.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/data\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/loss\n",
            "copying fairseq/examples/attention_head_selection/src/loss/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/loss\n",
            "copying fairseq/examples/attention_head_selection/src/loss/attention_head_selection.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/loss\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/multihead_functional.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/attn_head_selector.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/multihead_attention_selection.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/head_selection_transformer_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/language_model\n",
            "copying fairseq/examples/language_model/README.adaptive_inputs.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/language_model\n",
            "copying fairseq/examples/language_model/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/language_model\n",
            "copying fairseq/examples/language_model/prepare-wikitext-103.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/language_model\n",
            "copying fairseq/examples/language_model/README.conv.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/language_model\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/constrained_decoding\n",
            "copying fairseq/examples/constrained_decoding/tok.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/constrained_decoding\n",
            "copying fairseq/examples/constrained_decoding/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/constrained_decoding\n",
            "copying fairseq/examples/constrained_decoding/normalize.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/constrained_decoding\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms\n",
            "copying fairseq/examples/mms/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms\n",
            "copying fairseq/examples/mms/MODEL_CARD.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/data_prep\n",
            "copying fairseq/examples/mms/data_prep/align_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/data_prep\n",
            "copying fairseq/examples/mms/data_prep/norm_config.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/data_prep\n",
            "copying fairseq/examples/mms/data_prep/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/data_prep\n",
            "copying fairseq/examples/mms/data_prep/punctuations.lst -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/data_prep\n",
            "copying fairseq/examples/mms/data_prep/align_and_segment.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/data_prep\n",
            "copying fairseq/examples/mms/data_prep/text_normalization.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/data_prep\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/lid\n",
            "copying fairseq/examples/mms/lid/infer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/lid\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/lid/tutorial\n",
            "copying fairseq/examples/mms/lid/tutorial/MMS_LID_Inference_Colab.ipynb -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/lid/tutorial\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/misc\n",
            "copying fairseq/examples/mms/misc/get_sample_size.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/misc\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/asr\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/asr/infer\n",
            "copying fairseq/examples/mms/asr/infer/mms_infer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/asr/infer\n",
            "copying fairseq/examples/mms/asr/infer/example_infer_adapter.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/asr/infer\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/asr/config\n",
            "copying fairseq/examples/mms/asr/config/infer_common.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/asr/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/asr/tutorial\n",
            "copying fairseq/examples/mms/asr/tutorial/MMS_ASR_Inference_Colab.ipynb -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/asr/tutorial\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/tts\n",
            "copying fairseq/examples/mms/tts/infer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/tts\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/tts/tutorial\n",
            "copying fairseq/examples/mms/tts/tutorial/MMS_TTS_Inference_Colab.ipynb -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/tts/tutorial\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/gottbert\n",
            "copying fairseq/examples/gottbert/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/gottbert\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt20\n",
            "copying fairseq/examples/wmt20/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt20\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion\n",
            "copying fairseq/examples/emotion_conversion/requirements.txt -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion\n",
            "copying fairseq/examples/emotion_conversion/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion\n",
            "copying fairseq/examples/emotion_conversion/synthesize.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/duration_predictor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/pitch_predictor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/duration_predictor.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/pitch_predictor.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/emotion_models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/create_core_manifest.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/build_hifigan_manifest.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/extract_f0.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/split_emov_km_tsv_by_uttid.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/split_km_tsv.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/process_km.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/build_translation_manifests.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/split_km.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/fairseq_models\n",
            "copying fairseq/examples/emotion_conversion/fairseq_models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/fairseq_models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/xmod\n",
            "copying fairseq/examples/xmod/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/xmod\n",
            "copying fairseq/examples/xmod/preprocess_nli.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/xmod\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/scaling_nmt\n",
            "copying fairseq/examples/scaling_nmt/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/scaling_nmt\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt21\n",
            "copying fairseq/examples/wmt21/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt21\n",
            "copying fairseq/examples/wmt21/eval.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt21\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt21/scripts\n",
            "copying fairseq/examples/wmt21/scripts/replace-unicode-punctuation.perl -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt21/scripts\n",
            "copying fairseq/examples/wmt21/scripts/normalize-punctuation.perl -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt21/scripts\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/inference_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/truncated_laplace.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/quantize_f0.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/data_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/naive_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/generate_waveform.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/prepare_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/preprocess_f0.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/eval\n",
            "copying fairseq/examples/textless_nlp/pgslm/eval/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/eval\n",
            "copying fairseq/examples/textless_nlp/pgslm/eval/cont_metrics.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/eval\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/sample\n",
            "copying fairseq/examples/textless_nlp/pgslm/sample/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/sample\n",
            "copying fairseq/examples/textless_nlp/pgslm/sample/sample.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/sample\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/scripts\n",
            "copying fairseq/examples/textless_nlp/pgslm/scripts/prepare_f0_quantization.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/scripts\n",
            "copying fairseq/examples/textless_nlp/pgslm/scripts/prepare_data.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/scripts\n",
            "copying fairseq/examples/textless_nlp/pgslm/scripts/join_units_manifest.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/scripts\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm\n",
            "copying fairseq/examples/textless_nlp/dgslm/create_code_file.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm\n",
            "copying fairseq/examples/textless_nlp/dgslm/sample_speech_dlm.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm\n",
            "copying fairseq/examples/textless_nlp/dgslm/dgslm_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm\n",
            "copying fairseq/examples/textless_nlp/dgslm/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm/vocoder_hifigan\n",
            "copying fairseq/examples/textless_nlp/dgslm/vocoder_hifigan/generate_stereo_waveform.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm/vocoder_hifigan\n",
            "copying fairseq/examples/textless_nlp/dgslm/vocoder_hifigan/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm/vocoder_hifigan\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm/hubert_fisher\n",
            "copying fairseq/examples/textless_nlp/dgslm/hubert_fisher/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm/hubert_fisher\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/speech-resynth\n",
            "copying fairseq/examples/textless_nlp/speech-resynth/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/speech-resynth\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/speech-resynth/img\n",
            "copying fairseq/examples/textless_nlp/speech-resynth/img/fig.png -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/speech-resynth/img\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm\n",
            "copying fairseq/examples/textless_nlp/gslm/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/hubert_feature_reader.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/cpc_feature_reader.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/w2v2_feature_reader.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/logmel_feature_reader.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/quantize_with_kmeans.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/cluster_kmeans.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/dump_feats.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/tools\n",
            "copying fairseq/examples/textless_nlp/gslm/tools/resynthesize_speech.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/tools\n",
            "copying fairseq/examples/textless_nlp/gslm/tools/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/tools\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/abx_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/abx_metrics/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/abx_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/abx_metrics/dump_abx_feats.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/abx_metrics\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/self_auto_bleu.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/ppx.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/continuation_eval.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/cut_as.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/bleu_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/dict.ltr.txt -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/ulm\n",
            "copying fairseq/examples/textless_nlp/gslm/ulm/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/ulm\n",
            "copying fairseq/examples/textless_nlp/gslm/ulm/sample.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/ulm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/glow.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/convert_to_16k.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/multiproc.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/synthesize_audio_from_units.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tts_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/cmudict.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/numbers.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/stft.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/audio_processing.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/waveglow_denoiser.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/layers.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/symbols.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/text.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/cleaners.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/fully_sharded_data_parallel\n",
            "copying fairseq/examples/fully_sharded_data_parallel/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/fully_sharded_data_parallel\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth\n",
            "copying fairseq/examples/latent_depth/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/multilingual_translation_latent_depth.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/models\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/models\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/models/latent_multilingual_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/models\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/models/latent_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/loss\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/loss/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/loss\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/loss/latent_depth.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/loss\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/modules\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/modules\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/modules/latent_layers.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/criss\n",
            "copying fairseq/examples/criss/save_encoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/criss\n",
            "copying fairseq/examples/criss/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/criss\n",
            "copying fairseq/examples/criss/download_and_preprocess_flores_test.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/criss\n",
            "copying fairseq/examples/criss/download_and_preprocess_tatoeba.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/criss\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/criss/unsupervised_mt\n",
            "copying fairseq/examples/criss/unsupervised_mt/eval.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/criss/unsupervised_mt\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/criss/mining\n",
            "copying fairseq/examples/criss/mining/mine_example.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/criss/mining\n",
            "copying fairseq/examples/criss/mining/mine.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/criss/mining\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/criss/sentence_retrieval\n",
            "copying fairseq/examples/criss/sentence_retrieval/sentence_retrieval_tatoeba.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/criss/sentence_retrieval\n",
            "copying fairseq/examples/criss/sentence_retrieval/encoder_analysis.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/criss/sentence_retrieval\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/prepare-iwslt14.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/prepare-wmt14en2fr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/prepare-iwslt17-multilingual.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/prepare-wmt14en2de.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/translation_moe\n",
            "copying fairseq/examples/translation_moe/score.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation_moe\n",
            "copying fairseq/examples/translation_moe/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation_moe\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/translation_moe/translation_moe_src\n",
            "copying fairseq/examples/translation_moe/translation_moe_src/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation_moe/translation_moe_src\n",
            "copying fairseq/examples/translation_moe/translation_moe_src/logsumexp_moe.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation_moe/translation_moe_src\n",
            "copying fairseq/examples/translation_moe/translation_moe_src/mean_pool_gating_network.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation_moe/translation_moe_src\n",
            "copying fairseq/examples/translation_moe/translation_moe_src/translation_moe.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation_moe/translation_moe_src\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/alignment_train_kernel.cu -> build/lib.linux-x86_64-cpython-310/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/utils.h -> build/lib.linux-x86_64-cpython-310/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/alignment_train_cuda.h -> build/lib.linux-x86_64-cpython-310/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/alignment_train_cuda.cpp -> build/lib.linux-x86_64-cpython-310/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/alignment_train_cpu.cpp -> build/lib.linux-x86_64-cpython-310/fairseq/examples/operators\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/moe_lm\n",
            "copying fairseq/examples/moe_lm/model_card.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/moe_lm\n",
            "copying fairseq/examples/moe_lm/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/moe_lm\n",
            "copying fairseq/examples/moe_lm/data_card.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/moe_lm\n",
            "copying fairseq/examples/data2vec/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts\n",
            "copying fairseq/examples/data2vec/scripts/convert_audioset_labels.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_char_fair_aws_local_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_local_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep_aws_local_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_large_fair_local_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_large_fair_nodep_aws_local_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep_aws_lr_nopos.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_aws_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_aws_local_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/glue.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_large_fair_aws_local_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_sst2_qnli_sweep_fair_nodep.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/valids.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/glue_lr.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep_aws_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/unprocess_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep_aws.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_aws.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/multi\n",
            "copying fairseq/examples/data2vec/scripts/multi/finetune_all_fair_local_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/multi\n",
            "copying fairseq/examples/data2vec/scripts/multi/finetune_all_fair_aws_local_lr_nodep.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/multi\n",
            "copying fairseq/examples/data2vec/scripts/multi/finetune_all_fair_aws_local_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/multi\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/large_images_only_task.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/huge_images14_only_task.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/base_images_only_task.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/large_text_only_task_pgrp_1M.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/huge_images_only_task.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/large_audio_only_task.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/large_text_only_task.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/base_text_only_task.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/base_audio_only_task.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/local.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_8.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_4.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_6_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/sst_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/mnli.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/qnli.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/sts_b.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/mrpc.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/qqp.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/rte.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/cola.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/run_config/local.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/base_librispeech.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/audioset.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/local.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_4.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_6_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/classification\n",
            "copying fairseq/examples/data2vec/config/audio/classification/base_classification.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/classification\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/classification/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/classification/run_config/slurm_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/classification/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/classification/run_config/slurm_1g.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/classification/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/classification/run_config/slurm_1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/classification/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/base.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/local.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_4.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/base_mae_imagenet.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/base_imagenet.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/base_imagenet_d2v1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/local.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_4.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_6_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/imagenet.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/mae_imagenet_clean.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/mae_imagenet_large_clean.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/mae_imagenet_huge_clean.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/local.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_4.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_6_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/pointer_generator\n",
            "copying fairseq/examples/pointer_generator/README.xsum.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/pointer_generator\n",
            "copying fairseq/examples/pointer_generator/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/pointer_generator\n",
            "copying fairseq/examples/pointer_generator/postprocess.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/pointer_generator\n",
            "copying fairseq/examples/pointer_generator/preprocess.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/pointer_generator\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/pointer_generator/pointer_generator_src\n",
            "copying fairseq/examples/pointer_generator/pointer_generator_src/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/pointer_generator/pointer_generator_src\n",
            "copying fairseq/examples/pointer_generator/pointer_generator_src/transformer_pg.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/pointer_generator/pointer_generator_src\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/normformer\n",
            "copying fairseq/examples/normformer/train_lm.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/normformer\n",
            "copying fairseq/examples/normformer/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/normformer\n",
            "copying fairseq/examples/adaptive_span/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/adaptive_span\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/laser\n",
            "copying fairseq/examples/laser/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/laser\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/laser_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/laser_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/multitask_data_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/laser_lstm.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/laser/laser_src\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/layerdrop\n",
            "copying fairseq/examples/layerdrop/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/layerdrop\n",
            "copying fairseq/examples/noisychannel/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer\n",
            "copying fairseq/examples/linformer/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src\n",
            "copying fairseq/examples/linformer/linformer_src/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src/models\n",
            "copying fairseq/examples/linformer/linformer_src/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src/models\n",
            "copying fairseq/examples/linformer/linformer_src/models/linformer_roberta.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src/modules\n",
            "copying fairseq/examples/linformer/linformer_src/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src/modules\n",
            "copying fairseq/examples/linformer/linformer_src/modules/linformer_sentence_encoder_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src/modules\n",
            "copying fairseq/examples/linformer/linformer_src/modules/multihead_linear_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src/modules\n",
            "copying fairseq/examples/linformer/linformer_src/modules/linformer_sentence_encoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/cross_lingual_language_model\n",
            "copying fairseq/examples/cross_lingual_language_model/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/cross_lingual_language_model\n",
            "copying fairseq/examples/speech_synthesis/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/docs\n",
            "copying fairseq/examples/speech_synthesis/docs/vctk_example.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/docs\n",
            "copying fairseq/examples/speech_synthesis/docs/common_voice_example.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/docs\n",
            "copying fairseq/examples/speech_synthesis/docs/ljspeech_example.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/docs\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert\n",
            "copying fairseq/examples/mr_hubert/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert\n",
            "copying fairseq/examples/mr_hubert/train.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert\n",
            "copying fairseq/examples/mr_hubert/decode.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert\n",
            "copying fairseq/examples/mr_hubert/finetune.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/simple_kmeans\n",
            "copying fairseq/examples/mr_hubert/simple_kmeans/dump_hubert_feature_s2t.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/simple_kmeans\n",
            "copying fairseq/examples/mr_hubert/simple_kmeans/learn_kmeans.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/simple_kmeans\n",
            "copying fairseq/examples/mr_hubert/simple_kmeans/dump_w2v2_feature.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/simple_kmeans\n",
            "copying fairseq/examples/mr_hubert/simple_kmeans/dump_hubert_feature.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/simple_kmeans\n",
            "copying fairseq/examples/mr_hubert/simple_kmeans/dump_km_label.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/simple_kmeans\n",
            "copying fairseq/examples/mr_hubert/simple_kmeans/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/simple_kmeans\n",
            "copying fairseq/examples/mr_hubert/simple_kmeans/feature_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/simple_kmeans\n",
            "copying fairseq/examples/mr_hubert/simple_kmeans/dump_mfcc_feature.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/simple_kmeans\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/finetune\n",
            "copying fairseq/examples/mr_hubert/config/finetune/base_1h_large.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/finetune\n",
            "copying fairseq/examples/mr_hubert/config/finetune/base_10h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/finetune\n",
            "copying fairseq/examples/mr_hubert/config/finetune/base_100h_large.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/finetune\n",
            "copying fairseq/examples/mr_hubert/config/finetune/base_100h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/finetune\n",
            "copying fairseq/examples/mr_hubert/config/finetune/base_10h_large.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/finetune\n",
            "copying fairseq/examples/mr_hubert/config/finetune/base_1h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/finetune\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/pretrain\n",
            "copying fairseq/examples/mr_hubert/config/pretrain/mrhubert_large_librilight.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/pretrain\n",
            "copying fairseq/examples/mr_hubert/config/pretrain/mrhubert_base_librispeech.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/pretrain\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/pretrain/run\n",
            "copying fairseq/examples/mr_hubert/config/pretrain/run/submitit_reg.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/pretrain/run\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/decode\n",
            "copying fairseq/examples/mr_hubert/config/decode/infer.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/decode\n",
            "copying fairseq/examples/mr_hubert/config/decode/infer_lm.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/decode\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/decode/run\n",
            "copying fairseq/examples/mr_hubert/config/decode/run/submitit_slurm_8gpu.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/decode/run\n",
            "copying fairseq/examples/mr_hubert/config/decode/run/submitit_slurm.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/decode/run\n",
            "copying fairseq/examples/speech_to_speech/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/docs\n",
            "copying fairseq/examples/speech_to_speech/docs/direct_s2st_discrete_units.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/docs\n",
            "copying fairseq/examples/speech_to_speech/docs/textless_s2st_real_data.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/docs\n",
            "copying fairseq/examples/speech_to_speech/docs/data_augmentation.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/docs\n",
            "copying fairseq/examples/speech_to_speech/docs/enhanced_direct_s2st_discrete_units.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/docs\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/core.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/data_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/get_metrics.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/configs/3StageS2ST.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/configs/DirectS2U.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/configs/2StageS2ST.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/configs/S2T.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "copying fairseq/examples/speech_to_speech/asr_bleu/asr_model_cfgs.json -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/asr_bleu\n",
            "copying fairseq/examples/speech_to_speech/asr_bleu/requirements.txt -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/asr_bleu\n",
            "copying fairseq/examples/speech_to_speech/asr_bleu/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/asr_bleu\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/xglm\n",
            "copying fairseq/examples/xglm/model_card.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/xglm\n",
            "copying fairseq/examples/xglm/XStoryCloze.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/xglm\n",
            "copying fairseq/examples/xglm/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/xglm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/audio_nlp\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/audio_nlp/nlu\n",
            "copying fairseq/examples/audio_nlp/nlu/generate_manifests.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/audio_nlp/nlu\n",
            "copying fairseq/examples/audio_nlp/nlu/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/audio_nlp/nlu\n",
            "copying fairseq/examples/audio_nlp/nlu/create_dict_stop.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/audio_nlp/nlu\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/audio_nlp/nlu/configs\n",
            "copying fairseq/examples/audio_nlp/nlu/configs/nlu_finetuning.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/audio_nlp/nlu/configs\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/locallaunch.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/endtask.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/vlm.png -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/videoclip.png -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/pretraining.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/.gitignore -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/CONFIG.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/setup.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/DATASET.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt_cli\n",
            "copying fairseq/examples/MMPT/mmpt_cli/predict.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt_cli\n",
            "copying fairseq/examples/MMPT/mmpt_cli/localjob.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt_cli\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/model.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/shard_feature.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/random_sequence_shuffler.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/preprocessing.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/pathbuilder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/extract.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/videoreader.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor/how2\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/how2/s3d.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor/how2\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/text_token_extractor\n",
            "copying fairseq/examples/MMPT/scripts/text_token_extractor/pretokenization.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/text_token_extractor\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/text_token_extractor/configs\n",
            "copying fairseq/examples/MMPT/scripts/text_token_extractor/configs/bert-base-uncased.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/text_token_extractor/configs\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects\n",
            "copying fairseq/examples/MMPT/projects/mfmmlm.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm\n",
            "copying fairseq/examples/MMPT/projects/mtm/mmfusionmtm.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/youcookcap.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_coin.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_crosstask_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/youcook.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/vtt.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_youcook.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/crosstask.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_youcookcap.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/coin.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_vttqa.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/how2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_vtt.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_crosstask.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/vttqa.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri\n",
            "copying fairseq/examples/MMPT/projects/retri/videoretri.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_youcook_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_youcook_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_vttqa_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_didemo_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/coin_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_vttqa_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/vttqa_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_coin_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/crosstask_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/vtt_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_crosstask_zs_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/how2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_vtt_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_crosstask_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_vtt_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/youcook_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_coin_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_youcook_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/ft.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_youcook_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/youcookcap.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vttqa_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_didemo_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/coin_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_coin.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vttqa_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/vttqa_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_coin_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_crosstask_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/crosstask_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/youcook.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/vtt_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/vtt.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_youcook.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_crosstask_zs_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/crosstask.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/default.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_youcookcap.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/coin.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vttqa.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/how2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vtt_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_crosstask_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vtt.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_crosstask.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vtt_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/youcook_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/vttqa.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_coin_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt\n",
            "copying fairseq/examples/MMPT/mmpt/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/transformermodel.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/mmfusion.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/fairseqmmmodel.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/mmfusionnlg.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/datasets\n",
            "copying fairseq/examples/MMPT/mmpt/datasets/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/datasets\n",
            "copying fairseq/examples/MMPT/mmpt/datasets/mmdataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/datasets\n",
            "copying fairseq/examples/MMPT/mmpt/datasets/fairseqmmdataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/datasets\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/losses\n",
            "copying fairseq/examples/MMPT/mmpt/losses/nce.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/losses\n",
            "copying fairseq/examples/MMPT/mmpt/losses/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/losses\n",
            "copying fairseq/examples/MMPT/mmpt/losses/loss.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/losses\n",
            "copying fairseq/examples/MMPT/mmpt/losses/fairseqmmloss.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/losses\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/utils\n",
            "copying fairseq/examples/MMPT/mmpt/utils/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/utils\n",
            "copying fairseq/examples/MMPT/mmpt/utils/load_config.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/utils\n",
            "copying fairseq/examples/MMPT/mmpt/utils/shardedtensor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/utils\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/dsprocessor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/how2processor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/how2retriprocessor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/dedupprocessor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/processor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/processors\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/processors/models\n",
            "copying fairseq/examples/MMPT/mmpt/processors/models/s3dg.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/processors/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/modules\n",
            "copying fairseq/examples/MMPT/mmpt/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/modules\n",
            "copying fairseq/examples/MMPT/mmpt/modules/retri.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/modules\n",
            "copying fairseq/examples/MMPT/mmpt/modules/mm.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/modules\n",
            "copying fairseq/examples/MMPT/mmpt/modules/vectorpool.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/evaluators\n",
            "copying fairseq/examples/MMPT/mmpt/evaluators/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/evaluators\n",
            "copying fairseq/examples/MMPT/mmpt/evaluators/evaluator.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/evaluators\n",
            "copying fairseq/examples/MMPT/mmpt/evaluators/predictor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/evaluators\n",
            "copying fairseq/examples/MMPT/mmpt/evaluators/metric.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/evaluators\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/retritask.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/task.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/fairseqmmtask.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/vlmtask.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/milncetask.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/tasks\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/shuffled_word_order\n",
            "copying fairseq/examples/shuffled_word_order/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/shuffled_word_order\n",
            "copying fairseq/examples/shuffled_word_order/README.finetuning.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/shuffled_word_order\n",
            "copying fairseq/examples/fast_noisy_channel/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/fast_noisy_channel\n",
            "copying fairseq/config/config.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/config/model\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/config/model/wav2vec2\n",
            "copying fairseq/config/model/wav2vec2/wav2vec2_large.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/wav2vec2\n",
            "copying fairseq/config/model/wav2vec2/wav2vec2_base.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/wav2vec2\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/config/model/wav2vec\n",
            "copying fairseq/config/model/wav2vec/vq_wav2vec_gumbel.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/wav2vec\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_baevski_gbw.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gpt2_small.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_baevski_wiki103.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gpt.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_big.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_wiki103.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gpt2_big.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gpt2_medium.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gbw.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/config/fb_run_config\n",
            "copying fairseq/config/fb_run_config/slurm.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/fb_run_config\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:500: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "building 'fairseq.libbleu' extension\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "creating build/temp.linux-x86_64-cpython-310/fairseq\n",
            "creating build/temp.linux-x86_64-cpython-310/fairseq/clib\n",
            "creating build/temp.linux-x86_64-cpython-310/fairseq/clib/libbleu\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/python3.10 -c fairseq/clib/libbleu/libbleu.cpp -o build/temp.linux-x86_64-cpython-310/fairseq/clib/libbleu/libbleu.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/python3.10 -c fairseq/clib/libbleu/module.cpp -o build/temp.linux-x86_64-cpython-310/fairseq/clib/libbleu/module.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/fairseq/clib/libbleu/libbleu.o build/temp.linux-x86_64-cpython-310/fairseq/clib/libbleu/module.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-310/fairseq/libbleu.cpython-310-x86_64-linux-gnu.so\n",
            "building 'fairseq.data.data_utils_fast' extension\n",
            "creating build/temp.linux-x86_64-cpython-310/fairseq/data\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I/usr/include/python3.10 -c fairseq/data/data_utils_fast.cpp -o build/temp.linux-x86_64-cpython-310/fairseq/data/data_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=data_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1929\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/arrayobject.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kfairseq/data/data_utils_fast.cpp:1273\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wcpp\u0007-Wcpp\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/fairseq/data/data_utils_fast.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-310/fairseq/data/data_utils_fast.cpython-310-x86_64-linux-gnu.so\n",
            "building 'fairseq.data.token_block_utils_fast' extension\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I/usr/include/python3.10 -c fairseq/data/token_block_utils_fast.cpp -o build/temp.linux-x86_64-cpython-310/fairseq/data/token_block_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=token_block_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1929\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/arrayobject.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kfairseq/data/token_block_utils_fast.cpp:1274\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wcpp\u0007-Wcpp\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/fairseq/data/token_block_utils_fast.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-310/fairseq/data/token_block_utils_fast.cpython-310-x86_64-linux-gnu.so\n",
            "building 'fairseq.libbase' extension\n",
            "creating build/temp.linux-x86_64-cpython-310/fairseq/clib/libbase\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/include/python3.10 -c fairseq/clib/libbase/balanced_assignment.cpp -o build/temp.linux-x86_64-cpython-310/fairseq/clib/libbase/balanced_assignment.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=libbase -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/fairseq/clib/libbase/balanced_assignment.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-310/fairseq/libbase.cpython-310-x86_64-linux-gnu.so\n",
            "building 'fairseq.libnat' extension\n",
            "creating build/temp.linux-x86_64-cpython-310/fairseq/clib/libnat\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/include/python3.10 -c fairseq/clib/libnat/edit_dist.cpp -o build/temp.linux-x86_64-cpython-310/fairseq/clib/libnat/edit_dist.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=libnat -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/fairseq/clib/libnat/edit_dist.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-310/fairseq/libnat.cpython-310-x86_64-linux-gnu.so\n",
            "building 'alignment_train_cpu_binding' extension\n",
            "creating build/temp.linux-x86_64-cpython-310/examples\n",
            "creating build/temp.linux-x86_64-cpython-310/examples/operators\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/include/python3.10 -c examples/operators/alignment_train_cpu.cpp -o build/temp.linux-x86_64-cpython-310/examples/operators/alignment_train_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=alignment_train_cpu_binding -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = double]\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:131:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid free(void*)\u001b[m\u001b[K’ called on pointer returned from a mismatched allocation function [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmismatched-new-delete\u0007-Wmismatched-new-delete\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  131 |   \u001b[01;35m\u001b[Kfree(cumprod_1mp)\u001b[m\u001b[K;\n",
            "      |   \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:93:20:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kreturned from ‘\u001b[01m\u001b[Kvoid* operator new [](std::size_t)\u001b[m\u001b[K’\n",
            "   93 |   T* cumprod_1mp = \u001b[01;36m\u001b[Knew T[elements]\u001b[m\u001b[K;\n",
            "      |                    \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = double]\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:132:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid free(void*)\u001b[m\u001b[K’ called on pointer returned from a mismatched allocation function [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmismatched-new-delete\u0007-Wmismatched-new-delete\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  132 |   \u001b[01;35m\u001b[Kfree(cumprod_1mp_clamp)\u001b[m\u001b[K;\n",
            "      |   \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:94:26:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kreturned from ‘\u001b[01m\u001b[Kvoid* operator new [](std::size_t)\u001b[m\u001b[K’\n",
            "   94 |   T* cumprod_1mp_clamp = \u001b[01;36m\u001b[Knew T[elements]\u001b[m\u001b[K;\n",
            "      |                          \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = float]\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:131:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid free(void*)\u001b[m\u001b[K’ called on pointer returned from a mismatched allocation function [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmismatched-new-delete\u0007-Wmismatched-new-delete\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  131 |   \u001b[01;35m\u001b[Kfree(cumprod_1mp)\u001b[m\u001b[K;\n",
            "      |   \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:93:20:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kreturned from ‘\u001b[01m\u001b[Kvoid* operator new [](std::size_t)\u001b[m\u001b[K’\n",
            "   93 |   T* cumprod_1mp = \u001b[01;36m\u001b[Knew T[elements]\u001b[m\u001b[K;\n",
            "      |                    \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = float]\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:132:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid free(void*)\u001b[m\u001b[K’ called on pointer returned from a mismatched allocation function [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmismatched-new-delete\u0007-Wmismatched-new-delete\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  132 |   \u001b[01;35m\u001b[Kfree(cumprod_1mp_clamp)\u001b[m\u001b[K;\n",
            "      |   \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:94:26:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kreturned from ‘\u001b[01m\u001b[Kvoid* operator new [](std::size_t)\u001b[m\u001b[K’\n",
            "   94 |   T* cumprod_1mp_clamp = \u001b[01;36m\u001b[Knew T[elements]\u001b[m\u001b[K;\n",
            "      |                          \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = c10::Half]\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:131:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid free(void*)\u001b[m\u001b[K’ called on pointer returned from a mismatched allocation function [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmismatched-new-delete\u0007-Wmismatched-new-delete\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  131 |   \u001b[01;35m\u001b[Kfree(cumprod_1mp)\u001b[m\u001b[K;\n",
            "      |   \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:93:20:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kreturned from ‘\u001b[01m\u001b[Kvoid* operator new [](std::size_t)\u001b[m\u001b[K’\n",
            "   93 |   T* cumprod_1mp = \u001b[01;36m\u001b[Knew T[elements]\u001b[m\u001b[K;\n",
            "      |                    \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = c10::Half]\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:132:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid free(void*)\u001b[m\u001b[K’ called on pointer returned from a mismatched allocation function [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmismatched-new-delete\u0007-Wmismatched-new-delete\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  132 |   \u001b[01;35m\u001b[Kfree(cumprod_1mp_clamp)\u001b[m\u001b[K;\n",
            "      |   \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:94:26:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kreturned from ‘\u001b[01m\u001b[Kvoid* operator new [](std::size_t)\u001b[m\u001b[K’\n",
            "   94 |   T* cumprod_1mp_clamp = \u001b[01;36m\u001b[Knew T[elements]\u001b[m\u001b[K;\n",
            "      |                          \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = c10::BFloat16]\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:131:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid free(void*)\u001b[m\u001b[K’ called on pointer returned from a mismatched allocation function [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmismatched-new-delete\u0007-Wmismatched-new-delete\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  131 |   \u001b[01;35m\u001b[Kfree(cumprod_1mp)\u001b[m\u001b[K;\n",
            "      |   \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:93:20:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kreturned from ‘\u001b[01m\u001b[Kvoid* operator new [](std::size_t)\u001b[m\u001b[K’\n",
            "   93 |   T* cumprod_1mp = \u001b[01;36m\u001b[Knew T[elements]\u001b[m\u001b[K;\n",
            "      |                    \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = c10::BFloat16]\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:132:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid free(void*)\u001b[m\u001b[K’ called on pointer returned from a mismatched allocation function [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmismatched-new-delete\u0007-Wmismatched-new-delete\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  132 |   \u001b[01;35m\u001b[Kfree(cumprod_1mp_clamp)\u001b[m\u001b[K;\n",
            "      |   \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:94:26:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kreturned from ‘\u001b[01m\u001b[Kvoid* operator new [](std::size_t)\u001b[m\u001b[K’\n",
            "   94 |   T* cumprod_1mp_clamp = \u001b[01;36m\u001b[Knew T[elements]\u001b[m\u001b[K;\n",
            "      |                          \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/examples/operators/alignment_train_cpu.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-310/alignment_train_cpu_binding.cpython-310-x86_64-linux-gnu.so\n",
            "running develop\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  easy_install.initialize_options(self)\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running egg_info\n",
            "writing fairseq.egg-info/PKG-INFO\n",
            "writing dependency_links to fairseq.egg-info/dependency_links.txt\n",
            "writing entry points to fairseq.egg-info/entry_points.txt\n",
            "writing requirements to fairseq.egg-info/requires.txt\n",
            "writing top-level names to fairseq.egg-info/top_level.txt\n",
            "reading manifest file 'fairseq.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'fairseq.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "copying build/lib.linux-x86_64-cpython-310/fairseq/libbleu.cpython-310-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-cpython-310/fairseq/data/data_utils_fast.cpython-310-x86_64-linux-gnu.so -> fairseq/data\n",
            "copying build/lib.linux-x86_64-cpython-310/fairseq/data/token_block_utils_fast.cpython-310-x86_64-linux-gnu.so -> fairseq/data\n",
            "copying build/lib.linux-x86_64-cpython-310/fairseq/libbase.cpython-310-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-cpython-310/fairseq/libnat.cpython-310-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-cpython-310/alignment_train_cpu_binding.cpython-310-x86_64-linux-gnu.so -> \n",
            "Creating /usr/local/lib/python3.10/dist-packages/fairseq.egg-link (link to .)\n",
            "Adding fairseq 0.12.2 to easy-install.pth file\n",
            "Installing fairseq-eval-lm script to /usr/local/bin\n",
            "Installing fairseq-generate script to /usr/local/bin\n",
            "Installing fairseq-hydra-train script to /usr/local/bin\n",
            "Installing fairseq-interactive script to /usr/local/bin\n",
            "Installing fairseq-preprocess script to /usr/local/bin\n",
            "Installing fairseq-score script to /usr/local/bin\n",
            "Installing fairseq-train script to /usr/local/bin\n",
            "Installing fairseq-validate script to /usr/local/bin\n",
            "\n",
            "Installed /content/fairseq\n",
            "Processing dependencies for fairseq==0.12.2\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py\", line 3108, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/_vendor/packaging/requirements.py\", line 35, in __init__\n",
            "    parsed = parse_requirement(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/_vendor/packaging/_parser.py\", line 64, in parse_requirement\n",
            "    return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/_vendor/packaging/_parser.py\", line 82, in _parse_requirement\n",
            "    url, specifier, marker = _parse_requirement_details(tokenizer)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/_vendor/packaging/_parser.py\", line 120, in _parse_requirement_details\n",
            "    specifier = _parse_specifier(tokenizer)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/_vendor/packaging/_parser.py\", line 206, in _parse_specifier\n",
            "    with tokenizer.enclosing_tokens(\"LEFT_PARENTHESIS\", \"RIGHT_PARENTHESIS\"):\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 142, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/_vendor/packaging/_tokenizer.py\", line 183, in enclosing_tokens\n",
            "    self.raise_syntax_error(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/_vendor/packaging/_tokenizer.py\", line 163, in raise_syntax_error\n",
            "    raise ParserSyntaxError(\n",
            "pkg_resources.extern.packaging._tokenizer.ParserSyntaxError: Expected closing RIGHT_PARENTHESIS\n",
            "    PyYAML (>=5.1.*)\n",
            "           ~~~~~~^\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/fairseq/setup.py\", line 254, in <module>\n",
            "    do_setup(package_data)\n",
            "  File \"/content/fairseq/setup.py\", line 164, in do_setup\n",
            "    setup(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/__init__.py\", line 107, in setup\n",
            "    return distutils.core.setup(**attrs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
            "    return run_commands(dist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
            "    dist.run_commands()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n",
            "    self.run_command(cmd)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/dist.py\", line 1244, in run_command\n",
            "    super().run_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
            "    cmd_obj.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py\", line 34, in run\n",
            "    self.install_for_development()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py\", line 130, in install_for_development\n",
            "    self.process_distribution(None, self.dist, not self.no_deps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/command/easy_install.py\", line 750, in process_distribution\n",
            "    distros = WorkingSet([]).resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py\", line 832, in resolve\n",
            "    new_requirements = dist.requires(req.extras)[::-1]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py\", line 2821, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py\", line 3110, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py\", line 3173, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/_vendor/packaging/requirements.py\", line 37, in __init__\n",
            "    raise InvalidRequirement(str(e)) from e\n",
            "pkg_resources.extern.packaging.requirements.InvalidRequirement: Expected closing RIGHT_PARENTHESIS\n",
            "    PyYAML (>=5.1.*)\n",
            "           ~~~~~~^\n"
          ]
        }
      ],
      "source": [
        "!cd /content/fairseq && python setup.py build develop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5prhJ-gkK0P"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/SRC_AUDIO.zip -d /content\n",
        "!unzip /content/drive/MyDrive/TGT_AUDIO.zip -d /content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import soundfile as sf\n",
        "\n",
        "# Function to resample a single file\n",
        "def resample_wav(input_path, output_path, target_sr=22050):\n",
        "    y, sr = sf.read(input_path)\n",
        "    y_resampled = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
        "    sf.write(output_path, y_resampled, target_sr, subtype='PCM_16')\n",
        "\n",
        "# Function to resample all .wav files in a folder\n",
        "def resample_folder(input_folder, output_folder, target_sr=22050):\n",
        "    # Create output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Resample each .wav file in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".wav\"):\n",
        "            input_path = os.path.join(input_folder, filename)\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            resample_wav(input_path, output_path, target_sr)\n",
        "\n",
        "# Example usage:\n",
        "input_folder = \"/content/TGT_AUDIO_OLD/train\"\n",
        "output_folder = \"/content/TGT_AUDIO/train\"\n",
        "resample_folder(input_folder, output_folder)"
      ],
      "metadata": {
        "id": "ZkXLVAxj7qDh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "\n",
        "# Function to check the sampling rate of a .wav file\n",
        "def check_sampling_rate(file_path):\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "    return sr\n",
        "\n",
        "# Example usage:\n",
        "file_path = \"/content/TGT_AUDIO/train/1.wav\"\n",
        "sampling_rate = check_sampling_rate(file_path)\n",
        "print(\"Sampling rate:\", sampling_rate, \"Hz\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IqFBFv_8WxY",
        "outputId": "2e063bce-a8df-4523-f60f-40fa03bba3aa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling rate: 22050 Hz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#resampling done"
      ],
      "metadata": {
        "id": "fjTOINkq8rTL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EUIOJ4eZkhoi"
      },
      "outputs": [],
      "source": [
        "# tsv files\n",
        "!cd /content/fairseq && python examples/wav2vec/wav2vec_manifest.py /content/TGT_AUDIO/dev --dest /content/TGT_AUDIO/dev --ext wav --valid-percent 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SEV_MBPekofg"
      },
      "outputs": [],
      "source": [
        "!cd /content/fairseq && python examples/wav2vec/wav2vec_manifest.py /content/TGT_AUDIO/test --dest /content/TGT_AUDIO/test --ext wav --valid-percent 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "NZlehtcgkwMp"
      },
      "outputs": [],
      "source": [
        "!cd /content/fairseq && python examples/wav2vec/wav2vec_manifest.py /content/TGT_AUDIO/train --dest /content/TGT_AUDIO/train --ext wav --valid-percent 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VKpynOSak8IO"
      },
      "outputs": [],
      "source": [
        "!cd /content/fairseq && python examples/wav2vec/wav2vec_manifest.py /content/SRC_AUDIO/dev --dest /content/SRC_AUDIO/dev --ext wav --valid-percent 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fh6-Z6Ymk-PJ"
      },
      "outputs": [],
      "source": [
        "!cd /content/fairseq && python examples/wav2vec/wav2vec_manifest.py /content/SRC_AUDIO/train --dest /content/SRC_AUDIO/train --ext wav --valid-percent 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "F11scViAlBEN"
      },
      "outputs": [],
      "source": [
        "!cd /content/fairseq && python examples/wav2vec/wav2vec_manifest.py /content/SRC_AUDIO/test --dest /content/SRC_AUDIO/test --ext wav --valid-percent 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5IFVQf6l6bd"
      },
      "source": [
        "renaming al the train.tsv is also done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFNh9IgYl9Hy"
      },
      "outputs": [],
      "source": [
        "! cd /content/fairseq && python examples/textless_nlp/gslm/speech2unit/clustering/quantize_with_kmeans.py --feature_type hubert --kmeans_model_path /content/drive/MyDrive/km_100.bin --acoustic_model_path /content/drive/MyDrive/hubert_base_ls960.pt --layer 6 --manifest_path /content/TGT_AUDIO/dev/dev.tsv --out_quantized_file_path /content/TGT_AUDIO/dev.txt --extension \".wav\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxe2_GnXmSjx"
      },
      "outputs": [],
      "source": [
        "! cd /content/fairseq && python examples/textless_nlp/gslm/speech2unit/clustering/quantize_with_kmeans.py --feature_type hubert --kmeans_model_path /content/drive/MyDrive/km_100.bin --acoustic_model_path /content/drive/MyDrive/hubert_base_ls960.pt --layer 6 --manifest_path /content/TGT_AUDIO/test/test.tsv --out_quantized_file_path /content/TGT_AUDIO/test.txt --extension \".wav\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEJ72AP7mbkt"
      },
      "outputs": [],
      "source": [
        "! cd /content/fairseq && python examples/textless_nlp/gslm/speech2unit/clustering/quantize_with_kmeans.py --feature_type hubert --kmeans_model_path /content/drive/MyDrive/km_100.bin --acoustic_model_path /content/drive/MyDrive/hubert_base_ls960.pt --layer 6 --manifest_path /content/TGT_AUDIO/train/train.tsv --out_quantized_file_path /content/TGT_AUDIO/train.txt --extension \".wav\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -rf /content/DATA_ROOT"
      ],
      "metadata": {
        "id": "2z6xEYPYBe8H"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7-B51wn0hvS",
        "outputId": "16950dcd-bc89-46af-b420-e0d26b01e753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-22 09:05:53.786047: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-22 09:05:53.786098: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-22 09:05:53.787767: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-22 09:05:53.796489: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-22 09:05:55.211859: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX\n",
            "Processing train...\n",
            "100% 1215/1215 [00:00<00:00, 6038.07it/s]\n",
            "Processed 1215 samples\n",
            "Processing dev...\n",
            "100% 140/140 [00:00<00:00, 5502.58it/s]\n",
            "Processed 140 samples\n",
            "Processing test...\n",
            "100% 292/292 [00:00<00:00, 5814.25it/s]\n",
            "Processed 292 samples\n",
            "Extracting Mel spectrogram features...\n",
            "100% 1647/1647 [02:56<00:00,  9.32it/s]\n",
            "ZIPing features...\n",
            "100% 1647/1647 [00:08<00:00, 196.30it/s]\n",
            "Fetching ZIP manifest...\n",
            "100% 1647/1647 [00:00<00:00, 1704.08it/s]\n",
            "Generating manifest...\n",
            "Processing train...\n",
            "100% 1215/1215 [00:00<00:00, 1025368.08it/s]\n",
            "Writing manifest to /content/DATA_ROOT/train.tsv...\n",
            "Processing dev...\n",
            "100% 140/140 [00:00<00:00, 669558.22it/s]\n",
            "Writing manifest to /content/DATA_ROOT/dev.tsv...\n",
            "Processing test...\n",
            "100% 292/292 [00:00<00:00, 791685.05it/s]\n",
            "Writing manifest to /content/DATA_ROOT/test.tsv...\n"
          ]
        }
      ],
      "source": [
        "#spectrogram starting\n",
        "! cd /content/fairseq && python examples/speech_to_speech/preprocessing/prep_s2spect_data.py --source-dir /content/SRC_AUDIO --target-dir /content/TGT_AUDIO --data-split train dev test --output-root /content/DATA_ROOT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OG95f4Bi3vks"
      },
      "outputs": [],
      "source": [
        "# things i did before making the above cell work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oVQXl3k2WgS"
      },
      "outputs": [],
      "source": [
        "# basis = librosa.filters.mel(sample_rate, n_fft, n_mels, f_min, f_max)\n",
        "# TypeError: mel() takes 0 positional arguments but 5 were given\n",
        "\n",
        "# to overcome this error imma go to that file name and change a few things in the\n",
        "#/content/fairseq/fairseq/data/audio/audio_utils.py\n",
        "#in line: the change i did: 343 basis = librosa.filters.mel(sr=sample_rate,n_fft= n_fft,n_mels= n_mels, fmin=f_min, fmax=f_max\n",
        "# https://stackoverflow.com/questions/75796284/typeerror-mel-takes-0-positional-arguments-but-5-were-given\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbGxwp-a1RkA"
      },
      "outputs": [],
      "source": [
        "# installing this, since i got an error in the above cell\n",
        "!sudo apt install libsox-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKqHT5_S3HvR"
      },
      "outputs": [],
      "source": [
        "# writing into fodler\n",
        "!cp -r /content/DATA_ROOT /content/drive/MyDrive/attempt1_spectro"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "_________________________________________________________________"
      ],
      "metadata": {
        "id": "3VOL7iSOwAGY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "URtIwt2dKQvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0GA3bSx3Hs1",
        "outputId": "07f833df-043a-4d16-eabc-64307159d029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-22 09:46:00.527805: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-22 09:46:00.527873: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-22 09:46:00.529533: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-22 09:46:00.539336: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-22 09:46:01.910442: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-04-22 09:46:03 | INFO | numexpr.utils | NumExpr defaulting to 2 threads.\n",
            "2024-04-22 09:46:05 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-04-22 09:46:08 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 80000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'dev', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 30000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/content/SAVE_DIR_TRAINING', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'mcd_loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='speech_to_spectrogram', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', simul_type=None, scoring='bleu', task='speech_to_speech', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=80000, batch_size=None, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid='30000', batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2spect_transformer', max_epoch=0, max_update=400000, stop_time_hours=0, clip_norm=10.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/content/SAVE_DIR_TRAINING', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='mcd_loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/content/DATA_ROOT', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=3000, target_is_code=False, target_code_size=None, n_frames_per_step=5, eval_inference=True, eval_args='{}', eos_prob_threshold=0.5, mcd_normalize_type='targ', vocoder='griffin_lim', spec_bwd_max_iter=8, infer_target_lang='', bce_pos_weight=1.0, use_guided_attention_loss=False, guided_attention_loss_sigma=0.4, ctc_weight=0.0, adam_betas='(0.9,0.98)', adam_eps=1e-08, weight_decay=1e-06, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=1e-07, pad=1, eos=2, unk=3, decoder_normalize_before=True, dropout=0.1, attention_dropout=0.1, activation_dropout=0.1, no_seed_provided=False, encoder_freezing_updates=0, input_channels=1, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=12, encoder_attention_heads=8, encoder_normalize_before=True, no_scale_embedding=False, speaker_embed_dim=256, output_frame_dim=240, prenet_dropout=0.5, prenet_layers=2, prenet_dim=256, postnet_dropout=0.5, postnet_layers=5, postnet_conv_dim=512, postnet_conv_kernel_size=5, decoder_transformer_layers=6, decoder_embed_dim=512, decoder_ffn_embed_dim=2048, decoder_attention_heads=4, _name='s2spect_transformer'), 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='speech_to_spectrogram', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', simul_type=None, scoring='bleu', task='speech_to_speech', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=80000, batch_size=None, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid='30000', batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2spect_transformer', max_epoch=0, max_update=400000, stop_time_hours=0, clip_norm=10.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/content/SAVE_DIR_TRAINING', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='mcd_loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/content/DATA_ROOT', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=3000, target_is_code=False, target_code_size=None, n_frames_per_step=5, eval_inference=True, eval_args='{}', eos_prob_threshold=0.5, mcd_normalize_type='targ', vocoder='griffin_lim', spec_bwd_max_iter=8, infer_target_lang='', bce_pos_weight=1.0, use_guided_attention_loss=False, guided_attention_loss_sigma=0.4, ctc_weight=0.0, adam_betas='(0.9,0.98)', adam_eps=1e-08, weight_decay=1e-06, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=1e-07, pad=1, eos=2, unk=3, decoder_normalize_before=True, dropout=0.1, attention_dropout=0.1, activation_dropout=0.1, no_seed_provided=False, encoder_freezing_updates=0, input_channels=1, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=12, encoder_attention_heads=8, encoder_normalize_before=True, no_scale_embedding=False, speaker_embed_dim=256, output_frame_dim=240, prenet_dropout=0.5, prenet_layers=2, prenet_dim=256, postnet_dropout=0.5, postnet_layers=5, postnet_conv_dim=512, postnet_conv_kernel_size=5, decoder_transformer_layers=6, decoder_embed_dim=512, decoder_ffn_embed_dim=2048, decoder_attention_heads=4, _name='speech_to_speech'), 'criterion': {'_name': 'speech_to_spectrogram', 'bce_pos_weight': 1.0, 'use_guided_attention_loss': False, 'guided_attention_loss_sigma': 0.4, 'ctc_weight': 0.0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 1e-06, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 10000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
            "2024-04-22 09:46:10 | INFO | fairseq_cli.train | S2SpecTTransformerModel(\n",
            "  (encoder): S2STransformerEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (subsample): Conv1dSubsampler(\n",
            "      (conv_layers): ModuleList(\n",
            "        (0): Conv1d(80, 1024, kernel_size=(5,), stride=(2,), padding=(2,))\n",
            "        (1): Conv1d(512, 1024, kernel_size=(5,), stride=(2,), padding=(2,))\n",
            "      )\n",
            "    )\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-11): 12 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TTSTransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (prenet): Sequential(\n",
            "      (0): Prenet(\n",
            "        (layers): ModuleList(\n",
            "          (0): Sequential(\n",
            "            (0): Linear(in_features=1200, out_features=256, bias=True)\n",
            "            (1): ReLU()\n",
            "          )\n",
            "          (1): Sequential(\n",
            "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (1): ReLU()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): Linear(in_features=256, out_features=512, bias=True)\n",
            "    )\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-5): 6 x TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "    (feat_proj): Linear(in_features=512, out_features=1200, bias=True)\n",
            "    (eos_proj): Linear(in_features=512, out_features=1, bias=True)\n",
            "    (postnet): Postnet(\n",
            "      (convolutions): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Conv1d(1200, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Tanh()\n",
            "          (3): Dropout(p=0.5, inplace=False)\n",
            "        )\n",
            "        (1-3): 3 x Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Tanh()\n",
            "          (3): Dropout(p=0.5, inplace=False)\n",
            "        )\n",
            "        (4): Sequential(\n",
            "          (0): Conv1d(512, 1200, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "          (1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Dropout(p=0.5, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2024-04-22 09:46:10 | INFO | fairseq_cli.train | task: SpeechToSpeechTask\n",
            "2024-04-22 09:46:10 | INFO | fairseq_cli.train | model: S2SpecTTransformerModel\n",
            "2024-04-22 09:46:10 | INFO | fairseq_cli.train | criterion: SpeechToSpectrogramMultitaskTaskCriterion\n",
            "2024-04-22 09:46:10 | INFO | fairseq_cli.train | num. shared model params: 77,294,786 (num. trained: 77,294,786)\n",
            "2024-04-22 09:46:10 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-04-22 09:46:10 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.\n",
            "2024-04-22 09:46:10 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToSpeechDataset(split=\"dev\", n_samples=140, prepend_tgt_lang_tag=False, n_frames_per_step=5, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(\n",
            "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
            "    DeltaDeltas\n",
            "), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
            "))\n",
            "2024-04-22 09:46:10 | INFO | fairseq.data.audio.speech_to_speech_dataset | SpeechToSpeechDataset(split=\"dev\", n_samples=140, prepend_tgt_lang_tag=False, n_frames_per_step=5, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(\n",
            "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
            "    DeltaDeltas\n",
            "), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
            "))\n",
            "2024-04-22 09:46:10 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-04-22 09:46:10 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.748 GB ; name = Tesla T4                                \n",
            "2024-04-22 09:46:10 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-04-22 09:46:10 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-04-22 09:46:10 | INFO | fairseq_cli.train | max tokens per device = 80000 and max sentences per device = None\n",
            "2024-04-22 09:46:10 | INFO | fairseq.trainer | Preparing to load checkpoint /content/SAVE_DIR_TRAINING/checkpoint_last.pt\n",
            "2024-04-22 09:46:10 | INFO | fairseq.trainer | No existing checkpoint found /content/SAVE_DIR_TRAINING/checkpoint_last.pt\n",
            "2024-04-22 09:46:10 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-04-22 09:46:10 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.\n",
            "2024-04-22 09:46:10 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToSpeechDataset(split=\"train\", n_samples=1_215, prepend_tgt_lang_tag=False, n_frames_per_step=5, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(\n",
            "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
            "    DeltaDeltas\n",
            "    SpecAugmentTransform(time_warp_w=0, freq_mask_n=1, freq_mask_f=27, time_mask_n=1, time_mask_t=100, time_mask_p=1.0)\n",
            "), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
            "))\n",
            "2024-04-22 09:46:10 | INFO | fairseq.data.audio.speech_to_speech_dataset | SpeechToSpeechDataset(split=\"train\", n_samples=1_215, prepend_tgt_lang_tag=False, n_frames_per_step=5, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(\n",
            "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
            "    DeltaDeltas\n",
            "    SpecAugmentTransform(time_warp_w=0, freq_mask_n=1, freq_mask_f=27, time_mask_n=1, time_mask_t=100, time_mask_p=1.0)\n",
            "), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
            "))\n",
            "2024-04-22 09:46:10 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-22 09:46:10 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n",
            "2024-04-22 09:46:10 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n",
            "2024-04-22 09:46:10 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n",
            "2024-04-22 09:46:13 | INFO | fairseq_cli.train | begin dry-run validation on \"dev\" subset\n",
            "2024-04-22 09:46:13 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-22 09:46:13 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n",
            "2024-04-22 09:46:13 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n",
            "2024-04-22 09:46:13 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "2024-04-22 09:46:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 001:   0% 0/29 [00:00<?, ?it/s]2024-04-22 09:46:18 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2024-04-22 09:46:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-train\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 574, in cli_main\n",
            "    distributed_utils.call_main(cfg, main)\n",
            "  File \"/content/fairseq/fairseq/distributed/utils.py\", line 404, in call_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 205, in main\n",
            "    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 331, in train\n",
            "    log_output = trainer.train_step(samples)\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 868, in train_step\n",
            "    raise e\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 843, in train_step\n",
            "    loss, sample_size_i, logging_output = self.task.train_step(\n",
            "  File \"/content/fairseq/fairseq/tasks/speech_to_speech.py\", line 504, in train_step\n",
            "    loss, sample_size, logging_output = super().train_step(\n",
            "  File \"/content/fairseq/fairseq/tasks/fairseq_task.py\", line 532, in train_step\n",
            "    loss, sample_size, logging_output = criterion(model, sample)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/criterions/speech_to_speech_criterion.py\", line 362, in forward\n",
            "    feat_out, eos_out, extra = model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/models/speech_to_speech/s2s_transformer.py\", line 561, in forward\n",
            "    encoder_out = self.encoder(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/models/speech_to_speech/s2s_transformer.py\", line 46, in forward\n",
            "    out = super().forward(src_tokens, src_lengths, return_all_hiddens)\n",
            "  File \"/content/fairseq/fairseq/models/speech_to_text/s2t_transformer.py\", line 382, in forward\n",
            "    x = self._forward(\n",
            "  File \"/content/fairseq/fairseq/models/speech_to_text/s2t_transformer.py\", line 346, in _forward\n",
            "    x, input_lengths = self.subsample(src_tokens, src_lengths)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/models/speech_to_text/modules/convolution.py\", line 55, in forward\n",
            "    x = conv(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 310, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 306, in _conv_forward\n",
            "    return F.conv1d(input, weight, bias, self.stride,\n",
            "RuntimeError: Given groups=1, weight of size [1024, 80, 5], expected input[23, 240, 2500] to have 80 channels, but got 240 channels instead\n"
          ]
        }
      ],
      "source": [
        "# training\n",
        "!cd /content/fairseq && fairseq-train /content/DATA_ROOT  --config-yaml config.yaml --task speech_to_speech --n-frames-per-step 5 --criterion speech_to_spectrogram --arch s2spect_transformer --decoder-normalize-before --dropout 0.1 --attention-dropout 0.1 --relu-dropout 0.1 --train-subset train --valid-subset dev --save-dir /content/SAVE_DIR_TRAINING --eval-inference --best-checkpoint-metric mcd_loss --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-init-lr 1e-7 --warmup-updates 10000 --optimizer adam --adam-betas \"(0.9,0.98)\" --clip-norm 10.0 --weight-decay 1e-6 --max-update 400000 --max-tokens 80000 --max-tokens-valid 30000  --required-batch-size-multiple 1 --max-target-positions 3000 --update-freq 1 --seed 1 --fp16 --num-workers 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWPSXf3BqaLI"
      },
      "outputs": [],
      "source": [
        "# prompt: RuntimeError: Given groups=1, weight of size [1024, 80, 5], expected input[23, 240, 2500] to have 80 channels, but got 240 channel, but i am not sure where i should change the path to?, i need ur help\n",
        "\n",
        "The error message indicates that the input to the model has 240 channels, but the model expects 80 channels. This is likely due to a mismatch between the input data and the model configuration.\n",
        "\n",
        "There are a few possible causes for this error:\n",
        "\n",
        "* The input data may have been prepared with a different sampling rate or frame length than the model was trained on.\n",
        "* The model may have been trained on a different dataset with a different number of channels.\n",
        "* There may be a bug in the model code.\n",
        "\n",
        "To fix this error, you will need to identify the cause of the mismatch and correct it.\n",
        "\n",
        "Here are some things you can try:\n",
        "\n",
        "* Check the sampling rate and frame length of the input data and make sure that they match the model configuration.\n",
        "* Check the dataset that the model was trained on and make sure that it has the same number of channels as the input data.\n",
        "* If you are using a custom model, check the model code to make sure that it is correctly handling the input data.\n",
        "\n",
        "Once you have identified the cause of the error, you can take steps to correct it. For example, you may need to resample the input data, change the model configuration, or fix the bug in the model code.\n",
        "\n",
        "Here is a specific example of how to change the path to the input data:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/DATA_ROOT/logmelspec80.zip /content/drive/MyDrive/using_spectro"
      ],
      "metadata": {
        "id": "uEyOywzSOOgz"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "!cd /content/fairseq && fairseq-train /content/DATA_ROOT  --config-yaml config.yaml --task speech_to_speech --n-frames-per-step 5 --criterion speech_to_spectrogram --arch s2spect_transformer_fisher --decoder-normalize-before --dropout 0.1 --attention-dropout 0.1 --relu-dropout 0.1 --train-subset train --valid-subset dev --save-dir /content/SAVE_DIR_TRAINING --eval-inference --best-checkpoint-metric mcd_loss --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-init-lr 1e-7 --warmup-updates 10000 --optimizer adam --adam-betas \"(0.9,0.98)\" --clip-norm 10.0 --weight-decay 1e-6 --max-update 400000 --max-tokens 80000 --max-tokens-valid 30000  --required-batch-size-multiple 1 --max-target-positions 3000 --update-freq 1 --seed 1 --fp16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYLOr7n-KT7f",
        "outputId": "4c83debe-8bfd-4b82-d14a-c38fce3e8336"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-04-22 09:34:45.036161: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-22 09:34:45.036223: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-22 09:34:45.037868: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-22 09:34:45.046537: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-22 09:34:46.407054: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-04-22 09:34:47 | INFO | numexpr.utils | NumExpr defaulting to 2 threads.\n",
            "2024-04-22 09:34:49 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-04-22 09:34:52 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 80000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'dev', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 30000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/content/SAVE_DIR_TRAINING', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'mcd_loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='speech_to_spectrogram', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', simul_type=None, scoring='bleu', task='speech_to_speech', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=80000, batch_size=None, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid='30000', batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2spect_transformer_fisher', max_epoch=0, max_update=400000, stop_time_hours=0, clip_norm=10.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/content/SAVE_DIR_TRAINING', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='mcd_loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/content/DATA_ROOT', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=3000, target_is_code=False, target_code_size=None, n_frames_per_step=5, eval_inference=True, eval_args='{}', eos_prob_threshold=0.5, mcd_normalize_type='targ', vocoder='griffin_lim', spec_bwd_max_iter=8, infer_target_lang='', bce_pos_weight=1.0, use_guided_attention_loss=False, guided_attention_loss_sigma=0.4, ctc_weight=0.0, adam_betas='(0.9,0.98)', adam_eps=1e-08, weight_decay=1e-06, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=1e-07, pad=1, eos=2, unk=3, decoder_normalize_before=True, dropout=0.1, attention_dropout=0.1, activation_dropout=0.1, no_seed_provided=False, encoder_embed_dim=256, encoder_ffn_embed_dim=2048, encoder_attention_heads=4, prenet_dim=32, encoder_freezing_updates=0, input_channels=1, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_layers=12, encoder_normalize_before=True, no_scale_embedding=False, speaker_embed_dim=256, output_frame_dim=80, prenet_dropout=0.5, prenet_layers=2, postnet_dropout=0.5, postnet_layers=5, postnet_conv_dim=512, postnet_conv_kernel_size=5, decoder_transformer_layers=6, decoder_embed_dim=512, decoder_ffn_embed_dim=2048, decoder_attention_heads=4, _name='s2spect_transformer_fisher'), 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='speech_to_spectrogram', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', simul_type=None, scoring='bleu', task='speech_to_speech', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=80000, batch_size=None, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid='30000', batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2spect_transformer_fisher', max_epoch=0, max_update=400000, stop_time_hours=0, clip_norm=10.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/content/SAVE_DIR_TRAINING', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='mcd_loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/content/DATA_ROOT', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=3000, target_is_code=False, target_code_size=None, n_frames_per_step=5, eval_inference=True, eval_args='{}', eos_prob_threshold=0.5, mcd_normalize_type='targ', vocoder='griffin_lim', spec_bwd_max_iter=8, infer_target_lang='', bce_pos_weight=1.0, use_guided_attention_loss=False, guided_attention_loss_sigma=0.4, ctc_weight=0.0, adam_betas='(0.9,0.98)', adam_eps=1e-08, weight_decay=1e-06, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=1e-07, pad=1, eos=2, unk=3, decoder_normalize_before=True, dropout=0.1, attention_dropout=0.1, activation_dropout=0.1, no_seed_provided=False, encoder_embed_dim=256, encoder_ffn_embed_dim=2048, encoder_attention_heads=4, prenet_dim=32, encoder_freezing_updates=0, input_channels=1, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_layers=12, encoder_normalize_before=True, no_scale_embedding=False, speaker_embed_dim=256, output_frame_dim=80, prenet_dropout=0.5, prenet_layers=2, postnet_dropout=0.5, postnet_layers=5, postnet_conv_dim=512, postnet_conv_kernel_size=5, decoder_transformer_layers=6, decoder_embed_dim=512, decoder_ffn_embed_dim=2048, decoder_attention_heads=4, _name='speech_to_speech'), 'criterion': {'_name': 'speech_to_spectrogram', 'bce_pos_weight': 1.0, 'use_guided_attention_loss': False, 'guided_attention_loss_sigma': 0.4, 'ctc_weight': 0.0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 1e-06, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 10000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
            "2024-04-22 09:34:55 | INFO | fairseq_cli.train | S2SpecTTransformerModel(\n",
            "  (encoder): S2STransformerEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (subsample): Conv1dSubsampler(\n",
            "      (conv_layers): ModuleList(\n",
            "        (0): Conv1d(80, 1024, kernel_size=(5,), stride=(2,), padding=(2,))\n",
            "        (1): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))\n",
            "      )\n",
            "    )\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-11): 12 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
            "        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TTSTransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (prenet): Sequential(\n",
            "      (0): Prenet(\n",
            "        (layers): ModuleList(\n",
            "          (0): Sequential(\n",
            "            (0): Linear(in_features=400, out_features=32, bias=True)\n",
            "            (1): ReLU()\n",
            "          )\n",
            "          (1): Sequential(\n",
            "            (0): Linear(in_features=32, out_features=32, bias=True)\n",
            "            (1): ReLU()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): Linear(in_features=32, out_features=512, bias=True)\n",
            "    )\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-5): 6 x TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=256, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=256, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "    (feat_proj): Linear(in_features=512, out_features=400, bias=True)\n",
            "    (eos_proj): Linear(in_features=512, out_features=1, bias=True)\n",
            "    (postnet): Postnet(\n",
            "      (convolutions): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Conv1d(400, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Tanh()\n",
            "          (3): Dropout(p=0.5, inplace=False)\n",
            "        )\n",
            "        (1-3): 3 x Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Tanh()\n",
            "          (3): Dropout(p=0.5, inplace=False)\n",
            "        )\n",
            "        (4): Sequential(\n",
            "          (0): Conv1d(512, 400, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "          (1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Dropout(p=0.5, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2024-04-22 09:34:55 | INFO | fairseq_cli.train | task: SpeechToSpeechTask\n",
            "2024-04-22 09:34:55 | INFO | fairseq_cli.train | model: S2SpecTTransformerModel\n",
            "2024-04-22 09:34:55 | INFO | fairseq_cli.train | criterion: SpeechToSpectrogramMultitaskTaskCriterion\n",
            "2024-04-22 09:34:55 | INFO | fairseq_cli.train | num. shared model params: 47,379,586 (num. trained: 47,379,586)\n",
            "2024-04-22 09:34:55 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-04-22 09:34:55 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.\n",
            "2024-04-22 09:34:55 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToSpeechDataset(split=\"dev\", n_samples=140, prepend_tgt_lang_tag=False, n_frames_per_step=5, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(\n",
            "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
            "    DeltaDeltas\n",
            "), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
            "))\n",
            "2024-04-22 09:34:55 | INFO | fairseq.data.audio.speech_to_speech_dataset | SpeechToSpeechDataset(split=\"dev\", n_samples=140, prepend_tgt_lang_tag=False, n_frames_per_step=5, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(\n",
            "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
            "    DeltaDeltas\n",
            "), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
            "))\n",
            "2024-04-22 09:34:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-04-22 09:34:55 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.748 GB ; name = Tesla T4                                \n",
            "2024-04-22 09:34:55 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-04-22 09:34:55 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-04-22 09:34:55 | INFO | fairseq_cli.train | max tokens per device = 80000 and max sentences per device = None\n",
            "2024-04-22 09:34:55 | INFO | fairseq.trainer | Preparing to load checkpoint /content/SAVE_DIR_TRAINING/checkpoint_last.pt\n",
            "2024-04-22 09:34:55 | INFO | fairseq.trainer | No existing checkpoint found /content/SAVE_DIR_TRAINING/checkpoint_last.pt\n",
            "2024-04-22 09:34:55 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-04-22 09:34:55 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.\n",
            "2024-04-22 09:34:55 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToSpeechDataset(split=\"train\", n_samples=1_215, prepend_tgt_lang_tag=False, n_frames_per_step=5, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(\n",
            "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
            "    DeltaDeltas\n",
            "    SpecAugmentTransform(time_warp_w=0, freq_mask_n=1, freq_mask_f=27, time_mask_n=1, time_mask_t=100, time_mask_p=1.0)\n",
            "), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
            "))\n",
            "2024-04-22 09:34:55 | INFO | fairseq.data.audio.speech_to_speech_dataset | SpeechToSpeechDataset(split=\"train\", n_samples=1_215, prepend_tgt_lang_tag=False, n_frames_per_step=5, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(\n",
            "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
            "    DeltaDeltas\n",
            "    SpecAugmentTransform(time_warp_w=0, freq_mask_n=1, freq_mask_f=27, time_mask_n=1, time_mask_t=100, time_mask_p=1.0)\n",
            "), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
            "))\n",
            "2024-04-22 09:34:55 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-22 09:34:55 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n",
            "2024-04-22 09:34:55 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n",
            "2024-04-22 09:34:55 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n",
            "2024-04-22 09:34:57 | INFO | fairseq_cli.train | begin dry-run validation on \"dev\" subset\n",
            "2024-04-22 09:34:57 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-22 09:34:57 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n",
            "2024-04-22 09:34:57 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n",
            "2024-04-22 09:34:57 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "2024-04-22 09:35:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 001:   0% 0/29 [00:00<?, ?it/s]2024-04-22 09:35:02 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2024-04-22 09:35:02 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-train\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 574, in cli_main\n",
            "    distributed_utils.call_main(cfg, main)\n",
            "  File \"/content/fairseq/fairseq/distributed/utils.py\", line 404, in call_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 205, in main\n",
            "    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 331, in train\n",
            "    log_output = trainer.train_step(samples)\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 868, in train_step\n",
            "    raise e\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 843, in train_step\n",
            "    loss, sample_size_i, logging_output = self.task.train_step(\n",
            "  File \"/content/fairseq/fairseq/tasks/speech_to_speech.py\", line 504, in train_step\n",
            "    loss, sample_size, logging_output = super().train_step(\n",
            "  File \"/content/fairseq/fairseq/tasks/fairseq_task.py\", line 532, in train_step\n",
            "    loss, sample_size, logging_output = criterion(model, sample)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/criterions/speech_to_speech_criterion.py\", line 362, in forward\n",
            "    feat_out, eos_out, extra = model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/models/speech_to_speech/s2s_transformer.py\", line 561, in forward\n",
            "    encoder_out = self.encoder(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/models/speech_to_speech/s2s_transformer.py\", line 46, in forward\n",
            "    out = super().forward(src_tokens, src_lengths, return_all_hiddens)\n",
            "  File \"/content/fairseq/fairseq/models/speech_to_text/s2t_transformer.py\", line 382, in forward\n",
            "    x = self._forward(\n",
            "  File \"/content/fairseq/fairseq/models/speech_to_text/s2t_transformer.py\", line 346, in _forward\n",
            "    x, input_lengths = self.subsample(src_tokens, src_lengths)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/models/speech_to_text/modules/convolution.py\", line 55, in forward\n",
            "    x = conv(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 310, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\", line 306, in _conv_forward\n",
            "    return F.conv1d(input, weight, bias, self.stride,\n",
            "RuntimeError: Given groups=1, weight of size [1024, 80, 5], expected input[23, 240, 2500] to have 80 channels, but got 240 channels instead\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mljXC3xJAU7G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw1q2nss8ZpA"
      },
      "source": [
        "this seems to be an issue with the pyyaml and omegaconf\n",
        "https://github.com/omry/omegaconf/issues/758"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}