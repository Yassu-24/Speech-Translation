{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vblhh9zwb19Q",
        "outputId": "aa4a6a3a-4c38-4ab7-cdb1-f13bb8274b11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 35184, done.\u001b[K\n",
            "remote: Counting objects: 100% (105/105), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 35184 (delta 61), reused 72 (delta 47), pack-reused 35079\u001b[K\n",
            "Receiving objects: 100% (35184/35184), 25.22 MiB | 13.30 MiB/s, done.\n",
            "Resolving deltas: 100% (25548/25548), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/pytorch/fairseq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxeSYwoIiDK4",
        "outputId": "7ede9d9b-3a2a-49f6-a00d-026fe57ccc59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (3.0.10)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq==0.12.2)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq==0.12.2)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: numpy>=1.21.3 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.25.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2023.12.25)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq==0.12.2)\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (4.66.2)\n",
            "Collecting bitarray (from fairseq==0.12.2)\n",
            "  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2.2.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (24.0)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq==0.12.2)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (4.11.0)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq==0.12.2)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq==0.12.2)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (4.9.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->fairseq==0.12.2)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq==0.12.2) (2.22)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->fairseq==0.12.2) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->fairseq==0.12.2) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building editable for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-0.editable-cp310-cp310-linux_x86_64.whl size=9394 sha256=0dfe677ef71140f947bf4bb3673e007097627656f98f6bbb5daa216c0d85c39a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ox08wsr_/wheels/c6/d7/db/bc419b1daa8266aa8de2a7c4d29f62dbfa814e8701fe4695a2\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141211 sha256=9904b7f264f5871a08f1743803df942a1d6bb19aae9efd1f6e69a72032bc0a3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, colorama, sacrebleu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, nvidia-cusolver-cu12, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.9.2 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 omegaconf-2.0.6 portalocker-2.8.2 sacrebleu-2.4.2\n"
          ]
        }
      ],
      "source": [
        "!cd /content/fairseq && pip install --editable ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSCYDFCfjoVn",
        "outputId": "cbcd9e61-2dfb-4611-a56b-00f98006904e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/validate.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/preprocess.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/eval_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/train.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/hydra_train.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/generate.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/hydra_validate.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/score.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "copying fairseq_cli/interactive.py -> build/lib.linux-x86_64-cpython-310/fairseq_cli\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/pdb.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/sequence_scorer.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/file_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/incremental_decoding_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/registry.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/version.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/hub_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/sequence_generator.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/iterative_refinement_generator.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/nan_detector.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/search.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/file_io.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/speech_generator.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/binarizer.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/quantization_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/token_generation_constraints.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/trainer.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/file_chunker_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/options.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/tokenizer.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/ngram_repeat_block.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "copying fairseq/checkpoint_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/model_parallel\n",
            "copying fairseq/model_parallel/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel\n",
            "copying fairseq/model_parallel/megatron_trainer.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/lstm_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/model_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/fairseq_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/fairseq_incremental_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/distributed_fairseq_model.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/fairseq_model.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/multilingual_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/transformer_from_pretrained_xlm.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/fconv_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/masked_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/lightconv.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/transformer_align.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/fconv.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/composite_encoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/fconv_self_att.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/lstm.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/transformer_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/lightconv_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/transformer_ulm.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "copying fairseq/models/fairseq_encoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/lightweight_convolution.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/dynamic_crf_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/conv_tbc.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/adaptive_softmax.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/sparse_transformer_sentence_encoder_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/transformer_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/fp32_batch_norm.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/ema_module.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/transformer_sentence_encoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/kmeans_vector_quantizer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/fairseq_dropout.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/positional_embedding.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/gumbel_vector_quantizer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/vggblock.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/grad_multiply.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/sinusoidal_positional_embedding.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/sparse_multihead_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/transformer_sentence_encoder_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/character_token_embedder.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/sparse_transformer_sentence_encoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/linearized_convolution.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/beamable_mm.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/fp32_instance_norm.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/conformer_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/downsampled_multihead_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/same_pad.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/layer_drop.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/scalar_bias.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/learned_positional_embedding.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/multihead_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/transpose_last.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/adaptive_input.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/gelu.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/lstm_cell_with_zoneout.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/unfold.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/dynamic_convolution.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/cross_entropy.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/transformer_layer_aug.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/location_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/quant_noise.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/rotary_positional_embedding.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/kmeans_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/espnet_multihead_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/layer_norm.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/positional_encoding.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/fp32_group_norm.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/base_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "copying fairseq/modules/checkpoint_activations.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/denoising.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/hubert_pretraining.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/cross_lingual_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/legacy_masked_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/audio_finetuning.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/language_modeling.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/multilingual_language_modeling.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/online_backtranslation.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/fairseq_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/translation_from_pretrained_bart.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/multires_hubert_pretraining.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/speech_to_speech.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/span_masked_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/speech_to_text.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/sentence_prediction.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/nlu_finetuning.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/translation_from_pretrained_xlm.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/translation_multi_simple_epoch.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/simultaneous_translation.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/multilingual_denoising.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/frm_text_to_speech.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/audio_pretraining.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/masked_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/semisupervised_translation.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/multilingual_translation.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/speech_dlm_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/sentence_ranking.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/translation.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/multilingual_masked_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/translation_lev.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/sentence_prediction_adapters.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/text_to_speech.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/audio_classification.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "copying fairseq/tasks/speech_ulm_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/tasks\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/fused_lamb.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/cpu_adam.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/shard.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/adagrad.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/sgd.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/composite.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/adam.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/amp_optimizer.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/fairseq_optimizer.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/nag.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/adamax.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/adadelta.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/fused_adam.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/adafactor.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/fp16_optimizer.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/dynamic_loss_scaler.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "copying fairseq/optim/bmuf.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/distributed\n",
            "copying fairseq/distributed/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/distributed\n",
            "copying fairseq/distributed/fully_sharded_data_parallel.py -> build/lib.linux-x86_64-cpython-310/fairseq/distributed\n",
            "copying fairseq/distributed/distributed_timeout_wrapper.py -> build/lib.linux-x86_64-cpython-310/fairseq/distributed\n",
            "copying fairseq/distributed/legacy_distributed_data_parallel.py -> build/lib.linux-x86_64-cpython-310/fairseq/distributed\n",
            "copying fairseq/distributed/tpu_distributed_data_parallel.py -> build/lib.linux-x86_64-cpython-310/fairseq/distributed\n",
            "copying fairseq/distributed/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/distributed\n",
            "copying fairseq/distributed/module_proxy_wrapper.py -> build/lib.linux-x86_64-cpython-310/fairseq/distributed\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/logging\n",
            "copying fairseq/logging/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/logging\n",
            "copying fairseq/logging/meters.py -> build/lib.linux-x86_64-cpython-310/fairseq/logging\n",
            "copying fairseq/logging/progress_bar.py -> build/lib.linux-x86_64-cpython-310/fairseq/logging\n",
            "copying fairseq/logging/metrics.py -> build/lib.linux-x86_64-cpython-310/fairseq/logging\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_mt.py -> build/lib.linux-x86_64-cpython-310/fairseq/benchmark\n",
            "copying fairseq/benchmark/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_model.py -> build/lib.linux-x86_64-cpython-310/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_masked_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/benchmark\n",
            "copying fairseq/benchmark/dummy_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/benchmark\n",
            "copying fairseq/benchmark/benchmark_multihead_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/benchmark\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/config\n",
            "copying fairseq/config/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/subsample_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/add_class_target_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/plasma_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/dictionary.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/roll_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/bucket_pad_length_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/data_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/strip_token_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/base_wrapper_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/lru_cache_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/nested_dictionary_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/prepend_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/list_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/speech_dlm_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/padding_mask_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/pad_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/append_token_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/raw_label_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/noising.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/round_robin_zip_datasets.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/transform_eos_lang_pair_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/transform_eos_concat_langpair_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/text_compressor.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/backtranslation_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/prepend_token_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/resampling_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/fasta_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/token_block_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/colorize_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/monolingual_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/transform_eos_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/offset_tokens_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/multi_corpus_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/denoising_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/language_pair_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/span_mask_tokens_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/replace_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/lm_context_window_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/sort_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/iterators.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/id_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/codedataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/concat_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/fairseq_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/shorten_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/indexed_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/concat_sentences_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/multi_corpus_sampled_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/mask_tokens_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/numel_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/add_target_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "copying fairseq/data/num_samples_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/fairseq_criterion.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/legacy_masked_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy_with_ctc.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/nat_loss.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/adaptive_loss.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy_with_alignment.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy_with_rdrop.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/composite_loss.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/sentence_prediction.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/fastspeech2_loss.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/speech_ulm_criterion.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/masked_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/hubert_criterion.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/speech_dlm_criterion.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/wav2vec_criterion.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/tacotron2_loss.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/sentence_ranking.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/cross_entropy.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/sentence_prediction_adapters.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/model_criterion.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/ctc.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/label_smoothed_cross_entropy_latency_augmented.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "copying fairseq/criterions/speech_to_speech_criterion.py -> build/lib.linux-x86_64-cpython-310/fairseq/criterions\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/dataclass\n",
            "copying fairseq/dataclass/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/dataclass\n",
            "copying fairseq/dataclass/configs.py -> build/lib.linux-x86_64-cpython-310/fairseq/dataclass\n",
            "copying fairseq/dataclass/initialize.py -> build/lib.linux-x86_64-cpython-310/fairseq/dataclass\n",
            "copying fairseq/dataclass/constants.py -> build/lib.linux-x86_64-cpython-310/fairseq/dataclass\n",
            "copying fairseq/dataclass/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/dataclass\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/scoring\n",
            "copying fairseq/scoring/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/scoring\n",
            "copying fairseq/scoring/bleu.py -> build/lib.linux-x86_64-cpython-310/fairseq/scoring\n",
            "copying fairseq/scoring/wer.py -> build/lib.linux-x86_64-cpython-310/fairseq/scoring\n",
            "copying fairseq/scoring/meteor.py -> build/lib.linux-x86_64-cpython-310/fairseq/scoring\n",
            "copying fairseq/scoring/chrf.py -> build/lib.linux-x86_64-cpython-310/fairseq/scoring\n",
            "copying fairseq/scoring/tokenizer.py -> build/lib.linux-x86_64-cpython-310/fairseq/scoring\n",
            "copying fairseq/scoring/bertscore.py -> build/lib.linux-x86_64-cpython-310/fairseq/scoring\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples\n",
            "copying fairseq/examples/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models\n",
            "copying fairseq/model_parallel/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models\n",
            "copying fairseq/model_parallel/models/transformer_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models\n",
            "copying fairseq/model_parallel/models/transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/modules\n",
            "copying fairseq/model_parallel/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/modules\n",
            "copying fairseq/model_parallel/modules/transformer_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/modules\n",
            "copying fairseq/model_parallel/modules/multihead_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/criterions\n",
            "copying fairseq/model_parallel/criterions/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/criterions\n",
            "copying fairseq/model_parallel/criterions/vocab_parallel_cross_entropy.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/criterions\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
            "copying fairseq/model_parallel/models/pipeline_parallel_transformer/model.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
            "copying fairseq/model_parallel/models/pipeline_parallel_transformer/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
            "copying fairseq/model_parallel/models/pipeline_parallel_transformer/layers.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models/pipeline_parallel_transformer\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models/roberta\n",
            "copying fairseq/model_parallel/models/roberta/model.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models/roberta\n",
            "copying fairseq/model_parallel/models/roberta/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/model_parallel/models/roberta\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/hubert\n",
            "copying fairseq/models/hubert/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/hubert\n",
            "copying fairseq/models/hubert/hubert.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/hubert\n",
            "copying fairseq/models/hubert/hubert_asr.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/hubert\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_legacy.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_decoder_aug.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_encoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_base.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/transformer\n",
            "copying fairseq/models/transformer/transformer_config.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/transformer\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/wav2vec2_classification.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/wav2vec2_asr.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/wav2vec2_laser.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/wav2vec.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/wav2vec2.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/wav2vec\n",
            "copying fairseq/models/wav2vec/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/wav2vec\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/s2s_conformer_translatotron2.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/s2s_conformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/s2s_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech\n",
            "copying fairseq/models/speech_to_speech/s2s_conformer_unity.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/hub_interface.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/hifigan.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/codehifigan.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/fastspeech2.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/tacotron2.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/vocoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/text_to_speech\n",
            "copying fairseq/models/text_to_speech/tts_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/text_to_speech\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/huggingface\n",
            "copying fairseq/models/huggingface/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/huggingface\n",
            "copying fairseq/models/huggingface/hf_gpt2.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/huggingface\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/convtransformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/s2t_wav_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/hub_interface.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/xm_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/xm_transformer_unity.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/multi_modality_model.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/berard.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/s2t_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/s2t_conformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "copying fairseq/models/speech_to_text/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm\n",
            "copying fairseq/models/speech_dlm/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm\n",
            "copying fairseq/models/speech_dlm/hub_interface.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm\n",
            "copying fairseq/models/speech_dlm/speech_dlm.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/xmod\n",
            "copying fairseq/models/xmod/model.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/xmod\n",
            "copying fairseq/models/xmod/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/xmod\n",
            "copying fairseq/models/xmod/hub_interface.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/xmod\n",
            "copying fairseq/models/xmod/transformer_layer_xmod.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/xmod\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/multires_hubert\n",
            "copying fairseq/models/multires_hubert/multires_hubert.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/multires_hubert\n",
            "copying fairseq/models/multires_hubert/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/multires_hubert\n",
            "copying fairseq/models/multires_hubert/multires_hubert_asr.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/multires_hubert\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/model.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/hub_interface.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/model_camembert.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/model_xlmr.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/alignment_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/enc_dec.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/roberta\n",
            "copying fairseq/models/roberta/model_gottbert.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/roberta\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/ema\n",
            "copying fairseq/models/ema/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/ema\n",
            "copying fairseq/models/ema/ema.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/ema\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/nat_crf_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/nonautoregressive_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/iterative_nonautoregressive_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/cmlm_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/insertion_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/levenshtein_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/fairseq_nat_model.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/nonautoregressive_ensembles.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "copying fairseq/models/nat/levenshtein_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/nat\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/bart\n",
            "copying fairseq/models/bart/model.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/bart\n",
            "copying fairseq/models/bart/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/bart\n",
            "copying fairseq/models/bart/hub_interface.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/bart\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/transformer_decoder_aug.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/ctc_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/stacked_embedding.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech/modules\n",
            "copying fairseq/models/speech_to_speech/modules/transformer_encoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_speech/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text/modules\n",
            "copying fairseq/models/speech_to_text/modules/convolution.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text/modules\n",
            "copying fairseq/models/speech_to_text/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text/modules\n",
            "copying fairseq/models/speech_to_text/modules/augmented_memory_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text/modules\n",
            "copying fairseq/models/speech_to_text/modules/emformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_to_text/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm/modules\n",
            "copying fairseq/models/speech_dlm/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm/modules\n",
            "copying fairseq/models/speech_dlm/modules/speech_dlm_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm/modules\n",
            "copying fairseq/models/speech_dlm/modules/speech_dlm_decoder_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm/sequence_generator\n",
            "copying fairseq/models/speech_dlm/sequence_generator/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm/sequence_generator\n",
            "copying fairseq/models/speech_dlm/sequence_generator/multichannel_search.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm/sequence_generator\n",
            "copying fairseq/models/speech_dlm/sequence_generator/multichannel_sequence_generator.py -> build/lib.linux-x86_64-cpython-310/fairseq/models/speech_dlm/sequence_generator\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/modules/dynamicconv_layer\n",
            "copying fairseq/modules/dynamicconv_layer/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/dynamicconv_layer\n",
            "copying fairseq/modules/dynamicconv_layer/setup.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/dynamicconv_layer\n",
            "copying fairseq/modules/dynamicconv_layer/dynamicconv_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/dynamicconv_layer\n",
            "copying fairseq/modules/dynamicconv_layer/cuda_function_gen.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/dynamicconv_layer\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/modules/lightconv_layer\n",
            "copying fairseq/modules/lightconv_layer/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/lightconv_layer\n",
            "copying fairseq/modules/lightconv_layer/setup.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/lightconv_layer\n",
            "copying fairseq/modules/lightconv_layer/cuda_function_gen.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/lightconv_layer\n",
            "copying fairseq/modules/lightconv_layer/lightconv_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/lightconv_layer\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization\n",
            "copying fairseq/modules/quantization/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization\n",
            "copying fairseq/modules/quantization/quantization_options.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar\n",
            "copying fairseq/modules/quantization/scalar/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar\n",
            "copying fairseq/modules/quantization/scalar/ops.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar\n",
            "copying fairseq/modules/quantization/scalar/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq\n",
            "copying fairseq/modules/quantization/pq/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq\n",
            "copying fairseq/modules/quantization/pq/em.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq\n",
            "copying fairseq/modules/quantization/pq/pq.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq\n",
            "copying fairseq/modules/quantization/pq/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/qemb.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/qconv.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/qact.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar/modules\n",
            "copying fairseq/modules/quantization/scalar/modules/qlinear.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/scalar/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq/modules\n",
            "copying fairseq/modules/quantization/pq/modules/qemb.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq/modules\n",
            "copying fairseq/modules/quantization/pq/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq/modules\n",
            "copying fairseq/modules/quantization/pq/modules/qconv.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq/modules\n",
            "copying fairseq/modules/quantization/pq/modules/qlinear.py -> build/lib.linux-x86_64-cpython-310/fairseq/modules/quantization/pq/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/inverse_square_root_schedule.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/triangular_lr_scheduler.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/step_lr_scheduler.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/fixed_schedule.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/reduce_lr_on_plateau.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/cosine_lr_scheduler.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/fairseq_lr_scheduler.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/tri_stage_lr_scheduler.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/manual_lr_scheduler.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/pass_through.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "copying fairseq/optim/lr_scheduler/polynomial_decay_schedule.py -> build/lib.linux-x86_64-cpython-310/fairseq/optim/lr_scheduler\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/byte_bpe.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/nltk_tokenizer.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/fastbpe.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/space_tokenizer.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/characters.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/byte_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/hf_byte_bpe.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/sentencepiece_bpe.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/gpt2_bpe_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/bytes.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/gpt2_bpe.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/subword_nmt_bpe.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/hf_bert_bpe.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "copying fairseq/data/encoders/moses_tokenizer.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/encoders\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/data_cfg.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/speech_to_text_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/speech_to_speech_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/multi_modality_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/speech_to_text_joint_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/text_to_speech_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/audio_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/frm_text_to_speech_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/raw_audio_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "copying fairseq/data/audio/hubert_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/data/legacy\n",
            "copying fairseq/data/legacy/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/legacy\n",
            "copying fairseq/data/legacy/block_pair_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/legacy\n",
            "copying fairseq/data/legacy/masked_lm_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/legacy\n",
            "copying fairseq/data/legacy/masked_lm_dictionary.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/legacy\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/multilingual_data_manager.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/multilingual_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/sampling_method.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/sampled_multi_epoch_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/multilingual\n",
            "copying fairseq/data/multilingual/sampled_multi_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/multilingual\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/data/huffman\n",
            "copying fairseq/data/huffman/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/huffman\n",
            "copying fairseq/data/huffman/huffman_coder.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/huffman\n",
            "copying fairseq/data/huffman/huffman_mmap_indexed_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/huffman\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/delta_deltas.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/specaugment.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/global_cmvn.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/feature_transforms\n",
            "copying fairseq/data/audio/feature_transforms/utterance_cmvn.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/feature_transforms\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/data/audio/waveform_transforms\n",
            "copying fairseq/data/audio/waveform_transforms/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/waveform_transforms\n",
            "copying fairseq/data/audio/waveform_transforms/noiseaugment.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/waveform_transforms\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/data/audio/dataset_transforms\n",
            "copying fairseq/data/audio/dataset_transforms/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/dataset_transforms\n",
            "copying fairseq/data/audio/dataset_transforms/noisyoverlapaugment.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/dataset_transforms\n",
            "copying fairseq/data/audio/dataset_transforms/concataugment.py -> build/lib.linux-x86_64-cpython-310/fairseq/data/audio/dataset_transforms\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_score_lm.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_generate.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_score_bw.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_tune.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "copying fairseq/examples/noisychannel/rerank_options.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt\n",
            "copying fairseq/examples/discriminative_reranking_nmt/drnmt_rerank.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt\n",
            "copying fairseq/examples/discriminative_reranking_nmt/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/truncated_bptt_lm_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adaptive_span_model_wrapper.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adaptive_span_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adaptive_span_model.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adagrad_with_grad_clip.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/adaptive_span/adaptive_span_loss.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/adaptive_span\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/truncated_bptt\n",
            "copying fairseq/examples/truncated_bptt/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/truncated_bptt\n",
            "copying fairseq/examples/truncated_bptt/truncated_bptt_lm_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/truncated_bptt\n",
            "copying fairseq/examples/truncated_bptt/transformer_xl_model.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/truncated_bptt\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/fast_noisy_channel\n",
            "copying fairseq/examples/fast_noisy_channel/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/fast_noisy_channel\n",
            "copying fairseq/examples/fast_noisy_channel/noisy_channel_translation.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/fast_noisy_channel\n",
            "copying fairseq/examples/fast_noisy_channel/noisy_channel_beam_search.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/fast_noisy_channel\n",
            "copying fairseq/examples/fast_noisy_channel/noisy_channel_sequence_generator.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/fast_noisy_channel\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/libri_labels.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/wav2vec_manifest.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/vq-wav2vec_featurize.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec\n",
            "copying fairseq/examples/wav2vec/wav2vec_featurize.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech\n",
            "copying fairseq/examples/speech_to_speech/generate_waveform_from_code.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech\n",
            "copying fairseq/examples/speech_to_speech/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis\n",
            "copying fairseq/examples/speech_synthesis/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis\n",
            "copying fairseq/examples/speech_synthesis/data_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis\n",
            "copying fairseq/examples/speech_synthesis/generate_waveform.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis\n",
            "copying fairseq/examples/speech_synthesis/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec\n",
            "copying fairseq/examples/data2vec/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec\n",
            "copying fairseq/examples/data2vec/fb_convert_beit_cp.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/rxf\n",
            "copying fairseq/examples/rxf/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/rxf\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition\n",
            "copying fairseq/examples/speech_recognition/w2l_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition\n",
            "copying fairseq/examples/speech_recognition/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition\n",
            "copying fairseq/examples/speech_recognition/infer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text\n",
            "copying fairseq/examples/speech_text_joint_to_text/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation\n",
            "copying fairseq/examples/simultaneous_translation/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/models\n",
            "copying fairseq/examples/discriminative_reranking_nmt/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/models\n",
            "copying fairseq/examples/discriminative_reranking_nmt/models/discriminative_reranking_model.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/tasks\n",
            "copying fairseq/examples/discriminative_reranking_nmt/tasks/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/tasks\n",
            "copying fairseq/examples/discriminative_reranking_nmt/tasks/discriminative_reranking_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/tasks\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/criterions\n",
            "copying fairseq/examples/discriminative_reranking_nmt/criterions/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/criterions\n",
            "copying fairseq/examples/discriminative_reranking_nmt/criterions/discriminative_reranking_criterion.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/criterions\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised\n",
            "copying fairseq/examples/wav2vec/unsupervised/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised\n",
            "copying fairseq/examples/wav2vec/unsupervised/w2vu_generate.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/models\n",
            "copying fairseq/examples/wav2vec/unsupervised/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/models\n",
            "copying fairseq/examples/wav2vec/unsupervised/models/wav2vec_u.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/tasks\n",
            "copying fairseq/examples/wav2vec/unsupervised/tasks/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/tasks\n",
            "copying fairseq/examples/wav2vec/unsupervised/tasks/unpaired_audio_text.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/tasks\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/data\n",
            "copying fairseq/examples/wav2vec/unsupervised/data/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/data\n",
            "copying fairseq/examples/wav2vec/unsupervised/data/extracted_features_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/data\n",
            "copying fairseq/examples/wav2vec/unsupervised/data/random_input_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/data\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/unity\n",
            "copying fairseq/examples/speech_to_speech/unity/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/unity\n",
            "copying fairseq/examples/speech_to_speech/unity/sequence_generator_multi_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/unity\n",
            "copying fairseq/examples/speech_to_speech/unity/sequence_generator.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/unity\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/data_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/prep_s2ut_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/prep_sn_output_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/prep_sn_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/preprocessing\n",
            "copying fairseq/examples/speech_to_speech/preprocessing/prep_s2spect_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/preprocessing\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/asr_bleu\n",
            "copying fairseq/examples/speech_to_speech/asr_bleu/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/asr_bleu\n",
            "copying fairseq/examples/speech_to_speech/asr_bleu/compute_asr_bleu.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/asr_bleu\n",
            "copying fairseq/examples/speech_to_speech/asr_bleu/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/asr_bleu\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/eval_f0.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/eval_sp.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/eval_asr.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/evaluation\n",
            "copying fairseq/examples/speech_synthesis/evaluation/get_eval_manifest.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/evaluation\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_vctk_audio_manifest.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoise_and_vad_audio.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_speaker_embedding.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_feature_manifest.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_common_voice_audio_manifest.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/get_ljspeech_audio_manifest.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/demucs.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/pretrained.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/denoiser/resample.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/denoiser\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/vad\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/vad/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/vad\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/speaker_embedder\n",
            "copying fairseq/examples/speech_synthesis/preprocessing/speaker_embedder/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/preprocessing/speaker_embedder\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_image_classification.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec2.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_text.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/mae.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_vision.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_audio.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/mae_image_classification.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/data2vec_text_classification.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "copying fairseq/examples/data2vec/models/audio_classification.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/multimodal.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/image_pretraining.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/mae_image_classification.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/mae_image_pretraining.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/image_classification.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/tasks\n",
            "copying fairseq/examples/data2vec/tasks/audio_classification.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/tasks\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/add_class_target_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/modality.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/path_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/image_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/mae_finetuning_image_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/data\n",
            "copying fairseq/examples/data2vec/data/mae_image_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/data\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/base.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/audio.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/images.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/text.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models/modalities\n",
            "copying fairseq/examples/data2vec/models/modalities/modules.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/models/modalities\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/rxf/rxf_src\n",
            "copying fairseq/examples/rxf/rxf_src/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/rxf/rxf_src\n",
            "copying fairseq/examples/rxf/rxf_src/label_smoothed_cross_entropy_r3f.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/rxf/rxf_src\n",
            "copying fairseq/examples/rxf/rxf_src/sentence_prediction_r3f.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/rxf/rxf_src\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/models\n",
            "copying fairseq/examples/speech_recognition/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/models\n",
            "copying fairseq/examples/speech_recognition/models/vggtransformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/models\n",
            "copying fairseq/examples/speech_recognition/models/w2l_conv_glu_enc.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/tasks\n",
            "copying fairseq/examples/speech_recognition/tasks/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/tasks\n",
            "copying fairseq/examples/speech_recognition/tasks/speech_recognition.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/tasks\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new\n",
            "copying fairseq/examples/speech_recognition/new/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new\n",
            "copying fairseq/examples/speech_recognition/new/infer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/replabels.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/data_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/collaters.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/data\n",
            "copying fairseq/examples/speech_recognition/data/asr_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/data\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/criterions\n",
            "copying fairseq/examples/speech_recognition/criterions/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/criterions\n",
            "copying fairseq/examples/speech_recognition/criterions/cross_entropy_acc.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/criterions\n",
            "copying fairseq/examples/speech_recognition/criterions/ASG_loss.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/criterions\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/kaldi\n",
            "copying fairseq/examples/speech_recognition/kaldi/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/kaldi\n",
            "copying fairseq/examples/speech_recognition/kaldi/kaldi_initializer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/kaldi\n",
            "copying fairseq/examples/speech_recognition/kaldi/kaldi_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/kaldi\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/base_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/decoder_config.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/viterbi_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/flashlight_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/decoders\n",
            "copying fairseq/examples/speech_recognition/new/decoders/decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/decoders\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/s2t_dualinputxmtransformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/joint_speech_text_pretrain_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/s2t_dualinputtransformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/models\n",
            "copying fairseq/examples/speech_text_joint_to_text/models/s2t_dualinputwavtransformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "copying fairseq/examples/speech_text_joint_to_text/tasks/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "copying fairseq/examples/speech_text_joint_to_text/tasks/speech_text_denoise_pretrain.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "copying fairseq/examples/speech_text_joint_to_text/tasks/speech_text_joint.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "copying fairseq/examples/speech_text_joint_to_text/tasks/pair_denoising.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/tasks\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "copying fairseq/examples/speech_text_joint_to_text/criterions/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "copying fairseq/examples/speech_text_joint_to_text/criterions/multi_modality_compound.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "copying fairseq/examples/speech_text_joint_to_text/criterions/text_guide_cross_entropy_acc.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "copying fairseq/examples/speech_text_joint_to_text/criterions/multi_modality_cross_entropy.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/criterions\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/models\n",
            "copying fairseq/examples/simultaneous_translation/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/models\n",
            "copying fairseq/examples/simultaneous_translation/models/convtransformer_simul_trans.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/models\n",
            "copying fairseq/examples/simultaneous_translation/models/transformer_monotonic_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/modules\n",
            "copying fairseq/examples/simultaneous_translation/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/modules\n",
            "copying fairseq/examples/simultaneous_translation/modules/fixed_pre_decision.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/modules\n",
            "copying fairseq/examples/simultaneous_translation/modules/monotonic_transformer_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/modules\n",
            "copying fairseq/examples/simultaneous_translation/modules/monotonic_multihead_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/utils\n",
            "copying fairseq/examples/simultaneous_translation/utils/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/utils\n",
            "copying fairseq/examples/simultaneous_translation/utils/functions.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/utils\n",
            "copying fairseq/examples/simultaneous_translation/utils/p_choose_strategy.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/utils\n",
            "copying fairseq/examples/simultaneous_translation/utils/monotonic_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/utils\n",
            "copying fairseq/examples/.gitignore -> build/lib.linux-x86_64-cpython-310/fairseq/examples\n",
            "copying fairseq/examples/noisychannel/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/noisychannel\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/pay_less_attention_paper\n",
            "copying fairseq/examples/pay_less_attention_paper/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/pay_less_attention_paper\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt21\n",
            "copying fairseq/examples/wmt21/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt21\n",
            "copying fairseq/examples/wmt21/eval.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt21\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt21/scripts\n",
            "copying fairseq/examples/wmt21/scripts/replace-unicode-punctuation.perl -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt21/scripts\n",
            "copying fairseq/examples/wmt21/scripts/normalize-punctuation.perl -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt21/scripts\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/pointer_generator\n",
            "copying fairseq/examples/pointer_generator/preprocess.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/pointer_generator\n",
            "copying fairseq/examples/pointer_generator/README.xsum.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/pointer_generator\n",
            "copying fairseq/examples/pointer_generator/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/pointer_generator\n",
            "copying fairseq/examples/pointer_generator/postprocess.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/pointer_generator\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/pointer_generator/pointer_generator_src\n",
            "copying fairseq/examples/pointer_generator/pointer_generator_src/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/pointer_generator/pointer_generator_src\n",
            "copying fairseq/examples/pointer_generator/pointer_generator_src/transformer_pg.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/pointer_generator/pointer_generator_src\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100\n",
            "copying fairseq/examples/m2m_100/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100\n",
            "copying fairseq/examples/m2m_100/install_dependecies.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100\n",
            "copying fairseq/examples/m2m_100/tok.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/tokenizer_ar.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/tokenize_thai.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/seg_ja.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/seg_ko.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/tokenize_zh.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers\n",
            "copying fairseq/examples/m2m_100/tokenizers/tokenize_indic.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers/thirdparty\n",
            "copying fairseq/examples/m2m_100/tokenizers/thirdparty/.gitignore -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/tokenizers/thirdparty\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/process_data\n",
            "copying fairseq/examples/m2m_100/process_data/clean_histogram.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/process_data\n",
            "copying fairseq/examples/m2m_100/process_data/remove_too_much_punc.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/process_data\n",
            "copying fairseq/examples/m2m_100/process_data/dedup_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/m2m_100/process_data\n",
            "copying fairseq/examples/discriminative_reranking_nmt/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/config\n",
            "copying fairseq/examples/discriminative_reranking_nmt/config/deen.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/scripts\n",
            "copying fairseq/examples/discriminative_reranking_nmt/scripts/prep_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/discriminative_reranking_nmt/scripts\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/conv_seq2seq\n",
            "copying fairseq/examples/conv_seq2seq/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/conv_seq2seq\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert\n",
            "copying fairseq/examples/hubert/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert\n",
            "copying fairseq/examples/hubert/measure_teacher_quality.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert\n",
            "copying fairseq/examples/hubert/update_ckpt.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.xlarge.L30.npy -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.base.L9.km500.km -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/6313-76958-0021.flac -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.base.L9.npy -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.xlarge.hypo.word -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.large.L20.len -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.base.L9.len -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.large.L20.npy -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.large.hypo.word -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/test_feature_and_unit.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/test_finetuned_asr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "copying fairseq/examples/hubert/tests/sample.xlarge.L30.len -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/tests\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_mfcc_feature.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_hubert_feature.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_hubert_feature_s2t.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/learn_kmeans.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/feature_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_w2v2_feature.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/simple_kmeans\n",
            "copying fairseq/examples/hubert/simple_kmeans/dump_km_label.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/simple_kmeans\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode\n",
            "copying fairseq/examples/hubert/config/decode/infer_viterbi.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode\n",
            "copying fairseq/examples/hubert/config/decode/infer_fsqlm.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode\n",
            "copying fairseq/examples/hubert/config/decode/infer_kenlm.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode/run\n",
            "copying fairseq/examples/hubert/config/decode/run/submitit_slurm.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode/run\n",
            "copying fairseq/examples/hubert/config/decode/run/submitit_slurm_8gpu.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode/run\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode/ax_sweep\n",
            "copying fairseq/examples/hubert/config/decode/ax_sweep/ngram.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode/ax_sweep\n",
            "copying fairseq/examples/hubert/config/decode/ax_sweep/transformer.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/decode/ax_sweep\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/finetune\n",
            "copying fairseq/examples/hubert/config/finetune/base_10h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/finetune\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/finetune/run\n",
            "copying fairseq/examples/hubert/config/finetune/run/submitit_reg.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/finetune/run\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/finetune/lm\n",
            "copying fairseq/examples/hubert/config/finetune/lm/ls_4gram.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/finetune/lm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/finetune/ckpt\n",
            "copying fairseq/examples/hubert/config/finetune/ckpt/it1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/finetune/ckpt\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/pretrain\n",
            "copying fairseq/examples/hubert/config/pretrain/hubert_base_librispeech.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/pretrain\n",
            "copying fairseq/examples/hubert/config/pretrain/hubert_large_librivox.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/pretrain\n",
            "copying fairseq/examples/hubert/config/pretrain/hubert_xlarge_librivox.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/pretrain\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/pretrain/run\n",
            "copying fairseq/examples/hubert/config/pretrain/run/submitit_reg.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/pretrain/run\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/pretrain/data\n",
            "copying fairseq/examples/hubert/config/pretrain/data/iter1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/pretrain/data\n",
            "copying fairseq/examples/hubert/config/pretrain/data/iter2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/hubert/config/pretrain/data\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/criss\n",
            "copying fairseq/examples/criss/save_encoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/criss\n",
            "copying fairseq/examples/criss/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/criss\n",
            "copying fairseq/examples/criss/download_and_preprocess_tatoeba.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/criss\n",
            "copying fairseq/examples/criss/download_and_preprocess_flores_test.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/criss\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/criss/sentence_retrieval\n",
            "copying fairseq/examples/criss/sentence_retrieval/encoder_analysis.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/criss/sentence_retrieval\n",
            "copying fairseq/examples/criss/sentence_retrieval/sentence_retrieval_tatoeba.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/criss/sentence_retrieval\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/criss/mining\n",
            "copying fairseq/examples/criss/mining/mine.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/criss/mining\n",
            "copying fairseq/examples/criss/mining/mine_example.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/criss/mining\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/criss/unsupervised_mt\n",
            "copying fairseq/examples/criss/unsupervised_mt/eval.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/criss/unsupervised_mt\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/tokenized_bleu.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/extract_bt_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/sacrebleu.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/prepare-wmt18en2de.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/deduplicate_lines.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/backtranslation\n",
            "copying fairseq/examples/backtranslation/prepare-de-monolingual.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/backtranslation\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/camembert\n",
            "copying fairseq/examples/camembert/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/camembert\n",
            "copying fairseq/examples/adaptive_span/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/adaptive_span\n",
            "copying fairseq/examples/truncated_bptt/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/truncated_bptt\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/prepare-iwslt17-multilingual.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/prepare-wmt14en2de.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/prepare-wmt14en2fr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation\n",
            "copying fairseq/examples/translation/prepare-iwslt14.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation\n",
            "copying fairseq/examples/fast_noisy_channel/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/fast_noisy_channel\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert\n",
            "copying fairseq/examples/mr_hubert/train.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert\n",
            "copying fairseq/examples/mr_hubert/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert\n",
            "copying fairseq/examples/mr_hubert/decode.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert\n",
            "copying fairseq/examples/mr_hubert/finetune.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/simple_kmeans\n",
            "copying fairseq/examples/mr_hubert/simple_kmeans/dump_mfcc_feature.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/simple_kmeans\n",
            "copying fairseq/examples/mr_hubert/simple_kmeans/dump_hubert_feature.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/simple_kmeans\n",
            "copying fairseq/examples/mr_hubert/simple_kmeans/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/simple_kmeans\n",
            "copying fairseq/examples/mr_hubert/simple_kmeans/dump_hubert_feature_s2t.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/simple_kmeans\n",
            "copying fairseq/examples/mr_hubert/simple_kmeans/learn_kmeans.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/simple_kmeans\n",
            "copying fairseq/examples/mr_hubert/simple_kmeans/feature_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/simple_kmeans\n",
            "copying fairseq/examples/mr_hubert/simple_kmeans/dump_w2v2_feature.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/simple_kmeans\n",
            "copying fairseq/examples/mr_hubert/simple_kmeans/dump_km_label.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/simple_kmeans\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/decode\n",
            "copying fairseq/examples/mr_hubert/config/decode/infer_lm.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/decode\n",
            "copying fairseq/examples/mr_hubert/config/decode/infer.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/decode\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/decode/run\n",
            "copying fairseq/examples/mr_hubert/config/decode/run/submitit_slurm.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/decode/run\n",
            "copying fairseq/examples/mr_hubert/config/decode/run/submitit_slurm_8gpu.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/decode/run\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/finetune\n",
            "copying fairseq/examples/mr_hubert/config/finetune/base_100h_large.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/finetune\n",
            "copying fairseq/examples/mr_hubert/config/finetune/base_1h_large.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/finetune\n",
            "copying fairseq/examples/mr_hubert/config/finetune/base_10h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/finetune\n",
            "copying fairseq/examples/mr_hubert/config/finetune/base_100h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/finetune\n",
            "copying fairseq/examples/mr_hubert/config/finetune/base_10h_large.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/finetune\n",
            "copying fairseq/examples/mr_hubert/config/finetune/base_1h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/finetune\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/pretrain\n",
            "copying fairseq/examples/mr_hubert/config/pretrain/mrhubert_large_librilight.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/pretrain\n",
            "copying fairseq/examples/mr_hubert/config/pretrain/mrhubert_base_librispeech.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/pretrain\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/pretrain/run\n",
            "copying fairseq/examples/mr_hubert/config/pretrain/run/submitit_reg.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mr_hubert/config/pretrain/run\n",
            "copying fairseq/examples/wav2vec/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/xlsr\n",
            "copying fairseq/examples/wav2vec/xlsr/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/xlsr\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/xlsr/config\n",
            "copying fairseq/examples/wav2vec/xlsr/config/finetune.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/xlsr/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/xlsr/scripts\n",
            "copying fairseq/examples/wav2vec/xlsr/scripts/eval_speaker_clf_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/xlsr/scripts\n",
            "copying fairseq/examples/wav2vec/xlsr/scripts/gen_audio_embedding.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/xlsr/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/path.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/train.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/decode_word_step1.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/cmd.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/decode_phone.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/decode_word_step2.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/unsup_select_decode_word.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/unsup_select.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_data_from_w2v.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/copy_aligned_text.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/decode.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_lm.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_lang_word.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/unsup_select_decode.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/train_subset_lgbeam.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/score.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/show_wer.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local/prepare_lang.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/local\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/train_deltas.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/train_sat.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan/train_lda_mllt.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/kaldi_self_train/st/steps_gan\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_matched/train_text.uid -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_matched/valid.uid -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_matched/test.uid -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_matched/train.uid -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_matched\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/gan/w2vu2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/gan\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/gan/w2vu.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/gan\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/train_text.uid -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/valid.uid -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/test.uid -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/timit_unmatched/train.uid -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/timit_unmatched\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/generate\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/generate/viterbi.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/generate\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/finetuning\n",
            "copying fairseq/examples/wav2vec/unsupervised/config/finetuning/w2v_finetune.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/config/finetuning\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/phonemize_with_sil.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/prepare_text.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/vads.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/prepare_audio.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/remove_silence.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/prepare_timit.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/pca.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/copy_labels.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/merge_clusters.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/g2p_wrd_to_phn.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wav2vec_extract_features.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/apply_pca.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/ltr_to_wrd.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wav2vec_apply_cluster_faiss.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/normalize_text.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/prepare_audio_v2.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/mean_pool.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/filter_tsv.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/filter_lexicon.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wrd_to_ltr.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/normalize_and_filter_text.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "copying fairseq/examples/wav2vec/unsupervised/scripts/wav2vec_cluster_faiss.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/unsupervised/scripts\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_conformer_large_librivox.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox_tpu-pod.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_conformer_base_librispeech.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox_tpu.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_base_librispeech.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/pretraining\n",
            "copying fairseq/examples/wav2vec/config/pretraining/wav2vec2_large_librivox.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/pretraining\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_4.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10m_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_100h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10m.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_960h_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_100h_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10m_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_100h_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_10h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_960h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_100h_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_100h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_960h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10m_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_1h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/base_10m.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_10h_aws_v100.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_1h_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_960h_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "copying fairseq/examples/wav2vec/config/finetuning/vox_960h_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_16.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_4g_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_2g.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_8.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_4g.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "copying fairseq/examples/wav2vec/config/finetuning/run_config/slurm_1_old.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/config/finetuning/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/scripts\n",
            "copying fairseq/examples/wav2vec/scripts/binarize_manifest.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wav2vec/scripts\n",
            "copying fairseq/examples/speech_to_speech/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/data_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/core.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/get_metrics.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/configs/S2T.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/configs/2StageS2ST.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/configs/DirectS2U.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "copying fairseq/examples/speech_to_speech/benchmarking/configs/3StageS2ST.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/benchmarking/configs\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/docs\n",
            "copying fairseq/examples/speech_to_speech/docs/textless_s2st_real_data.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/docs\n",
            "copying fairseq/examples/speech_to_speech/docs/data_augmentation.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/docs\n",
            "copying fairseq/examples/speech_to_speech/docs/direct_s2st_discrete_units.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/docs\n",
            "copying fairseq/examples/speech_to_speech/docs/enhanced_direct_s2st_discrete_units.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/docs\n",
            "copying fairseq/examples/speech_to_speech/asr_bleu/requirements.txt -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/asr_bleu\n",
            "copying fairseq/examples/speech_to_speech/asr_bleu/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/asr_bleu\n",
            "copying fairseq/examples/speech_to_speech/asr_bleu/asr_model_cfgs.json -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_speech/asr_bleu\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/xformers\n",
            "copying fairseq/examples/xformers/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/xformers\n",
            "copying fairseq/examples/speech_synthesis/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/docs\n",
            "copying fairseq/examples/speech_synthesis/docs/vctk_example.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/docs\n",
            "copying fairseq/examples/speech_synthesis/docs/common_voice_example.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/docs\n",
            "copying fairseq/examples/speech_synthesis/docs/ljspeech_example.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_synthesis/docs\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt20\n",
            "copying fairseq/examples/wmt20/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt20\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/byte_level_bpe\n",
            "copying fairseq/examples/byte_level_bpe/gru_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/byte_level_bpe\n",
            "copying fairseq/examples/byte_level_bpe/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/byte_level_bpe\n",
            "copying fairseq/examples/byte_level_bpe/get_data.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/byte_level_bpe\n",
            "copying fairseq/examples/byte_level_bpe/get_bitext.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/byte_level_bpe\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer\n",
            "copying fairseq/examples/linformer/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src\n",
            "copying fairseq/examples/linformer/linformer_src/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src/models\n",
            "copying fairseq/examples/linformer/linformer_src/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src/models\n",
            "copying fairseq/examples/linformer/linformer_src/models/linformer_roberta.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src/modules\n",
            "copying fairseq/examples/linformer/linformer_src/modules/multihead_linear_attention.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src/modules\n",
            "copying fairseq/examples/linformer/linformer_src/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src/modules\n",
            "copying fairseq/examples/linformer/linformer_src/modules/linformer_sentence_encoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src/modules\n",
            "copying fairseq/examples/linformer/linformer_src/modules/linformer_sentence_encoder_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/linformer/linformer_src/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/xlmr\n",
            "copying fairseq/examples/xlmr/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/xlmr\n",
            "copying fairseq/examples/data2vec/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/base_librispeech.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/audioset.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/local.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_6_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_4.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/pretraining/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/pretraining/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/classification\n",
            "copying fairseq/examples/data2vec/config/audio/classification/base_classification.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/classification\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/classification/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/classification/run_config/slurm_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/classification/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/classification/run_config/slurm_1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/classification/run_config\n",
            "copying fairseq/examples/data2vec/config/audio/classification/run_config/slurm_1g.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/audio/classification/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/base.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/local.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_4.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/text/pretraining/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/text/pretraining/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/large_text_only_task.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/huge_images_only_task.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/large_audio_only_task.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/huge_images14_only_task.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/base_audio_only_task.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/base_images_only_task.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/large_text_only_task_pgrp_1M.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/base_text_only_task.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "copying fairseq/examples/data2vec/config/v2/large_images_only_task.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/local.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_6_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_8.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_4.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/rte.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/qqp.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/cola.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/mrpc.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/qnli.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/sts_b.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/mnli.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/sst_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/v2/text_finetuning/run_config/local.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/v2/text_finetuning/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/base_imagenet_d2v1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/base_mae_imagenet.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/base_imagenet.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/local.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_6_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_4.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/pretraining/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/pretraining/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/mae_imagenet_huge_clean.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/mae_imagenet_clean.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/mae_imagenet_large_clean.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/imagenet.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_4_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/local.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_1_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_6_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_4.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "copying fairseq/examples/data2vec/config/vision/finetuning/run_config/slurm_8_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/config/vision/finetuning/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts\n",
            "copying fairseq/examples/data2vec/scripts/convert_audioset_labels.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/multi\n",
            "copying fairseq/examples/data2vec/scripts/multi/finetune_all_fair_aws_local_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/multi\n",
            "copying fairseq/examples/data2vec/scripts/multi/finetune_all_fair_local_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/multi\n",
            "copying fairseq/examples/data2vec/scripts/multi/finetune_all_fair_aws_local_lr_nodep.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/multi\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_sst2_qnli_sweep_fair_nodep.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep_aws.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_char_fair_aws_local_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/unprocess_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep_aws_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_large_fair_nodep_aws_local_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep_aws_lr_nopos.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_aws_local_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/valids.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_large_fair_local_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_local_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_aws.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_large_fair_aws_local_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_aws_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep_aws_local_lr.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/glue.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/finetune_all_fair_nodep.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/data2vec/scripts/text/glue_lr.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/data2vec/scripts/text\n",
            "copying fairseq/examples/rxf/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/rxf\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/quant_noise\n",
            "copying fairseq/examples/quant_noise/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/quant_noise\n",
            "copying fairseq/examples/quant_noise/transformer_quantization_config.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/quant_noise\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/utils.h -> build/lib.linux-x86_64-cpython-310/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/alignment_train_kernel.cu -> build/lib.linux-x86_64-cpython-310/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/alignment_train_cuda.cpp -> build/lib.linux-x86_64-cpython-310/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/alignment_train_cpu.cpp -> build/lib.linux-x86_64-cpython-310/fairseq/examples/operators\n",
            "copying fairseq/examples/operators/alignment_train_cuda.h -> build/lib.linux-x86_64-cpython-310/fairseq/examples/operators\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt19\n",
            "copying fairseq/examples/wmt19/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/wmt19\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/paraphraser\n",
            "copying fairseq/examples/paraphraser/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/paraphraser\n",
            "copying fairseq/examples/paraphraser/paraphrase.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/paraphraser\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/womens_bios\n",
            "copying fairseq/examples/womens_bios/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/womens_bios\n",
            "copying fairseq/examples/womens_bios/query_occupations_from_wikidata.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/womens_bios\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/audio_nlp\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/audio_nlp/nlu\n",
            "copying fairseq/examples/audio_nlp/nlu/generate_manifests.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/audio_nlp/nlu\n",
            "copying fairseq/examples/audio_nlp/nlu/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/audio_nlp/nlu\n",
            "copying fairseq/examples/audio_nlp/nlu/create_dict_stop.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/audio_nlp/nlu\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/audio_nlp/nlu/configs\n",
            "copying fairseq/examples/audio_nlp/nlu/configs/nlu_finetuning.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/audio_nlp/nlu/configs\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms\n",
            "copying fairseq/examples/mms/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms\n",
            "copying fairseq/examples/mms/MODEL_CARD.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/misc\n",
            "copying fairseq/examples/mms/misc/get_sample_size.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/misc\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/asr\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/asr/infer\n",
            "copying fairseq/examples/mms/asr/infer/mms_infer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/asr/infer\n",
            "copying fairseq/examples/mms/asr/infer/example_infer_adapter.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/asr/infer\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/asr/config\n",
            "copying fairseq/examples/mms/asr/config/infer_common.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/asr/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/asr/tutorial\n",
            "copying fairseq/examples/mms/asr/tutorial/MMS_ASR_Inference_Colab.ipynb -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/asr/tutorial\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/lid\n",
            "copying fairseq/examples/mms/lid/infer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/lid\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/lid/tutorial\n",
            "copying fairseq/examples/mms/lid/tutorial/MMS_LID_Inference_Colab.ipynb -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/lid/tutorial\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/tts\n",
            "copying fairseq/examples/mms/tts/infer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/tts\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/tts/tutorial\n",
            "copying fairseq/examples/mms/tts/tutorial/MMS_TTS_Inference_Colab.ipynb -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/tts/tutorial\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/data_prep\n",
            "copying fairseq/examples/mms/data_prep/punctuations.lst -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/data_prep\n",
            "copying fairseq/examples/mms/data_prep/align_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/data_prep\n",
            "copying fairseq/examples/mms/data_prep/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/data_prep\n",
            "copying fairseq/examples/mms/data_prep/text_normalization.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/data_prep\n",
            "copying fairseq/examples/mms/data_prep/norm_config.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/data_prep\n",
            "copying fairseq/examples/mms/data_prep/align_and_segment.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mms/data_prep\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/layerdrop\n",
            "copying fairseq/examples/layerdrop/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/layerdrop\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection\n",
            "copying fairseq/examples/attention_head_selection/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src\n",
            "copying fairseq/examples/attention_head_selection/src/speech_to_text_head_selection.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src\n",
            "copying fairseq/examples/attention_head_selection/src/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/models\n",
            "copying fairseq/examples/attention_head_selection/src/models/head_selection_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/models\n",
            "copying fairseq/examples/attention_head_selection/src/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/models\n",
            "copying fairseq/examples/attention_head_selection/src/models/head_selection_s2t_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/multihead_attention_selection.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/multihead_functional.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/attn_head_selector.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/modules\n",
            "copying fairseq/examples/attention_head_selection/src/modules/head_selection_transformer_layer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/loss\n",
            "copying fairseq/examples/attention_head_selection/src/loss/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/loss\n",
            "copying fairseq/examples/attention_head_selection/src/loss/attention_head_selection.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/loss\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/data\n",
            "copying fairseq/examples/attention_head_selection/src/data/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/data\n",
            "copying fairseq/examples/attention_head_selection/src/data/speech_to_text_dataset_with_domain.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/attention_head_selection/src/data\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/data_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/prep_covost_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/prep_mustc_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/seg_mustc_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/prep_mtedx_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text\n",
            "copying fairseq/examples/speech_to_text/prep_librispeech_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/simulst_mustc_example.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/mustc_example.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/covost_example.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/librispeech_example.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text/docs\n",
            "copying fairseq/examples/speech_to_text/docs/mtedx_example.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text/docs\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text/simultaneous_translation\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text/simultaneous_translation/agents\n",
            "copying fairseq/examples/speech_to_text/simultaneous_translation/agents/fairseq_simul_st_agent.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_to_text/simultaneous_translation/agents\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/scaling_nmt\n",
            "copying fairseq/examples/scaling_nmt/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/scaling_nmt\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/translation_moe\n",
            "copying fairseq/examples/translation_moe/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation_moe\n",
            "copying fairseq/examples/translation_moe/score.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation_moe\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/translation_moe/translation_moe_src\n",
            "copying fairseq/examples/translation_moe/translation_moe_src/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation_moe/translation_moe_src\n",
            "copying fairseq/examples/translation_moe/translation_moe_src/logsumexp_moe.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation_moe/translation_moe_src\n",
            "copying fairseq/examples/translation_moe/translation_moe_src/mean_pool_gating_network.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation_moe/translation_moe_src\n",
            "copying fairseq/examples/translation_moe/translation_moe_src/translation_moe.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/translation_moe/translation_moe_src\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion\n",
            "copying fairseq/examples/emotion_conversion/synthesize.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion\n",
            "copying fairseq/examples/emotion_conversion/requirements.txt -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion\n",
            "copying fairseq/examples/emotion_conversion/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/fairseq_models\n",
            "copying fairseq/examples/emotion_conversion/fairseq_models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/fairseq_models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/duration_predictor.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/pitch_predictor.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/duration_predictor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/emotion_models\n",
            "copying fairseq/examples/emotion_conversion/emotion_models/pitch_predictor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/emotion_models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/build_translation_manifests.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/build_hifigan_manifest.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/split_emov_km_tsv_by_uttid.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/create_core_manifest.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/extract_f0.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/split_km.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/process_km.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "copying fairseq/examples/emotion_conversion/preprocess/split_km_tsv.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/emotion_conversion/preprocess\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/joint_alignment_translation\n",
            "copying fairseq/examples/joint_alignment_translation/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/joint_alignment_translation\n",
            "copying fairseq/examples/joint_alignment_translation/prepare-wmt18en2de_no_norm_no_escape_no_agressive.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/joint_alignment_translation\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/fully_sharded_data_parallel\n",
            "copying fairseq/examples/fully_sharded_data_parallel/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/fully_sharded_data_parallel\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/megatron_11b\n",
            "copying fairseq/examples/megatron_11b/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/megatron_11b\n",
            "copying fairseq/examples/megatron_11b/detok.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/megatron_11b\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/ML50_langs.txt -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/multilingual_fairseq_gen.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/finetune_multilingual_model.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual\n",
            "copying fairseq/examples/multilingual/train_multilingual_model.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_iwslt_and_extract.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_wmt19_and_before.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_iitb.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_lotus.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/check_iswlt_test_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/check_self_overlaps.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/dedup_all.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_ML50_v1.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/remove_valid_test_in_train.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/requirement.txt -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/binarize.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_wat19_my.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_ted_and_extract.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/preprocess_ML50_v1.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_wmt20.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_flores_data.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/download_af_xh.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "copying fairseq/examples/multilingual/data_scripts/check_valid_test_overlaps.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts/utils\n",
            "copying fairseq/examples/multilingual/data_scripts/utils/strip_sgm.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts/utils\n",
            "copying fairseq/examples/multilingual/data_scripts/utils/dedup.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts/utils\n",
            "copying fairseq/examples/multilingual/data_scripts/utils/fasttext_multi_filter.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/multilingual/data_scripts/utils\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/data_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/truncated_laplace.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/generate_waveform.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/inference_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/prepare_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/preprocess_f0.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/naive_decoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "copying fairseq/examples/textless_nlp/pgslm/quantize_f0.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/sample\n",
            "copying fairseq/examples/textless_nlp/pgslm/sample/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/sample\n",
            "copying fairseq/examples/textless_nlp/pgslm/sample/sample.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/sample\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/eval\n",
            "copying fairseq/examples/textless_nlp/pgslm/eval/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/eval\n",
            "copying fairseq/examples/textless_nlp/pgslm/eval/cont_metrics.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/eval\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/scripts\n",
            "copying fairseq/examples/textless_nlp/pgslm/scripts/join_units_manifest.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/scripts\n",
            "copying fairseq/examples/textless_nlp/pgslm/scripts/prepare_data.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/scripts\n",
            "copying fairseq/examples/textless_nlp/pgslm/scripts/prepare_f0_quantization.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/pgslm/scripts\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/speech-resynth\n",
            "copying fairseq/examples/textless_nlp/speech-resynth/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/speech-resynth\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/speech-resynth/img\n",
            "copying fairseq/examples/textless_nlp/speech-resynth/img/fig.png -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/speech-resynth/img\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm\n",
            "copying fairseq/examples/textless_nlp/gslm/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/abx_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/abx_metrics/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/abx_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/abx_metrics/dump_abx_feats.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/abx_metrics\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/self_auto_bleu.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/ppx.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/continuation_eval.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/dict.ltr.txt -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/cut_as.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc\n",
            "copying fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc/bleu_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/metrics/asr_metrics/misc\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/tools\n",
            "copying fairseq/examples/textless_nlp/gslm/tools/resynthesize_speech.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/tools\n",
            "copying fairseq/examples/textless_nlp/gslm/tools/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/tools\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/quantize_with_kmeans.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/cluster_kmeans.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/dump_feats.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/clustering/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/clustering\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/w2v2_feature_reader.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/logmel_feature_reader.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/hubert_feature_reader.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/cpc_feature_reader.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "copying fairseq/examples/textless_nlp/gslm/speech2unit/pretrained/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/speech2unit/pretrained\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/ulm\n",
            "copying fairseq/examples/textless_nlp/gslm/ulm/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/ulm\n",
            "copying fairseq/examples/textless_nlp/gslm/ulm/sample.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/ulm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/multiproc.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/glow.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/synthesize_audio_from_units.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tts_data.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/convert_to_16k.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/model.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/audio_processing.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/waveglow_denoiser.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/cleaners.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/cmudict.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/text.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/numbers.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/stft.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/symbols.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "copying fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2/layers.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/gslm/unit2speech/tacotron2\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm\n",
            "copying fairseq/examples/textless_nlp/dgslm/create_code_file.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm\n",
            "copying fairseq/examples/textless_nlp/dgslm/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm\n",
            "copying fairseq/examples/textless_nlp/dgslm/sample_speech_dlm.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm\n",
            "copying fairseq/examples/textless_nlp/dgslm/dgslm_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm/hubert_fisher\n",
            "copying fairseq/examples/textless_nlp/dgslm/hubert_fisher/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm/hubert_fisher\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm/vocoder_hifigan\n",
            "copying fairseq/examples/textless_nlp/dgslm/vocoder_hifigan/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm/vocoder_hifigan\n",
            "copying fairseq/examples/textless_nlp/dgslm/vocoder_hifigan/generate_stereo_waveform.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/textless_nlp/dgslm/vocoder_hifigan\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/nonautoregressive_translation\n",
            "copying fairseq/examples/nonautoregressive_translation/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/nonautoregressive_translation\n",
            "copying fairseq/examples/nonautoregressive_translation/scripts.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/nonautoregressive_translation\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/gottbert\n",
            "copying fairseq/examples/gottbert/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/gottbert\n",
            "copying fairseq/examples/speech_recognition/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition\n",
            "copying fairseq/examples/speech_recognition/new/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/conf\n",
            "copying fairseq/examples/speech_recognition/new/conf/infer.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/conf\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/conf/run_config\n",
            "copying fairseq/examples/speech_recognition/new/conf/run_config/fb_slurm_1.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/conf/run_config\n",
            "copying fairseq/examples/speech_recognition/new/conf/run_config/fb_slurm_2g.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/conf/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/conf/hydra\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/conf/hydra/sweeper\n",
            "copying fairseq/examples/speech_recognition/new/conf/hydra/sweeper/ax_sil.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/conf/hydra/sweeper\n",
            "copying fairseq/examples/speech_recognition/new/conf/hydra/sweeper/ax.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/new/conf/hydra/sweeper\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/datasets\n",
            "copying fairseq/examples/speech_recognition/datasets/asr_prep_json.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/datasets\n",
            "copying fairseq/examples/speech_recognition/datasets/prepare-librispeech.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/datasets\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/utils\n",
            "copying fairseq/examples/speech_recognition/utils/wer_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/utils\n",
            "copying fairseq/examples/speech_recognition/kaldi/add-self-loop-simple.cc -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/kaldi\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/kaldi/config\n",
            "copying fairseq/examples/speech_recognition/kaldi/config/kaldi_initializer.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_recognition/kaldi/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/xmod\n",
            "copying fairseq/examples/xmod/preprocess_nli.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/xmod\n",
            "copying fairseq/examples/xmod/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/xmod\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/mbart\n",
            "copying fairseq/examples/mbart/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/mbart\n",
            "copying fairseq/examples/speech_text_joint_to_text/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/configs\n",
            "copying fairseq/examples/speech_text_joint_to_text/configs/mustc_noise.list -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/configs\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/docs\n",
            "copying fairseq/examples/speech_text_joint_to_text/docs/pre-training.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/docs\n",
            "copying fairseq/examples/speech_text_joint_to_text/docs/ende-mustc.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/docs\n",
            "copying fairseq/examples/speech_text_joint_to_text/docs/iwslt2021.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/docs\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/scripts\n",
            "copying fairseq/examples/speech_text_joint_to_text/scripts/convert_model.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/scripts\n",
            "copying fairseq/examples/speech_text_joint_to_text/scripts/g2p_encode.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/scripts\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/data\n",
            "copying fairseq/examples/speech_text_joint_to_text/data/pair_denoising_dataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/speech_text_joint_to_text/data\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/moe_lm\n",
            "copying fairseq/examples/moe_lm/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/moe_lm\n",
            "copying fairseq/examples/moe_lm/data_card.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/moe_lm\n",
            "copying fairseq/examples/moe_lm/model_card.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/moe_lm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/unsupervised_quality_estimation\n",
            "copying fairseq/examples/unsupervised_quality_estimation/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/unsupervised_quality_estimation\n",
            "copying fairseq/examples/unsupervised_quality_estimation/aggregate_scores.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/unsupervised_quality_estimation\n",
            "copying fairseq/examples/unsupervised_quality_estimation/meteor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/unsupervised_quality_estimation\n",
            "copying fairseq/examples/unsupervised_quality_estimation/repeat_lines.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/unsupervised_quality_estimation\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.race.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.glue.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/multiprocessing_bpe_encoder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/preprocess_RACE.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/preprocess_RACE.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/preprocess_GLUE_tasks.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.custom_classification.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "copying fairseq/examples/roberta/README.pretraining.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/wsc_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/wsc_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/wsc\n",
            "copying fairseq/examples/roberta/wsc/wsc_criterion.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/wsc\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/fb_multilingual\n",
            "copying fairseq/examples/roberta/fb_multilingual/README.multilingual.pretraining.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/fb_multilingual\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/pretraining\n",
            "copying fairseq/examples/roberta/config/pretraining/base.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/pretraining\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/slurm_3.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/local.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/slurm_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/slurm_2_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/pretraining/run_config\n",
            "copying fairseq/examples/roberta/config/pretraining/run_config/slurm_4.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/pretraining/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/rte.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/qqp.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/cola.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/mrpc.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/qnli.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/sts_b.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/mnli.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning\n",
            "copying fairseq/examples/roberta/config/finetuning/sst_2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning/run_config\n",
            "copying fairseq/examples/roberta/config/finetuning/run_config/local.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning/run_config\n",
            "copying fairseq/examples/roberta/config/finetuning/run_config/slurm_1g_aws.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning/run_config\n",
            "copying fairseq/examples/roberta/config/finetuning/run_config/slurm_1g.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/config/finetuning/run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/commonsense_qa\n",
            "copying fairseq/examples/roberta/commonsense_qa/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/commonsense_qa\n",
            "copying fairseq/examples/roberta/commonsense_qa/commonsense_qa_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/commonsense_qa\n",
            "copying fairseq/examples/roberta/commonsense_qa/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/commonsense_qa\n",
            "copying fairseq/examples/roberta/commonsense_qa/download_cqa_data.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/roberta/commonsense_qa\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/constrained_decoding\n",
            "copying fairseq/examples/constrained_decoding/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/constrained_decoding\n",
            "copying fairseq/examples/constrained_decoding/tok.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/constrained_decoding\n",
            "copying fairseq/examples/constrained_decoding/normalize.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/constrained_decoding\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/cross_lingual_language_model\n",
            "copying fairseq/examples/cross_lingual_language_model/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/cross_lingual_language_model\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth\n",
            "copying fairseq/examples/latent_depth/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/multilingual_translation_latent_depth.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/models\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/models\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/models/latent_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/models\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/models/latent_multilingual_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/modules\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/modules/latent_layers.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/modules\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/loss\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/loss/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/loss\n",
            "copying fairseq/examples/latent_depth/latent_depth_src/loss/latent_depth.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/latent_depth/latent_depth_src/loss\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/language_model\n",
            "copying fairseq/examples/language_model/README.conv.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/language_model\n",
            "copying fairseq/examples/language_model/prepare-wikitext-103.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/language_model\n",
            "copying fairseq/examples/language_model/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/language_model\n",
            "copying fairseq/examples/language_model/README.adaptive_inputs.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/language_model\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/shuffled_word_order\n",
            "copying fairseq/examples/shuffled_word_order/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/shuffled_word_order\n",
            "copying fairseq/examples/shuffled_word_order/README.finetuning.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/shuffled_word_order\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/laser\n",
            "copying fairseq/examples/laser/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/laser\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/laser_transformer.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/multitask_data_utils.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/laser_lstm.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/laser/laser_src\n",
            "copying fairseq/examples/laser/laser_src/laser_task.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/laser/laser_src\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/xglm\n",
            "copying fairseq/examples/xglm/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/xglm\n",
            "copying fairseq/examples/xglm/model_card.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/xglm\n",
            "copying fairseq/examples/xglm/XStoryCloze.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/xglm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/stories\n",
            "copying fairseq/examples/stories/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/stories\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/setup.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/locallaunch.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/CONFIG.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/endtask.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/DATASET.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/pretraining.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/videoclip.png -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/.gitignore -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "copying fairseq/examples/MMPT/vlm.png -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt\n",
            "copying fairseq/examples/MMPT/mmpt/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/losses\n",
            "copying fairseq/examples/MMPT/mmpt/losses/loss.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/losses\n",
            "copying fairseq/examples/MMPT/mmpt/losses/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/losses\n",
            "copying fairseq/examples/MMPT/mmpt/losses/nce.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/losses\n",
            "copying fairseq/examples/MMPT/mmpt/losses/fairseqmmloss.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/losses\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/fairseqmmmodel.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/transformermodel.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/mmfusionnlg.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/models\n",
            "copying fairseq/examples/MMPT/mmpt/models/mmfusion.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/modules\n",
            "copying fairseq/examples/MMPT/mmpt/modules/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/modules\n",
            "copying fairseq/examples/MMPT/mmpt/modules/mm.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/modules\n",
            "copying fairseq/examples/MMPT/mmpt/modules/vectorpool.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/modules\n",
            "copying fairseq/examples/MMPT/mmpt/modules/retri.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/modules\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/vlmtask.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/milncetask.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/retritask.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/task.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/tasks\n",
            "copying fairseq/examples/MMPT/mmpt/tasks/fairseqmmtask.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/tasks\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/how2retriprocessor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/dsprocessor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/dedupprocessor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/processor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/processors\n",
            "copying fairseq/examples/MMPT/mmpt/processors/how2processor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/processors\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/processors/models\n",
            "copying fairseq/examples/MMPT/mmpt/processors/models/s3dg.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/processors/models\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/evaluators\n",
            "copying fairseq/examples/MMPT/mmpt/evaluators/predictor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/evaluators\n",
            "copying fairseq/examples/MMPT/mmpt/evaluators/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/evaluators\n",
            "copying fairseq/examples/MMPT/mmpt/evaluators/metric.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/evaluators\n",
            "copying fairseq/examples/MMPT/mmpt/evaluators/evaluator.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/evaluators\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/datasets\n",
            "copying fairseq/examples/MMPT/mmpt/datasets/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/datasets\n",
            "copying fairseq/examples/MMPT/mmpt/datasets/fairseqmmdataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/datasets\n",
            "copying fairseq/examples/MMPT/mmpt/datasets/mmdataset.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/datasets\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/utils\n",
            "copying fairseq/examples/MMPT/mmpt/utils/__init__.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/utils\n",
            "copying fairseq/examples/MMPT/mmpt/utils/load_config.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/utils\n",
            "copying fairseq/examples/MMPT/mmpt/utils/shardedtensor.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt/utils\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects\n",
            "copying fairseq/examples/MMPT/projects/mfmmlm.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri\n",
            "copying fairseq/examples/MMPT/projects/retri/videoretri.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/vtt_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_vtt_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_coin_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/coin_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_youcook_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_youcook_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_vttqa_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/vttqa_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/how2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/crosstask_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_vtt_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/youcook_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_coin_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_crosstask_zs_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_vttqa_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_crosstask_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "copying fairseq/examples/MMPT/projects/retri/videoclip/test_didemo_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/retri/videoclip\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm\n",
            "copying fairseq/examples/MMPT/projects/mtm/mmfusionmtm.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_youcookcap.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_crosstask_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/vttqa.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_coin.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/youcook.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/crosstask.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_vtt.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/how2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/coin.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_vttqa.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/youcookcap.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/vtt.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_youcook.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "copying fairseq/examples/MMPT/projects/mtm/vlm/test_crosstask.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/mtm/vlm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_youcookcap.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_crosstask_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/vttqa.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_coin.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/youcook.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/crosstask.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/vtt_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vtt_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vtt.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_coin_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/coin_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_youcook_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_youcook_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vttqa_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/ft.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/vttqa_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/how2.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/coin.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/crosstask_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vttqa.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/default.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vtt_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/youcook_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/youcookcap.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_coin_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/vtt.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_crosstask_zs_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_youcook.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_vttqa_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_crosstask_videoclip.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_crosstask.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "copying fairseq/examples/MMPT/projects/task/test_didemo_zs.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/projects/task\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/model.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/pathbuilder.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/shard_feature.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/videoreader.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/preprocessing.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/random_sequence_shuffler.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/extract.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor/how2\n",
            "copying fairseq/examples/MMPT/scripts/video_feature_extractor/how2/s3d.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/video_feature_extractor/how2\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/text_token_extractor\n",
            "copying fairseq/examples/MMPT/scripts/text_token_extractor/pretokenization.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/text_token_extractor\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/text_token_extractor/configs\n",
            "copying fairseq/examples/MMPT/scripts/text_token_extractor/configs/bert-base-uncased.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/scripts/text_token_extractor/configs\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt_cli\n",
            "copying fairseq/examples/MMPT/mmpt_cli/localjob.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt_cli\n",
            "copying fairseq/examples/MMPT/mmpt_cli/predict.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/MMPT/mmpt_cli\n",
            "copying fairseq/examples/simultaneous_translation/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/eval\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/eval/agents\n",
            "copying fairseq/examples/simultaneous_translation/eval/agents/simul_t2t_enja.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/eval/agents\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/tests\n",
            "copying fairseq/examples/simultaneous_translation/tests/test_text_models.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/tests\n",
            "copying fairseq/examples/simultaneous_translation/tests/test_alignment_train.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/tests\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/docs\n",
            "copying fairseq/examples/simultaneous_translation/docs/enja-waitk.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/docs\n",
            "copying fairseq/examples/simultaneous_translation/docs/ende-mma.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/simultaneous_translation/docs\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/flores101\n",
            "copying fairseq/examples/flores101/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/flores101\n",
            "copying fairseq/examples/flores101/flores_logo.png -> build/lib.linux-x86_64-cpython-310/fairseq/examples/flores101\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/bart\n",
            "copying fairseq/examples/bart/README.glue.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/bart\n",
            "copying fairseq/examples/bart/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/bart\n",
            "copying fairseq/examples/bart/summarize.py -> build/lib.linux-x86_64-cpython-310/fairseq/examples/bart\n",
            "copying fairseq/examples/bart/README.summarization.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/bart\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/examples/normformer\n",
            "copying fairseq/examples/normformer/README.md -> build/lib.linux-x86_64-cpython-310/fairseq/examples/normformer\n",
            "copying fairseq/examples/normformer/train_lm.sh -> build/lib.linux-x86_64-cpython-310/fairseq/examples/normformer\n",
            "copying fairseq/config/config.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/config/fb_run_config\n",
            "copying fairseq/config/fb_run_config/slurm.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/fb_run_config\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/config/model\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_wiki103.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gpt2_small.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_baevski_wiki103.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gbw.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_big.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gpt.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gpt2_medium.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_gpt2_big.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "copying fairseq/config/model/transformer_lm/transformer_lm_baevski_gbw.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/transformer_lm\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/config/model/wav2vec\n",
            "copying fairseq/config/model/wav2vec/vq_wav2vec_gumbel.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/wav2vec\n",
            "creating build/lib.linux-x86_64-cpython-310/fairseq/config/model/wav2vec2\n",
            "copying fairseq/config/model/wav2vec2/wav2vec2_large.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/wav2vec2\n",
            "copying fairseq/config/model/wav2vec2/wav2vec2_base.yaml -> build/lib.linux-x86_64-cpython-310/fairseq/config/model/wav2vec2\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:500: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "building 'fairseq.libbleu' extension\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "creating build/temp.linux-x86_64-cpython-310/fairseq\n",
            "creating build/temp.linux-x86_64-cpython-310/fairseq/clib\n",
            "creating build/temp.linux-x86_64-cpython-310/fairseq/clib/libbleu\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/python3.10 -c fairseq/clib/libbleu/libbleu.cpp -o build/temp.linux-x86_64-cpython-310/fairseq/clib/libbleu/libbleu.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/include/python3.10 -c fairseq/clib/libbleu/module.cpp -o build/temp.linux-x86_64-cpython-310/fairseq/clib/libbleu/module.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=libbleu -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/fairseq/clib/libbleu/libbleu.o build/temp.linux-x86_64-cpython-310/fairseq/clib/libbleu/module.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-310/fairseq/libbleu.cpython-310-x86_64-linux-gnu.so\n",
            "building 'fairseq.data.data_utils_fast' extension\n",
            "creating build/temp.linux-x86_64-cpython-310/fairseq/data\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I/usr/include/python3.10 -c fairseq/data/data_utils_fast.cpp -o build/temp.linux-x86_64-cpython-310/fairseq/data/data_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=data_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1929\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/arrayobject.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kfairseq/data/data_utils_fast.cpp:1273\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wcpp\u0007-Wcpp\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/fairseq/data/data_utils_fast.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-310/fairseq/data/data_utils_fast.cpython-310-x86_64-linux-gnu.so\n",
            "building 'fairseq.data.token_block_utils_fast' extension\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I/usr/local/lib/python3.10/dist-packages/numpy/core/include -I/usr/include/python3.10 -c fairseq/data/token_block_utils_fast.cpp -o build/temp.linux-x86_64-cpython-310/fairseq/data/token_block_utils_fast.o -std=c++11 -O3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=token_block_utils_fast -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/ndarraytypes.h:1929\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/ndarrayobject.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/arrayobject.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kfairseq/data/token_block_utils_fast.cpp:1274\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.10/dist-packages/numpy/core/include/numpy/npy_1_7_deprecated_api.h:17:2:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K#warning \"Using deprecated NumPy API, disable it with \" \"#define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\" [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wcpp\u0007-Wcpp\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   17 | #\u001b[01;35m\u001b[Kwarning\u001b[m\u001b[K \"Using deprecated NumPy API, disable it with \" \\\n",
            "      |  \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/fairseq/data/token_block_utils_fast.o -L/usr/lib/x86_64-linux-gnu -o build/lib.linux-x86_64-cpython-310/fairseq/data/token_block_utils_fast.cpython-310-x86_64-linux-gnu.so\n",
            "building 'fairseq.libbase' extension\n",
            "creating build/temp.linux-x86_64-cpython-310/fairseq/clib/libbase\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/include/python3.10 -c fairseq/clib/libbase/balanced_assignment.cpp -o build/temp.linux-x86_64-cpython-310/fairseq/clib/libbase/balanced_assignment.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=libbase -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/fairseq/clib/libbase/balanced_assignment.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-310/fairseq/libbase.cpython-310-x86_64-linux-gnu.so\n",
            "building 'fairseq.libnat' extension\n",
            "creating build/temp.linux-x86_64-cpython-310/fairseq/clib/libnat\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/include/python3.10 -c fairseq/clib/libnat/edit_dist.cpp -o build/temp.linux-x86_64-cpython-310/fairseq/clib/libnat/edit_dist.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=libnat -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/fairseq/clib/libnat/edit_dist.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-310/fairseq/libnat.cpython-310-x86_64-linux-gnu.so\n",
            "building 'alignment_train_cpu_binding' extension\n",
            "creating build/temp.linux-x86_64-cpython-310/examples\n",
            "creating build/temp.linux-x86_64-cpython-310/examples/operators\n",
            "x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/include/python3.10 -c examples/operators/alignment_train_cpu.cpp -o build/temp.linux-x86_64-cpython-310/examples/operators/alignment_train_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=alignment_train_cpu_binding -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = double]\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:131:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid free(void*)\u001b[m\u001b[K’ called on pointer returned from a mismatched allocation function [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmismatched-new-delete\u0007-Wmismatched-new-delete\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  131 |   \u001b[01;35m\u001b[Kfree(cumprod_1mp)\u001b[m\u001b[K;\n",
            "      |   \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:93:20:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kreturned from ‘\u001b[01m\u001b[Kvoid* operator new [](std::size_t)\u001b[m\u001b[K’\n",
            "   93 |   T* cumprod_1mp = \u001b[01;36m\u001b[Knew T[elements]\u001b[m\u001b[K;\n",
            "      |                    \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = double]\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:132:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid free(void*)\u001b[m\u001b[K’ called on pointer returned from a mismatched allocation function [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmismatched-new-delete\u0007-Wmismatched-new-delete\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  132 |   \u001b[01;35m\u001b[Kfree(cumprod_1mp_clamp)\u001b[m\u001b[K;\n",
            "      |   \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:94:26:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kreturned from ‘\u001b[01m\u001b[Kvoid* operator new [](std::size_t)\u001b[m\u001b[K’\n",
            "   94 |   T* cumprod_1mp_clamp = \u001b[01;36m\u001b[Knew T[elements]\u001b[m\u001b[K;\n",
            "      |                          \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = float]\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:131:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid free(void*)\u001b[m\u001b[K’ called on pointer returned from a mismatched allocation function [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmismatched-new-delete\u0007-Wmismatched-new-delete\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  131 |   \u001b[01;35m\u001b[Kfree(cumprod_1mp)\u001b[m\u001b[K;\n",
            "      |   \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:93:20:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kreturned from ‘\u001b[01m\u001b[Kvoid* operator new [](std::size_t)\u001b[m\u001b[K’\n",
            "   93 |   T* cumprod_1mp = \u001b[01;36m\u001b[Knew T[elements]\u001b[m\u001b[K;\n",
            "      |                    \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = float]\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:132:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid free(void*)\u001b[m\u001b[K’ called on pointer returned from a mismatched allocation function [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmismatched-new-delete\u0007-Wmismatched-new-delete\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  132 |   \u001b[01;35m\u001b[Kfree(cumprod_1mp_clamp)\u001b[m\u001b[K;\n",
            "      |   \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:94:26:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kreturned from ‘\u001b[01m\u001b[Kvoid* operator new [](std::size_t)\u001b[m\u001b[K’\n",
            "   94 |   T* cumprod_1mp_clamp = \u001b[01;36m\u001b[Knew T[elements]\u001b[m\u001b[K;\n",
            "      |                          \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = c10::Half]\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:131:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid free(void*)\u001b[m\u001b[K’ called on pointer returned from a mismatched allocation function [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmismatched-new-delete\u0007-Wmismatched-new-delete\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  131 |   \u001b[01;35m\u001b[Kfree(cumprod_1mp)\u001b[m\u001b[K;\n",
            "      |   \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:93:20:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kreturned from ‘\u001b[01m\u001b[Kvoid* operator new [](std::size_t)\u001b[m\u001b[K’\n",
            "   93 |   T* cumprod_1mp = \u001b[01;36m\u001b[Knew T[elements]\u001b[m\u001b[K;\n",
            "      |                    \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = c10::Half]\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:132:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid free(void*)\u001b[m\u001b[K’ called on pointer returned from a mismatched allocation function [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmismatched-new-delete\u0007-Wmismatched-new-delete\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  132 |   \u001b[01;35m\u001b[Kfree(cumprod_1mp_clamp)\u001b[m\u001b[K;\n",
            "      |   \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:94:26:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kreturned from ‘\u001b[01m\u001b[Kvoid* operator new [](std::size_t)\u001b[m\u001b[K’\n",
            "   94 |   T* cumprod_1mp_clamp = \u001b[01;36m\u001b[Knew T[elements]\u001b[m\u001b[K;\n",
            "      |                          \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = c10::BFloat16]\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:131:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid free(void*)\u001b[m\u001b[K’ called on pointer returned from a mismatched allocation function [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmismatched-new-delete\u0007-Wmismatched-new-delete\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  131 |   \u001b[01;35m\u001b[Kfree(cumprod_1mp)\u001b[m\u001b[K;\n",
            "      |   \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:93:20:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kreturned from ‘\u001b[01m\u001b[Kvoid* operator new [](std::size_t)\u001b[m\u001b[K’\n",
            "   93 |   T* cumprod_1mp = \u001b[01;36m\u001b[Knew T[elements]\u001b[m\u001b[K;\n",
            "      |                    \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPUImpl(const T*, T*, uint32_t, uint32_t, uint32_t, float) [with T = c10::BFloat16]\u001b[m\u001b[K’,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[K{anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)::<lambda()>\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K,\n",
            "    inlined from ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’ at \u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:143:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:132:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kvoid free(void*)\u001b[m\u001b[K’ called on pointer returned from a mismatched allocation function [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wmismatched-new-delete\u0007-Wmismatched-new-delete\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  132 |   \u001b[01;35m\u001b[Kfree(cumprod_1mp_clamp)\u001b[m\u001b[K;\n",
            "      |   \u001b[01;35m\u001b[K~~~~^~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid {anonymous}::alignmentTrainCPU(const at::Tensor&, at::Tensor&, float)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexamples/operators/alignment_train_cpu.cpp:94:26:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kreturned from ‘\u001b[01m\u001b[Kvoid* operator new [](std::size_t)\u001b[m\u001b[K’\n",
            "   94 |   T* cumprod_1mp_clamp = \u001b[01;36m\u001b[Knew T[elements]\u001b[m\u001b[K;\n",
            "      |                          \u001b[01;36m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-g++ -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/examples/operators/alignment_train_cpu.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-310/alignment_train_cpu_binding.cpython-310-x86_64-linux-gnu.so\n",
            "running develop\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  easy_install.initialize_options(self)\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running egg_info\n",
            "writing fairseq.egg-info/PKG-INFO\n",
            "writing dependency_links to fairseq.egg-info/dependency_links.txt\n",
            "writing entry points to fairseq.egg-info/entry_points.txt\n",
            "writing requirements to fairseq.egg-info/requires.txt\n",
            "writing top-level names to fairseq.egg-info/top_level.txt\n",
            "reading manifest file 'fairseq.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'fairseq.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "copying build/lib.linux-x86_64-cpython-310/fairseq/libbleu.cpython-310-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-cpython-310/fairseq/data/data_utils_fast.cpython-310-x86_64-linux-gnu.so -> fairseq/data\n",
            "copying build/lib.linux-x86_64-cpython-310/fairseq/data/token_block_utils_fast.cpython-310-x86_64-linux-gnu.so -> fairseq/data\n",
            "copying build/lib.linux-x86_64-cpython-310/fairseq/libbase.cpython-310-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-cpython-310/fairseq/libnat.cpython-310-x86_64-linux-gnu.so -> fairseq\n",
            "copying build/lib.linux-x86_64-cpython-310/alignment_train_cpu_binding.cpython-310-x86_64-linux-gnu.so -> \n",
            "Creating /usr/local/lib/python3.10/dist-packages/fairseq.egg-link (link to .)\n",
            "Adding fairseq 0.12.2 to easy-install.pth file\n",
            "Installing fairseq-eval-lm script to /usr/local/bin\n",
            "Installing fairseq-generate script to /usr/local/bin\n",
            "Installing fairseq-hydra-train script to /usr/local/bin\n",
            "Installing fairseq-interactive script to /usr/local/bin\n",
            "Installing fairseq-preprocess script to /usr/local/bin\n",
            "Installing fairseq-score script to /usr/local/bin\n",
            "Installing fairseq-train script to /usr/local/bin\n",
            "Installing fairseq-validate script to /usr/local/bin\n",
            "\n",
            "Installed /content/fairseq\n",
            "Processing dependencies for fairseq==0.12.2\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py\", line 3108, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/_vendor/packaging/requirements.py\", line 35, in __init__\n",
            "    parsed = parse_requirement(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/_vendor/packaging/_parser.py\", line 64, in parse_requirement\n",
            "    return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/_vendor/packaging/_parser.py\", line 82, in _parse_requirement\n",
            "    url, specifier, marker = _parse_requirement_details(tokenizer)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/_vendor/packaging/_parser.py\", line 120, in _parse_requirement_details\n",
            "    specifier = _parse_specifier(tokenizer)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/_vendor/packaging/_parser.py\", line 206, in _parse_specifier\n",
            "    with tokenizer.enclosing_tokens(\"LEFT_PARENTHESIS\", \"RIGHT_PARENTHESIS\"):\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 142, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/_vendor/packaging/_tokenizer.py\", line 183, in enclosing_tokens\n",
            "    self.raise_syntax_error(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/_vendor/packaging/_tokenizer.py\", line 163, in raise_syntax_error\n",
            "    raise ParserSyntaxError(\n",
            "pkg_resources.extern.packaging._tokenizer.ParserSyntaxError: Expected closing RIGHT_PARENTHESIS\n",
            "    PyYAML (>=5.1.*)\n",
            "           ~~~~~~^\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/fairseq/setup.py\", line 254, in <module>\n",
            "    do_setup(package_data)\n",
            "  File \"/content/fairseq/setup.py\", line 164, in do_setup\n",
            "    setup(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/__init__.py\", line 107, in setup\n",
            "    return distutils.core.setup(**attrs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/core.py\", line 185, in setup\n",
            "    return run_commands(dist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/core.py\", line 201, in run_commands\n",
            "    dist.run_commands()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/dist.py\", line 969, in run_commands\n",
            "    self.run_command(cmd)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/dist.py\", line 1244, in run_command\n",
            "    super().run_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/dist.py\", line 988, in run_command\n",
            "    cmd_obj.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py\", line 34, in run\n",
            "    self.install_for_development()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py\", line 130, in install_for_development\n",
            "    self.process_distribution(None, self.dist, not self.no_deps)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/setuptools/command/easy_install.py\", line 750, in process_distribution\n",
            "    distros = WorkingSet([]).resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py\", line 832, in resolve\n",
            "    new_requirements = dist.requires(req.extras)[::-1]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py\", line 2821, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py\", line 3110, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py\", line 3173, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pkg_resources/_vendor/packaging/requirements.py\", line 37, in __init__\n",
            "    raise InvalidRequirement(str(e)) from e\n",
            "pkg_resources.extern.packaging.requirements.InvalidRequirement: Expected closing RIGHT_PARENTHESIS\n",
            "    PyYAML (>=5.1.*)\n",
            "           ~~~~~~^\n"
          ]
        }
      ],
      "source": [
        "!cd /content/fairseq && python setup.py build develop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IqFBFv_8WxY",
        "outputId": "fb05390d-d818-4deb-97dd-9cd81be671c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampling rate: 22050 Hz\n"
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "\n",
        "# Function to check the sampling rate of a .wav file\n",
        "def check_sampling_rate(file_path):\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "    return sr\n",
        "\n",
        "# Example usage:\n",
        "file_path = \"/content/TGT_AUDIO/train/1.wav\"\n",
        "sampling_rate = check_sampling_rate(file_path)\n",
        "print(\"Sampling rate:\", sampling_rate, \"Hz\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjTOINkq8rTL"
      },
      "source": [
        "#resampling done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7-B51wn0hvS",
        "outputId": "d86c0ae6-fe9e-4e91-a76c-1b95f3399d93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-04-28 17:50:14.093608: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-28 17:50:14.093656: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-28 17:50:14.095114: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-28 17:50:14.103125: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-28 17:50:15.228426: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX\n",
            "Processing train...\n",
            "100% 1215/1215 [00:00<00:00, 11318.33it/s]\n",
            "Processed 1215 samples\n",
            "Processing dev...\n",
            "100% 140/140 [00:00<00:00, 11295.40it/s]\n",
            "Processed 140 samples\n",
            "Processing test...\n",
            "100% 292/292 [00:00<00:00, 11740.87it/s]\n",
            "Processed 292 samples\n",
            "Extracting Mel spectrogram features...\n",
            "100% 1647/1647 [01:18<00:00, 21.01it/s]\n",
            "ZIPing features...\n",
            "100% 1647/1647 [00:01<00:00, 1082.53it/s]\n",
            "Fetching ZIP manifest...\n",
            "100% 1647/1647 [00:00<00:00, 4218.91it/s]\n",
            "Generating manifest...\n",
            "Processing train...\n",
            "100% 1215/1215 [00:00<00:00, 1301680.55it/s]\n",
            "Writing manifest to /content/DATA_ROOT/train.tsv...\n",
            "Processing dev...\n",
            "100% 140/140 [00:00<00:00, 935035.92it/s]\n",
            "Writing manifest to /content/DATA_ROOT/dev.tsv...\n",
            "Processing test...\n",
            "100% 292/292 [00:00<00:00, 1030056.15it/s]\n",
            "Writing manifest to /content/DATA_ROOT/test.tsv...\n"
          ]
        }
      ],
      "source": [
        "#spectrogram starting\n",
        "! cd /content/fairseq && python examples/speech_to_speech/preprocessing/prep_s2spect_data.py --source-dir /content/SRC_AUDIO --target-dir /content/TGT_AUDIO --data-split train dev test --output-root /content/DATA_ROOT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OG95f4Bi3vks"
      },
      "outputs": [],
      "source": [
        "# things i did before making the above cell work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oVQXl3k2WgS"
      },
      "outputs": [],
      "source": [
        "# basis = librosa.filters.mel(sample_rate, n_fft, n_mels, f_min, f_max)\n",
        "# TypeError: mel() takes 0 positional arguments but 5 were given\n",
        "\n",
        "# to overcome this error imma go to that file name and change a few things in the\n",
        "#/content/fairseq/fairseq/data/audio/audio_utils.py\n",
        "#in line: the change i did: 343 basis = librosa.filters.mel(sr=sample_rate,n_fft= n_fft,n_mels= n_mels, fmin=f_min, fmax=f_max\n",
        "# https://stackoverflow.com/questions/75796284/typeerror-mel-takes-0-positional-arguments-but-5-were-given\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbGxwp-a1RkA",
        "outputId": "44d0c982-47df-4a03-c06c-52707669ce17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libao-common libao4 libid3tag0 libmad0 libopencore-amrnb0 libopencore-amrwb0\n",
            "  libsox-fmt-all libsox-fmt-alsa libsox-fmt-ao libsox-fmt-base libsox-fmt-mp3\n",
            "  libsox-fmt-oss libsox-fmt-pulse libsox3 libwavpack1\n",
            "Suggested packages:\n",
            "  libaudio2 libsndio6.1\n",
            "The following NEW packages will be installed:\n",
            "  libao-common libao4 libid3tag0 libmad0 libopencore-amrnb0 libopencore-amrwb0\n",
            "  libsox-dev libsox-fmt-all libsox-fmt-alsa libsox-fmt-ao libsox-fmt-base\n",
            "  libsox-fmt-mp3 libsox-fmt-oss libsox-fmt-pulse libsox3 libwavpack1\n",
            "0 upgraded, 16 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 1,053 kB of archives.\n",
            "After this operation, 4,061 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libao-common all 1.2.2+20180113-1.1ubuntu3 [6,568 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libao4 amd64 1.2.2+20180113-1.1ubuntu3 [35.2 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libid3tag0 amd64 0.15.1b-14 [31.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmad0 amd64 0.15.1b-10ubuntu1 [63.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrnb0 amd64 0.1.5-1 [94.8 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrwb0 amd64 0.1.5-1 [49.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [240 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [11.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-ao amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [7,740 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwavpack1 amd64 5.4.0-1build2 [83.7 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-base amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [33.7 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-mp3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [17.3 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-oss amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [9,424 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-pulse amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [7,732 B]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-all amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [5,016 B]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-dev amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [356 kB]\n",
            "Fetched 1,053 kB in 4s (258 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 16.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libao-common.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libao-common_1.2.2+20180113-1.1ubuntu3_all.deb ...\n",
            "Unpacking libao-common (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Selecting previously unselected package libao4:amd64.\n",
            "Preparing to unpack .../01-libao4_1.2.2+20180113-1.1ubuntu3_amd64.deb ...\n",
            "Unpacking libao4:amd64 (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Selecting previously unselected package libid3tag0:amd64.\n",
            "Preparing to unpack .../02-libid3tag0_0.15.1b-14_amd64.deb ...\n",
            "Unpacking libid3tag0:amd64 (0.15.1b-14) ...\n",
            "Selecting previously unselected package libmad0:amd64.\n",
            "Preparing to unpack .../03-libmad0_0.15.1b-10ubuntu1_amd64.deb ...\n",
            "Unpacking libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "Preparing to unpack .../04-libopencore-amrnb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../05-libopencore-amrwb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../06-libsox3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../07-libsox-fmt-alsa_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-ao:amd64.\n",
            "Preparing to unpack .../08-libsox-fmt-ao_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-ao:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libwavpack1:amd64.\n",
            "Preparing to unpack .../09-libwavpack1_5.4.0-1build2_amd64.deb ...\n",
            "Unpacking libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../10-libsox-fmt-base_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-mp3:amd64.\n",
            "Preparing to unpack .../11-libsox-fmt-mp3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-oss:amd64.\n",
            "Preparing to unpack .../12-libsox-fmt-oss_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-oss:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-pulse:amd64.\n",
            "Preparing to unpack .../13-libsox-fmt-pulse_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-pulse:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-all:amd64.\n",
            "Preparing to unpack .../14-libsox-fmt-all_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-all:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-dev:amd64.\n",
            "Preparing to unpack .../15-libsox-dev_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-dev:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-oss:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libao-common (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Setting up libid3tag0:amd64 (0.15.1b-14) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libao4:amd64 (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Setting up libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
            "Setting up libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-ao:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-pulse:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-all:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-dev:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# installing this, since i got an error in the above cell\n",
        "!sudo apt install libsox-dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VOL7iSOwAGY"
      },
      "source": [
        "_________________________________________________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0GA3bSx3Hs1",
        "outputId": "399ba8dd-fb66-426a-c14b-2fe293e3669b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-04-28 17:56:20.847920: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-28 17:56:20.847994: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-28 17:56:20.849478: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-28 17:56:20.857027: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-28 17:56:21.903448: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-04-28 17:56:22 | INFO | numexpr.utils | NumExpr defaulting to 8 threads.\n",
            "2024-04-28 17:56:24 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n",
            "2024-04-28 17:56:26 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 80000, 'batch_size': None, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'dev', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 30000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/content/SAVE_DIR_TRAINING', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'mcd_loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='speech_to_spectrogram', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', simul_type=None, scoring='bleu', task='speech_to_speech', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=80000, batch_size=None, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid='30000', batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2spect_transformer', max_epoch=0, max_update=400000, stop_time_hours=0, clip_norm=10.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/content/SAVE_DIR_TRAINING', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='mcd_loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/content/DATA_ROOT', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=3000, target_is_code=False, target_code_size=None, n_frames_per_step=5, eval_inference=True, eval_args='{}', eos_prob_threshold=0.5, mcd_normalize_type='targ', vocoder='griffin_lim', spec_bwd_max_iter=8, infer_target_lang='', bce_pos_weight=1.0, use_guided_attention_loss=False, guided_attention_loss_sigma=0.4, ctc_weight=0.0, adam_betas='(0.9,0.98)', adam_eps=1e-08, weight_decay=1e-06, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=1e-07, pad=1, eos=2, unk=3, decoder_normalize_before=True, dropout=0.1, attention_dropout=0.1, activation_dropout=0.1, no_seed_provided=False, encoder_freezing_updates=0, input_channels=1, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=12, encoder_attention_heads=8, encoder_normalize_before=True, no_scale_embedding=False, speaker_embed_dim=256, output_frame_dim=80, prenet_dropout=0.5, prenet_layers=2, prenet_dim=256, postnet_dropout=0.5, postnet_layers=5, postnet_conv_dim=512, postnet_conv_kernel_size=5, decoder_transformer_layers=6, decoder_embed_dim=512, decoder_ffn_embed_dim=2048, decoder_attention_heads=4, _name='s2spect_transformer'), 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='speech_to_spectrogram', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', simul_type=None, scoring='bleu', task='speech_to_speech', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=80000, batch_size=None, required_batch_size_multiple=1, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid='30000', batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2spect_transformer', max_epoch=0, max_update=400000, stop_time_hours=0, clip_norm=10.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/content/SAVE_DIR_TRAINING', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='mcd_loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/content/DATA_ROOT', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=3000, target_is_code=False, target_code_size=None, n_frames_per_step=5, eval_inference=True, eval_args='{}', eos_prob_threshold=0.5, mcd_normalize_type='targ', vocoder='griffin_lim', spec_bwd_max_iter=8, infer_target_lang='', bce_pos_weight=1.0, use_guided_attention_loss=False, guided_attention_loss_sigma=0.4, ctc_weight=0.0, adam_betas='(0.9,0.98)', adam_eps=1e-08, weight_decay=1e-06, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=1e-07, pad=1, eos=2, unk=3, decoder_normalize_before=True, dropout=0.1, attention_dropout=0.1, activation_dropout=0.1, no_seed_provided=False, encoder_freezing_updates=0, input_channels=1, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=12, encoder_attention_heads=8, encoder_normalize_before=True, no_scale_embedding=False, speaker_embed_dim=256, output_frame_dim=80, prenet_dropout=0.5, prenet_layers=2, prenet_dim=256, postnet_dropout=0.5, postnet_layers=5, postnet_conv_dim=512, postnet_conv_kernel_size=5, decoder_transformer_layers=6, decoder_embed_dim=512, decoder_ffn_embed_dim=2048, decoder_attention_heads=4, _name='speech_to_speech'), 'criterion': {'_name': 'speech_to_spectrogram', 'bce_pos_weight': 1.0, 'use_guided_attention_loss': False, 'guided_attention_loss_sigma': 0.4, 'ctc_weight': 0.0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 1e-06, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 10000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}\n",
            "2024-04-28 17:56:27 | INFO | fairseq_cli.train | S2SpecTTransformerModel(\n",
            "  (encoder): S2STransformerEncoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (subsample): Conv1dSubsampler(\n",
            "      (conv_layers): ModuleList(\n",
            "        (0): Conv1d(240, 1024, kernel_size=(5,), stride=(2,), padding=(2,))\n",
            "        (1): Conv1d(512, 1024, kernel_size=(5,), stride=(2,), padding=(2,))\n",
            "      )\n",
            "    )\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-11): 12 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TTSTransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (prenet): Sequential(\n",
            "      (0): Prenet(\n",
            "        (layers): ModuleList(\n",
            "          (0): Sequential(\n",
            "            (0): Linear(in_features=400, out_features=256, bias=True)\n",
            "            (1): ReLU()\n",
            "          )\n",
            "          (1): Sequential(\n",
            "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
            "            (1): ReLU()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): Linear(in_features=256, out_features=512, bias=True)\n",
            "    )\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-5): 6 x TransformerDecoderLayer(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "    (feat_proj): Linear(in_features=512, out_features=400, bias=True)\n",
            "    (eos_proj): Linear(in_features=512, out_features=1, bias=True)\n",
            "    (postnet): Postnet(\n",
            "      (convolutions): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Conv1d(400, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Tanh()\n",
            "          (3): Dropout(p=0.5, inplace=False)\n",
            "        )\n",
            "        (1-3): 3 x Sequential(\n",
            "          (0): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Tanh()\n",
            "          (3): Dropout(p=0.5, inplace=False)\n",
            "        )\n",
            "        (4): Sequential(\n",
            "          (0): Conv1d(512, 400, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "          (1): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Dropout(p=0.5, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2024-04-28 17:56:27 | INFO | fairseq_cli.train | task: SpeechToSpeechTask\n",
            "2024-04-28 17:56:27 | INFO | fairseq_cli.train | model: S2SpecTTransformerModel\n",
            "2024-04-28 17:56:27 | INFO | fairseq_cli.train | criterion: SpeechToSpectrogramMultitaskTaskCriterion\n",
            "2024-04-28 17:56:27 | INFO | fairseq_cli.train | num. shared model params: 73,400,386 (num. trained: 73,400,386)\n",
            "2024-04-28 17:56:27 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2024-04-28 17:56:27 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.\n",
            "2024-04-28 17:56:27 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToSpeechDataset(split=\"dev\", n_samples=140, prepend_tgt_lang_tag=False, n_frames_per_step=5, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(\n",
            "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
            "    DeltaDeltas\n",
            "), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
            "))\n",
            "2024-04-28 17:56:27 | INFO | fairseq.data.audio.speech_to_speech_dataset | SpeechToSpeechDataset(split=\"dev\", n_samples=140, prepend_tgt_lang_tag=False, n_frames_per_step=5, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(\n",
            "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
            "    DeltaDeltas\n",
            "), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
            "))\n",
            "2024-04-28 17:56:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-04-28 17:56:27 | INFO | fairseq.utils | rank   0: capabilities =  7.5  ; total memory = 14.748 GB ; name = Tesla T4                                \n",
            "2024-04-28 17:56:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2024-04-28 17:56:27 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2024-04-28 17:56:27 | INFO | fairseq_cli.train | max tokens per device = 80000 and max sentences per device = None\n",
            "2024-04-28 17:56:27 | INFO | fairseq.trainer | Preparing to load checkpoint /content/SAVE_DIR_TRAINING/checkpoint_last.pt\n",
            "2024-04-28 17:56:27 | INFO | fairseq.trainer | No existing checkpoint found /content/SAVE_DIR_TRAINING/checkpoint_last.pt\n",
            "2024-04-28 17:56:27 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2024-04-28 17:56:27 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.\n",
            "2024-04-28 17:56:27 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToSpeechDataset(split=\"train\", n_samples=1_215, prepend_tgt_lang_tag=False, n_frames_per_step=5, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(\n",
            "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
            "    DeltaDeltas\n",
            "    SpecAugmentTransform(time_warp_w=0, freq_mask_n=1, freq_mask_f=27, time_mask_n=1, time_mask_t=100, time_mask_p=1.0)\n",
            "), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
            "))\n",
            "2024-04-28 17:56:27 | INFO | fairseq.data.audio.speech_to_speech_dataset | SpeechToSpeechDataset(split=\"train\", n_samples=1_215, prepend_tgt_lang_tag=False, n_frames_per_step=5, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(\n",
            "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
            "    DeltaDeltas\n",
            "    SpecAugmentTransform(time_warp_w=0, freq_mask_n=1, freq_mask_f=27, time_mask_n=1, time_mask_t=100, time_mask_p=1.0)\n",
            "), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
            "))\n",
            "2024-04-28 17:56:27 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 17:56:27 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n",
            "2024-04-28 17:56:27 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n",
            "2024-04-28 17:56:27 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n",
            "2024-04-28 17:56:29 | INFO | fairseq_cli.train | begin dry-run validation on \"dev\" subset\n",
            "2024-04-28 17:56:29 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 17:56:29 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True\n",
            "2024-04-28 17:56:29 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False\n",
            "2024-04-28 17:56:29 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "2024-04-28 17:56:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 001:   0% 0/29 [00:00<?, ?it/s]2024-04-28 17:56:32 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2024-04-28 17:56:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "epoch 001:  97% 28/29 [00:27<00:00,  1.10it/s]2024-04-28 17:57:01 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 17:57:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 001 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 001 | valid on 'dev' subset:  10% 1/10 [00:51<07:41, 51.28s/it]\u001b[A\n",
            "epoch 001 | valid on 'dev' subset:  20% 2/10 [01:49<07:21, 55.22s/it]\u001b[A\n",
            "epoch 001 | valid on 'dev' subset:  30% 3/10 [02:57<07:09, 61.36s/it]\u001b[A\n",
            "epoch 001 | valid on 'dev' subset:  40% 4/10 [04:10<06:33, 65.59s/it]\u001b[A\n",
            "epoch 001 | valid on 'dev' subset:  50% 5/10 [05:28<05:51, 70.26s/it]\u001b[A\n",
            "epoch 001 | valid on 'dev' subset:  60% 6/10 [06:55<05:03, 75.87s/it]\u001b[A\n",
            "epoch 001 | valid on 'dev' subset:  70% 7/10 [08:24<04:00, 80.29s/it]\u001b[A\n",
            "epoch 001 | valid on 'dev' subset:  80% 8/10 [10:01<02:50, 85.42s/it]\u001b[A\n",
            "epoch 001 | valid on 'dev' subset:  90% 9/10 [11:55<01:34, 94.60s/it]\u001b[A\n",
            "epoch 001 | valid on 'dev' subset: 100% 10/10 [12:35<00:00, 77.72s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 18:09:36 | INFO | dev | epoch 001 | valid on 'dev' subset | loss 94.013 | l1_loss 12.023 | mse_loss 81.679 | eos_loss 0.315 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 379.516 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 34.6 | wpb 2604.4 | bsz 14 | num_updates 29\n",
            "2024-04-28 18:09:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 29 updates\n",
            "2024-04-28 18:09:36 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint1.pt\n",
            "2024-04-28 18:09:38 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint1.pt\n",
            "2024-04-28 18:09:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint1.pt (epoch 1 @ 29 updates, score 379.516) (writing took 10.277861272999871 seconds)\n",
            "2024-04-28 18:09:47 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2024-04-28 18:09:47 | INFO | train | epoch 001 | loss 89.939 | l1_loss 11.507 | mse_loss 77.828 | eos_loss 0.601 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 324.2 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 29 | lr 1.54971e-06 | gnorm 0.006 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.3 | wall 799\n",
            "2024-04-28 18:09:47 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 18:09:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 002:   0% 0/29 [00:00<?, ?it/s]2024-04-28 18:09:47 | INFO | fairseq.trainer | begin training epoch 2\n",
            "2024-04-28 18:09:47 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 002:  97% 28/29 [00:27<00:00,  1.05it/s]2024-04-28 18:10:15 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 18:10:15 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 002 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 002 | valid on 'dev' subset:  10% 1/10 [00:52<07:51, 52.34s/it]\u001b[A\n",
            "epoch 002 | valid on 'dev' subset:  20% 2/10 [01:50<07:27, 55.89s/it]\u001b[A\n",
            "epoch 002 | valid on 'dev' subset:  30% 3/10 [02:59<07:12, 61.72s/it]\u001b[A\n",
            "epoch 002 | valid on 'dev' subset:  40% 4/10 [04:10<06:33, 65.59s/it]\u001b[A\n",
            "epoch 002 | valid on 'dev' subset:  50% 5/10 [05:28<05:49, 69.95s/it]\u001b[A\n",
            "epoch 002 | valid on 'dev' subset:  60% 6/10 [06:55<05:03, 75.80s/it]\u001b[A\n",
            "epoch 002 | valid on 'dev' subset:  70% 7/10 [08:25<04:00, 80.28s/it]\u001b[A\n",
            "epoch 002 | valid on 'dev' subset:  80% 8/10 [10:01<02:50, 85.23s/it]\u001b[A\n",
            "epoch 002 | valid on 'dev' subset:  90% 9/10 [11:56<01:34, 94.53s/it]\u001b[A\n",
            "epoch 002 | valid on 'dev' subset: 100% 10/10 [12:36<00:00, 77.82s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 18:22:52 | INFO | dev | epoch 002 | valid on 'dev' subset | loss 87.07 | l1_loss 11.502 | mse_loss 75.339 | eos_loss 0.224 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 358.946 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 34.6 | wpb 2604.4 | bsz 14 | num_updates 58 | best_mcd_loss 358.946\n",
            "2024-04-28 18:22:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 58 updates\n",
            "2024-04-28 18:22:52 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint2.pt\n",
            "2024-04-28 18:22:54 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint2.pt\n",
            "2024-04-28 18:23:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint2.pt (epoch 2 @ 58 updates, score 358.946) (writing took 10.196248239000397 seconds)\n",
            "2024-04-28 18:23:02 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2024-04-28 18:23:02 | INFO | train | epoch 002 | loss 83.854 | l1_loss 11.059 | mse_loss 72.502 | eos_loss 0.29 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 331.1 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 58 | lr 2.99942e-06 | gnorm 0.004 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.3 | wall 1595\n",
            "2024-04-28 18:23:02 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 18:23:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 003:   0% 0/29 [00:00<?, ?it/s]2024-04-28 18:23:02 | INFO | fairseq.trainer | begin training epoch 3\n",
            "2024-04-28 18:23:02 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 003:  97% 28/29 [00:27<00:00,  1.03it/s]2024-04-28 18:23:31 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 18:23:31 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 003 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 003 | valid on 'dev' subset:  10% 1/10 [00:52<07:50, 52.28s/it]\u001b[A\n",
            "epoch 003 | valid on 'dev' subset:  20% 2/10 [01:50<07:26, 55.76s/it]\u001b[A\n",
            "epoch 003 | valid on 'dev' subset:  30% 3/10 [02:58<07:11, 61.57s/it]\u001b[A\n",
            "epoch 003 | valid on 'dev' subset:  40% 4/10 [04:10<06:32, 65.50s/it]\u001b[A\n",
            "epoch 003 | valid on 'dev' subset:  50% 5/10 [05:27<05:48, 69.72s/it]\u001b[A\n",
            "epoch 003 | valid on 'dev' subset:  60% 6/10 [06:54<05:01, 75.48s/it]\u001b[A\n",
            "epoch 003 | valid on 'dev' subset:  70% 7/10 [08:23<04:00, 80.01s/it]\u001b[A\n",
            "epoch 003 | valid on 'dev' subset:  80% 8/10 [09:59<02:50, 85.01s/it]\u001b[A\n",
            "epoch 003 | valid on 'dev' subset:  90% 9/10 [11:52<01:33, 93.79s/it]\u001b[A\n",
            "epoch 003 | valid on 'dev' subset: 100% 10/10 [12:32<00:00, 77.16s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 18:36:03 | INFO | dev | epoch 003 | valid on 'dev' subset | loss 82.595 | l1_loss 11.157 | mse_loss 71.254 | eos_loss 0.186 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 355.34 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 34.8 | wpb 2604.4 | bsz 14 | num_updates 87 | best_mcd_loss 355.34\n",
            "2024-04-28 18:36:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 87 updates\n",
            "2024-04-28 18:36:03 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint3.pt\n",
            "2024-04-28 18:36:05 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint3.pt\n",
            "2024-04-28 18:36:11 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint3.pt (epoch 3 @ 87 updates, score 355.34) (writing took 7.556482039999992 seconds)\n",
            "2024-04-28 18:36:11 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2024-04-28 18:36:11 | INFO | train | epoch 003 | loss 78.548 | l1_loss 10.637 | mse_loss 67.691 | eos_loss 0.219 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 333.9 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 87 | lr 4.44913e-06 | gnorm 0.003 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 4.8 | wall 2384\n",
            "2024-04-28 18:36:11 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 18:36:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 004:   0% 0/29 [00:00<?, ?it/s]2024-04-28 18:36:11 | INFO | fairseq.trainer | begin training epoch 4\n",
            "2024-04-28 18:36:11 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 004:  97% 28/29 [00:27<00:00,  1.03it/s, loss=82.924, l1_loss=10.971, mse_loss=71.603, eos_loss=0.348, attn_loss=0, ctc_loss=0, sample_size=9084.9, wps=377.5, ups=0.04, wpb=9084.9, bsz=42.5, num_updates=100, lr=5.099e-06, gnorm=0.004, clip=0, loss_scale=128, train_wall=73, gb_free=6.2, wall=2397]2024-04-28 18:36:40 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 18:36:40 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 004 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 004 | valid on 'dev' subset:  10% 1/10 [00:51<07:45, 51.67s/it]\u001b[A\n",
            "epoch 004 | valid on 'dev' subset:  20% 2/10 [01:49<07:20, 55.10s/it]\u001b[A\n",
            "epoch 004 | valid on 'dev' subset:  30% 3/10 [02:56<07:05, 60.83s/it]\u001b[A\n",
            "epoch 004 | valid on 'dev' subset:  40% 4/10 [04:07<06:27, 64.64s/it]\u001b[A\n",
            "epoch 004 | valid on 'dev' subset:  50% 5/10 [05:23<05:44, 68.98s/it]\u001b[A\n",
            "epoch 004 | valid on 'dev' subset:  60% 6/10 [06:51<05:00, 75.18s/it]\u001b[A\n",
            "epoch 004 | valid on 'dev' subset:  70% 7/10 [08:21<04:00, 80.17s/it]\u001b[A\n",
            "epoch 004 | valid on 'dev' subset:  80% 8/10 [09:57<02:50, 85.29s/it]\u001b[A\n",
            "epoch 004 | valid on 'dev' subset:  90% 9/10 [11:52<01:34, 94.44s/it]\u001b[A\n",
            "epoch 004 | valid on 'dev' subset: 100% 10/10 [12:33<00:00, 77.84s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 18:49:13 | INFO | dev | epoch 004 | valid on 'dev' subset | loss 77.843 | l1_loss 10.777 | mse_loss 66.903 | eos_loss 0.171 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 360.34 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 34.8 | wpb 2604.4 | bsz 14 | num_updates 116 | best_mcd_loss 355.34\n",
            "2024-04-28 18:49:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 116 updates\n",
            "2024-04-28 18:49:13 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint4.pt\n",
            "2024-04-28 18:49:15 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint4.pt\n",
            "2024-04-28 18:49:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint4.pt (epoch 4 @ 116 updates, score 360.34) (writing took 5.425847102999796 seconds)\n",
            "2024-04-28 18:49:18 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
            "2024-04-28 18:49:18 | INFO | train | epoch 004 | loss 74.578 | l1_loss 10.315 | mse_loss 64.07 | eos_loss 0.193 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 334.5 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 116 | lr 5.89884e-06 | gnorm 0.003 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.9 | wall 3171\n",
            "2024-04-28 18:49:18 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 18:49:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 005:   0% 0/29 [00:00<?, ?it/s]2024-04-28 18:49:19 | INFO | fairseq.trainer | begin training epoch 5\n",
            "2024-04-28 18:49:19 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 005:  97% 28/29 [00:27<00:00,  1.09it/s]2024-04-28 18:49:47 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 18:49:47 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 005 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 005 | valid on 'dev' subset:  10% 1/10 [00:51<07:46, 51.87s/it]\u001b[A\n",
            "epoch 005 | valid on 'dev' subset:  20% 2/10 [01:49<07:20, 55.06s/it]\u001b[A\n",
            "epoch 005 | valid on 'dev' subset:  30% 3/10 [02:56<07:05, 60.73s/it]\u001b[A\n",
            "epoch 005 | valid on 'dev' subset:  40% 4/10 [04:06<06:26, 64.49s/it]\u001b[A\n",
            "epoch 005 | valid on 'dev' subset:  50% 5/10 [05:23<05:44, 68.87s/it]\u001b[A\n",
            "epoch 005 | valid on 'dev' subset:  60% 6/10 [06:49<04:58, 74.59s/it]\u001b[A\n",
            "epoch 005 | valid on 'dev' subset:  70% 7/10 [08:17<03:57, 79.03s/it]\u001b[A\n",
            "epoch 005 | valid on 'dev' subset:  80% 8/10 [09:53<02:48, 84.36s/it]\u001b[A\n",
            "epoch 005 | valid on 'dev' subset:  90% 9/10 [11:47<01:33, 93.67s/it]\u001b[A\n",
            "epoch 005 | valid on 'dev' subset: 100% 10/10 [12:27<00:00, 77.08s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 19:02:14 | INFO | dev | epoch 005 | valid on 'dev' subset | loss 72.003 | l1_loss 10.276 | mse_loss 61.564 | eos_loss 0.164 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 383.39 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 35.1 | wpb 2604.4 | bsz 14 | num_updates 145 | best_mcd_loss 355.34\n",
            "2024-04-28 19:02:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 145 updates\n",
            "2024-04-28 19:02:14 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint5.pt\n",
            "2024-04-28 19:02:16 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint5.pt\n",
            "2024-04-28 19:02:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint5.pt (epoch 5 @ 145 updates, score 383.39) (writing took 3.342723553999349 seconds)\n",
            "2024-04-28 19:02:18 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n",
            "2024-04-28 19:02:18 | INFO | train | epoch 005 | loss 70.598 | l1_loss 9.988 | mse_loss 60.432 | eos_loss 0.178 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 337.9 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 145 | lr 7.34855e-06 | gnorm 0.003 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.3 | wall 3950\n",
            "2024-04-28 19:02:18 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 19:02:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 006:   0% 0/29 [00:00<?, ?it/s]2024-04-28 19:02:18 | INFO | fairseq.trainer | begin training epoch 6\n",
            "2024-04-28 19:02:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 006:  97% 28/29 [00:27<00:00,  1.00it/s]2024-04-28 19:02:47 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 19:02:47 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 006 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 006 | valid on 'dev' subset:  10% 1/10 [00:52<07:49, 52.20s/it]\u001b[A\n",
            "epoch 006 | valid on 'dev' subset:  20% 2/10 [01:50<07:25, 55.68s/it]\u001b[A\n",
            "epoch 006 | valid on 'dev' subset:  30% 3/10 [02:58<07:08, 61.22s/it]\u001b[A\n",
            "epoch 006 | valid on 'dev' subset:  40% 4/10 [04:08<06:30, 65.01s/it]\u001b[A\n",
            "epoch 006 | valid on 'dev' subset:  50% 5/10 [05:25<05:46, 69.29s/it]\u001b[A\n",
            "epoch 006 | valid on 'dev' subset:  60% 6/10 [06:52<05:00, 75.05s/it]\u001b[A\n",
            "epoch 006 | valid on 'dev' subset:  70% 7/10 [08:20<03:58, 79.47s/it]\u001b[A\n",
            "epoch 006 | valid on 'dev' subset:  80% 8/10 [09:55<02:48, 84.35s/it]\u001b[A\n",
            "epoch 006 | valid on 'dev' subset:  90% 9/10 [11:49<01:33, 93.73s/it]\u001b[A\n",
            "epoch 006 | valid on 'dev' subset: 100% 10/10 [12:29<00:00, 77.13s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 19:15:17 | INFO | dev | epoch 006 | valid on 'dev' subset | loss 65.236 | l1_loss 9.651 | mse_loss 55.438 | eos_loss 0.151 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 386.424 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 34.9 | wpb 2604.4 | bsz 14 | num_updates 174 | best_mcd_loss 355.34\n",
            "2024-04-28 19:15:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 174 updates\n",
            "2024-04-28 19:15:17 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint6.pt\n",
            "2024-04-28 19:15:18 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint6.pt\n",
            "2024-04-28 19:15:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint6.pt (epoch 6 @ 174 updates, score 386.424) (writing took 3.5820430190005936 seconds)\n",
            "2024-04-28 19:15:20 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)\n",
            "2024-04-28 19:15:20 | INFO | train | epoch 006 | loss 65.853 | l1_loss 9.586 | mse_loss 56.101 | eos_loss 0.164 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 336.6 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 174 | lr 8.79826e-06 | gnorm 0.003 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.3 | wall 4733\n",
            "2024-04-28 19:15:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 19:15:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 007:   0% 0/29 [00:00<?, ?it/s]2024-04-28 19:15:21 | INFO | fairseq.trainer | begin training epoch 7\n",
            "2024-04-28 19:15:21 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 007:  97% 28/29 [00:27<00:00,  1.01it/s, loss=67.453, l1_loss=9.719, mse_loss=57.565, eos_loss=0.168, attn_loss=0, ctc_loss=0, sample_size=9076.77, wps=384.3, ups=0.04, wpb=9076.8, bsz=41.4, num_updates=200, lr=1.0098e-05, gnorm=0.003, clip=0, loss_scale=128, train_wall=72, gb_free=6.4, wall=4758]2024-04-28 19:15:49 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 19:15:49 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 007 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 007 | valid on 'dev' subset:  10% 1/10 [00:51<07:47, 51.92s/it]\u001b[A\n",
            "epoch 007 | valid on 'dev' subset:  20% 2/10 [01:49<07:23, 55.43s/it]\u001b[A\n",
            "epoch 007 | valid on 'dev' subset:  30% 3/10 [02:57<07:07, 61.14s/it]\u001b[A\n",
            "epoch 007 | valid on 'dev' subset:  40% 4/10 [04:08<06:29, 64.89s/it]\u001b[A\n",
            "epoch 007 | valid on 'dev' subset:  50% 5/10 [05:25<05:46, 69.24s/it]\u001b[A\n",
            "epoch 007 | valid on 'dev' subset:  60% 6/10 [06:50<04:59, 74.81s/it]\u001b[A\n",
            "epoch 007 | valid on 'dev' subset:  70% 7/10 [08:18<03:57, 79.01s/it]\u001b[A\n",
            "epoch 007 | valid on 'dev' subset:  80% 8/10 [09:52<02:47, 83.75s/it]\u001b[A\n",
            "epoch 007 | valid on 'dev' subset:  90% 9/10 [11:45<01:32, 92.93s/it]\u001b[A\n",
            "epoch 007 | valid on 'dev' subset: 100% 10/10 [12:25<00:00, 76.57s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 19:28:14 | INFO | dev | epoch 007 | valid on 'dev' subset | loss 61.424 | l1_loss 9.291 | mse_loss 51.992 | eos_loss 0.14 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 379.804 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 35.1 | wpb 2604.4 | bsz 14 | num_updates 203 | best_mcd_loss 355.34\n",
            "2024-04-28 19:28:14 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 203 updates\n",
            "2024-04-28 19:28:14 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint7.pt\n",
            "2024-04-28 19:28:16 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint7.pt\n",
            "2024-04-28 19:28:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint7.pt (epoch 7 @ 203 updates, score 379.804) (writing took 3.555230625999684 seconds)\n",
            "2024-04-28 19:28:18 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)\n",
            "2024-04-28 19:28:18 | INFO | train | epoch 007 | loss 61.464 | l1_loss 9.199 | mse_loss 52.114 | eos_loss 0.15 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 338.6 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 203 | lr 1.0248e-05 | gnorm 0.003 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.9 | wall 5511\n",
            "2024-04-28 19:28:18 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 19:28:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 008:   0% 0/29 [00:00<?, ?it/s]2024-04-28 19:28:18 | INFO | fairseq.trainer | begin training epoch 8\n",
            "2024-04-28 19:28:18 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 008:  97% 28/29 [00:27<00:00,  1.01it/s]2024-04-28 19:28:47 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 19:28:47 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 008 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 008 | valid on 'dev' subset:  10% 1/10 [00:52<07:50, 52.28s/it]\u001b[A\n",
            "epoch 008 | valid on 'dev' subset:  20% 2/10 [01:49<07:23, 55.40s/it]\u001b[A\n",
            "epoch 008 | valid on 'dev' subset:  30% 3/10 [02:57<07:08, 61.16s/it]\u001b[A\n",
            "epoch 008 | valid on 'dev' subset:  40% 4/10 [04:08<06:29, 64.84s/it]\u001b[A\n",
            "epoch 008 | valid on 'dev' subset:  50% 5/10 [05:26<05:47, 69.51s/it]\u001b[A\n",
            "epoch 008 | valid on 'dev' subset:  60% 6/10 [06:52<05:01, 75.29s/it]\u001b[A\n",
            "epoch 008 | valid on 'dev' subset:  70% 7/10 [08:21<03:59, 79.72s/it]\u001b[A\n",
            "epoch 008 | valid on 'dev' subset:  80% 8/10 [09:56<02:49, 84.64s/it]\u001b[A\n",
            "epoch 008 | valid on 'dev' subset:  90% 9/10 [11:50<01:33, 93.78s/it]\u001b[A\n",
            "epoch 008 | valid on 'dev' subset: 100% 10/10 [12:30<00:00, 77.16s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 19:41:17 | INFO | dev | epoch 008 | valid on 'dev' subset | loss 58.676 | l1_loss 9.043 | mse_loss 49.507 | eos_loss 0.13 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 359.624 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 34.9 | wpb 2604.4 | bsz 14 | num_updates 232 | best_mcd_loss 355.34\n",
            "2024-04-28 19:41:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 232 updates\n",
            "2024-04-28 19:41:17 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint8.pt\n",
            "2024-04-28 19:41:19 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint8.pt\n",
            "2024-04-28 19:41:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint8.pt (epoch 8 @ 232 updates, score 359.624) (writing took 6.9454157410000334 seconds)\n",
            "2024-04-28 19:41:24 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)\n",
            "2024-04-28 19:41:24 | INFO | train | epoch 008 | loss 57.679 | l1_loss 8.849 | mse_loss 48.691 | eos_loss 0.137 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 335 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 232 | lr 1.16977e-05 | gnorm 0.003 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 9.8 | wall 6297\n",
            "2024-04-28 19:41:24 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 19:41:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 009:   0% 0/29 [00:00<?, ?it/s]2024-04-28 19:41:25 | INFO | fairseq.trainer | begin training epoch 9\n",
            "2024-04-28 19:41:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 009:  97% 28/29 [00:27<00:00,  1.11it/s]2024-04-28 19:41:53 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 19:41:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 009 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 009 | valid on 'dev' subset:  10% 1/10 [00:51<07:43, 51.49s/it]\u001b[A\n",
            "epoch 009 | valid on 'dev' subset:  20% 2/10 [01:49<07:21, 55.19s/it]\u001b[A\n",
            "epoch 009 | valid on 'dev' subset:  30% 3/10 [02:56<07:06, 60.88s/it]\u001b[A\n",
            "epoch 009 | valid on 'dev' subset:  40% 4/10 [04:08<06:29, 64.95s/it]\u001b[A\n",
            "epoch 009 | valid on 'dev' subset:  50% 5/10 [05:25<05:46, 69.32s/it]\u001b[A\n",
            "epoch 009 | valid on 'dev' subset:  60% 6/10 [06:51<05:00, 75.06s/it]\u001b[A\n",
            "epoch 009 | valid on 'dev' subset:  70% 7/10 [08:20<03:59, 79.69s/it]\u001b[A\n",
            "epoch 009 | valid on 'dev' subset:  80% 8/10 [09:56<02:49, 84.72s/it]\u001b[A\n",
            "epoch 009 | valid on 'dev' subset:  90% 9/10 [11:50<01:33, 93.89s/it]\u001b[A\n",
            "epoch 009 | valid on 'dev' subset: 100% 10/10 [12:30<00:00, 77.23s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 19:54:23 | INFO | dev | epoch 009 | valid on 'dev' subset | loss 56.594 | l1_loss 8.864 | mse_loss 47.613 | eos_loss 0.117 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 353.595 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 34.9 | wpb 2604.4 | bsz 14 | num_updates 261 | best_mcd_loss 353.595\n",
            "2024-04-28 19:54:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 261 updates\n",
            "2024-04-28 19:54:23 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint9.pt\n",
            "2024-04-28 19:54:25 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint9.pt\n",
            "2024-04-28 19:54:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint9.pt (epoch 9 @ 261 updates, score 353.595) (writing took 6.017200770000272 seconds)\n",
            "2024-04-28 19:54:29 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)\n",
            "2024-04-28 19:54:29 | INFO | train | epoch 009 | loss 54.063 | l1_loss 8.504 | mse_loss 45.429 | eos_loss 0.125 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 335.6 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 261 | lr 1.31474e-05 | gnorm 0.002 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.4 | wall 7082\n",
            "2024-04-28 19:54:29 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 19:54:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 010:   0% 0/29 [00:00<?, ?it/s]2024-04-28 19:54:29 | INFO | fairseq.trainer | begin training epoch 10\n",
            "2024-04-28 19:54:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 010:  97% 28/29 [00:27<00:00,  1.02it/s]2024-04-28 19:54:58 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 19:54:58 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 010 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 010 | valid on 'dev' subset:  10% 1/10 [00:52<07:48, 52.09s/it]\u001b[A\n",
            "epoch 010 | valid on 'dev' subset:  20% 2/10 [01:49<07:22, 55.32s/it]\u001b[A\n",
            "epoch 010 | valid on 'dev' subset:  30% 3/10 [02:58<07:09, 61.30s/it]\u001b[A\n",
            "epoch 010 | valid on 'dev' subset:  40% 4/10 [04:08<06:30, 65.00s/it]\u001b[A\n",
            "epoch 010 | valid on 'dev' subset:  50% 5/10 [05:25<05:46, 69.33s/it]\u001b[A\n",
            "epoch 010 | valid on 'dev' subset:  60% 6/10 [06:52<05:00, 75.22s/it]\u001b[A\n",
            "epoch 010 | valid on 'dev' subset:  70% 7/10 [08:21<03:59, 79.77s/it]\u001b[A\n",
            "epoch 010 | valid on 'dev' subset:  80% 8/10 [09:56<02:49, 84.66s/it]\u001b[A\n",
            "epoch 010 | valid on 'dev' subset:  90% 9/10 [11:50<01:33, 93.78s/it]\u001b[A\n",
            "epoch 010 | valid on 'dev' subset: 100% 10/10 [12:30<00:00, 77.15s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 20:07:29 | INFO | dev | epoch 010 | valid on 'dev' subset | loss 53.568 | l1_loss 8.581 | mse_loss 44.884 | eos_loss 0.103 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 326.711 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 34.9 | wpb 2604.4 | bsz 14 | num_updates 290 | best_mcd_loss 326.711\n",
            "2024-04-28 20:07:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 290 updates\n",
            "2024-04-28 20:07:29 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint10.pt\n",
            "2024-04-28 20:07:31 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint10.pt\n",
            "2024-04-28 20:07:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint10.pt (epoch 10 @ 290 updates, score 326.711) (writing took 7.98850714999935 seconds)\n",
            "2024-04-28 20:07:37 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)\n",
            "2024-04-28 20:07:37 | INFO | train | epoch 010 | loss 50.342 | l1_loss 8.13 | mse_loss 42.098 | eos_loss 0.111 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 334.3 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 290 | lr 1.45971e-05 | gnorm 0.002 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 5 | wall 7870\n",
            "2024-04-28 20:07:37 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 20:07:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 011:   0% 0/29 [00:00<?, ?it/s]2024-04-28 20:07:37 | INFO | fairseq.trainer | begin training epoch 11\n",
            "2024-04-28 20:07:37 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 011:  97% 28/29 [00:27<00:00,  1.01it/s, loss=53.685, l1_loss=8.46, mse_loss=45.099, eos_loss=0.122, attn_loss=0, ctc_loss=0, sample_size=9102.48, wps=291.5, ups=0.03, wpb=9102.5, bsz=41.7, num_updates=300, lr=1.5097e-05, gnorm=0.002, clip=0, loss_scale=128, train_wall=72, gb_free=6, wall=7881]2024-04-28 20:08:06 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 20:08:06 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 011 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 011 | valid on 'dev' subset:  10% 1/10 [00:52<07:49, 52.13s/it]\u001b[A\n",
            "epoch 011 | valid on 'dev' subset:  20% 2/10 [01:49<07:22, 55.36s/it]\u001b[A\n",
            "epoch 011 | valid on 'dev' subset:  30% 3/10 [02:57<07:07, 61.05s/it]\u001b[A\n",
            "epoch 011 | valid on 'dev' subset:  40% 4/10 [04:08<06:28, 64.83s/it]\u001b[A\n",
            "epoch 011 | valid on 'dev' subset:  50% 5/10 [05:25<05:45, 69.15s/it]\u001b[A\n",
            "epoch 011 | valid on 'dev' subset:  60% 6/10 [06:50<04:58, 74.73s/it]\u001b[A\n",
            "epoch 011 | valid on 'dev' subset:  70% 7/10 [08:18<03:56, 78.95s/it]\u001b[A\n",
            "epoch 011 | valid on 'dev' subset:  80% 8/10 [09:52<02:47, 83.87s/it]\u001b[A\n",
            "epoch 011 | valid on 'dev' subset:  90% 9/10 [11:45<01:32, 93.00s/it]\u001b[A\n",
            "epoch 011 | valid on 'dev' subset: 100% 10/10 [12:25<00:00, 76.64s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 20:20:32 | INFO | dev | epoch 011 | valid on 'dev' subset | loss 53.407 | l1_loss 8.607 | mse_loss 44.703 | eos_loss 0.091 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 321.922 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 35.1 | wpb 2604.4 | bsz 14 | num_updates 319 | best_mcd_loss 321.922\n",
            "2024-04-28 20:20:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 319 updates\n",
            "2024-04-28 20:20:32 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint11.pt\n",
            "2024-04-28 20:20:33 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint11.pt\n",
            "2024-04-28 20:20:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint11.pt (epoch 11 @ 319 updates, score 321.922) (writing took 5.713257512001292 seconds)\n",
            "2024-04-28 20:20:38 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)\n",
            "2024-04-28 20:20:38 | INFO | train | epoch 011 | loss 46.611 | l1_loss 7.743 | mse_loss 38.77 | eos_loss 0.098 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 337.4 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 319 | lr 1.60468e-05 | gnorm 0.002 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.2 | wall 8650\n",
            "2024-04-28 20:20:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 20:20:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 012:   0% 0/29 [00:00<?, ?it/s]2024-04-28 20:20:38 | INFO | fairseq.trainer | begin training epoch 12\n",
            "2024-04-28 20:20:38 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 012:  97% 28/29 [00:27<00:00,  1.02it/s]2024-04-28 20:21:07 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 20:21:07 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 012 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 012 | valid on 'dev' subset:  10% 1/10 [00:51<07:42, 51.41s/it]\u001b[A\n",
            "epoch 012 | valid on 'dev' subset:  20% 2/10 [01:50<07:26, 55.86s/it]\u001b[A\n",
            "epoch 012 | valid on 'dev' subset:  30% 3/10 [02:59<07:12, 61.73s/it]\u001b[A\n",
            "epoch 012 | valid on 'dev' subset:  40% 4/10 [04:13<06:40, 66.83s/it]\u001b[A\n",
            "epoch 012 | valid on 'dev' subset:  50% 5/10 [05:33<05:56, 71.34s/it]\u001b[A\n",
            "epoch 012 | valid on 'dev' subset:  60% 6/10 [07:01<05:07, 76.99s/it]\u001b[A\n",
            "epoch 012 | valid on 'dev' subset:  70% 7/10 [08:31<04:04, 81.49s/it]\u001b[A\n",
            "epoch 012 | valid on 'dev' subset:  80% 8/10 [10:11<02:54, 87.33s/it]\u001b[A\n",
            "epoch 012 | valid on 'dev' subset:  90% 9/10 [12:07<01:36, 96.40s/it]\u001b[A\n",
            "epoch 012 | valid on 'dev' subset: 100% 10/10 [12:49<00:00, 79.45s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 20:33:56 | INFO | dev | epoch 012 | valid on 'dev' subset | loss 52.991 | l1_loss 8.585 | mse_loss 44.331 | eos_loss 0.079 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 313.556 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 33.9 | wpb 2604.4 | bsz 14 | num_updates 348 | best_mcd_loss 313.556\n",
            "2024-04-28 20:33:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 348 updates\n",
            "2024-04-28 20:33:56 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint12.pt\n",
            "2024-04-28 20:33:58 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint12.pt\n",
            "2024-04-28 20:34:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint12.pt (epoch 12 @ 348 updates, score 313.556) (writing took 8.154045184001006 seconds)\n",
            "2024-04-28 20:34:04 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)\n",
            "2024-04-28 20:34:04 | INFO | train | epoch 012 | loss 42.747 | l1_loss 7.327 | mse_loss 35.334 | eos_loss 0.085 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 326.4 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 348 | lr 1.74965e-05 | gnorm 0.002 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.3 | wall 9457\n",
            "2024-04-28 20:34:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 20:34:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 013:   0% 0/29 [00:00<?, ?it/s]2024-04-28 20:34:05 | INFO | fairseq.trainer | begin training epoch 13\n",
            "2024-04-28 20:34:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 013:  97% 28/29 [00:29<00:01,  1.05s/it]2024-04-28 20:34:35 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 20:34:35 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 013 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 013 | valid on 'dev' subset:  10% 1/10 [00:54<08:07, 54.22s/it]\u001b[A\n",
            "epoch 013 | valid on 'dev' subset:  20% 2/10 [01:54<07:42, 57.77s/it]\u001b[A\n",
            "epoch 013 | valid on 'dev' subset:  30% 3/10 [03:05<07:26, 63.77s/it]\u001b[A\n",
            "epoch 013 | valid on 'dev' subset:  40% 4/10 [04:19<06:46, 67.71s/it]\u001b[A\n",
            "epoch 013 | valid on 'dev' subset:  50% 5/10 [05:39<06:01, 72.37s/it]\u001b[A\n",
            "epoch 013 | valid on 'dev' subset:  60% 6/10 [07:09<05:13, 78.41s/it]\u001b[A\n",
            "epoch 013 | valid on 'dev' subset:  70% 7/10 [08:43<04:09, 83.28s/it]\u001b[A\n",
            "epoch 013 | valid on 'dev' subset:  80% 8/10 [10:22<02:57, 88.53s/it]\u001b[A\n",
            "epoch 013 | valid on 'dev' subset:  90% 9/10 [12:21<01:37, 97.88s/it]\u001b[A\n",
            "epoch 013 | valid on 'dev' subset: 100% 10/10 [13:03<00:00, 80.72s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 20:47:39 | INFO | dev | epoch 013 | valid on 'dev' subset | loss 51.509 | l1_loss 8.438 | mse_loss 43.003 | eos_loss 0.069 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 298.79 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 33.4 | wpb 2604.4 | bsz 14 | num_updates 377 | best_mcd_loss 298.79\n",
            "2024-04-28 20:47:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 377 updates\n",
            "2024-04-28 20:47:39 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint13.pt\n",
            "2024-04-28 20:47:41 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint13.pt\n",
            "2024-04-28 20:47:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint13.pt (epoch 13 @ 377 updates, score 298.79) (writing took 8.12285520200021 seconds)\n",
            "2024-04-28 20:47:47 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)\n",
            "2024-04-28 20:47:47 | INFO | train | epoch 013 | loss 38.927 | l1_loss 6.897 | mse_loss 31.957 | eos_loss 0.074 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 320.2 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 377 | lr 1.89462e-05 | gnorm 0.002 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.2 | wall 10280\n",
            "2024-04-28 20:47:47 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 20:47:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 014:   0% 0/29 [00:00<?, ?it/s]2024-04-28 20:47:47 | INFO | fairseq.trainer | begin training epoch 14\n",
            "2024-04-28 20:47:47 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 014:  97% 28/29 [00:29<00:01,  1.04s/it, loss=40.508, l1_loss=7.068, mse_loss=33.362, eos_loss=0.079, attn_loss=0, ctc_loss=0, sample_size=9072.33, wps=374.3, ups=0.04, wpb=9072.3, bsz=42.3, num_updates=400, lr=2.0096e-05, gnorm=0.002, clip=0, loss_scale=128, train_wall=71, gb_free=5.8, wall=10304]2024-04-28 20:48:18 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 20:48:18 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 014 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 014 | valid on 'dev' subset:  10% 1/10 [00:54<08:11, 54.63s/it]\u001b[A\n",
            "epoch 014 | valid on 'dev' subset:  20% 2/10 [01:55<07:44, 58.03s/it]\u001b[A\n",
            "epoch 014 | valid on 'dev' subset:  30% 3/10 [03:06<07:29, 64.21s/it]\u001b[A\n",
            "epoch 014 | valid on 'dev' subset:  40% 4/10 [04:20<06:47, 67.91s/it]\u001b[A\n",
            "epoch 014 | valid on 'dev' subset:  50% 5/10 [05:39<06:00, 72.09s/it]\u001b[A\n",
            "epoch 014 | valid on 'dev' subset:  60% 6/10 [07:08<05:11, 77.78s/it]\u001b[A\n",
            "epoch 014 | valid on 'dev' subset:  70% 7/10 [08:40<04:07, 82.45s/it]\u001b[A\n",
            "epoch 014 | valid on 'dev' subset:  80% 8/10 [10:19<02:55, 87.79s/it]\u001b[A\n",
            "epoch 014 | valid on 'dev' subset:  90% 9/10 [12:17<01:37, 97.17s/it]\u001b[A\n",
            "epoch 014 | valid on 'dev' subset: 100% 10/10 [12:59<00:00, 80.26s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 21:01:18 | INFO | dev | epoch 014 | valid on 'dev' subset | loss 51.564 | l1_loss 8.415 | mse_loss 43.089 | eos_loss 0.06 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 289.034 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 33.6 | wpb 2604.4 | bsz 14 | num_updates 406 | best_mcd_loss 289.034\n",
            "2024-04-28 21:01:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 406 updates\n",
            "2024-04-28 21:01:18 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint14.pt\n",
            "2024-04-28 21:01:20 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint14.pt\n",
            "2024-04-28 21:01:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint14.pt (epoch 14 @ 406 updates, score 289.034) (writing took 7.685373992000677 seconds)\n",
            "2024-04-28 21:01:26 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)\n",
            "2024-04-28 21:01:26 | INFO | train | epoch 014 | loss 35.121 | l1_loss 6.454 | mse_loss 28.606 | eos_loss 0.064 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 321.8 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 406 | lr 2.03959e-05 | gnorm 0.002 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.3 | wall 11098\n",
            "2024-04-28 21:01:26 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 21:01:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 015:   0% 0/29 [00:00<?, ?it/s]2024-04-28 21:01:26 | INFO | fairseq.trainer | begin training epoch 15\n",
            "2024-04-28 21:01:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 015:  97% 28/29 [00:28<00:01,  1.01s/it]2024-04-28 21:01:56 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 21:01:56 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 015 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 015 | valid on 'dev' subset:  10% 1/10 [00:53<08:05, 53.97s/it]\u001b[A\n",
            "epoch 015 | valid on 'dev' subset:  20% 2/10 [01:55<07:47, 58.38s/it]\u001b[A\n",
            "epoch 015 | valid on 'dev' subset:  30% 3/10 [03:05<07:27, 63.90s/it]\u001b[A\n",
            "epoch 015 | valid on 'dev' subset:  40% 4/10 [04:19<06:46, 67.69s/it]\u001b[A\n",
            "epoch 015 | valid on 'dev' subset:  50% 5/10 [05:38<05:59, 71.88s/it]\u001b[A\n",
            "epoch 015 | valid on 'dev' subset:  60% 6/10 [07:07<05:10, 77.54s/it]\u001b[A\n",
            "epoch 015 | valid on 'dev' subset:  70% 7/10 [08:39<04:06, 82.20s/it]\u001b[A\n",
            "epoch 015 | valid on 'dev' subset:  80% 8/10 [10:17<02:54, 87.42s/it]\u001b[A\n",
            "epoch 015 | valid on 'dev' subset:  90% 9/10 [12:14<01:36, 96.64s/it]\u001b[A\n",
            "epoch 015 | valid on 'dev' subset: 100% 10/10 [12:56<00:00, 79.64s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 21:14:52 | INFO | dev | epoch 015 | valid on 'dev' subset | loss 49.296 | l1_loss 8.146 | mse_loss 41.095 | eos_loss 0.053 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 273.845 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 33.8 | wpb 2604.4 | bsz 14 | num_updates 435 | best_mcd_loss 273.845\n",
            "2024-04-28 21:14:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 435 updates\n",
            "2024-04-28 21:14:52 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint15.pt\n",
            "2024-04-28 21:14:54 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint15.pt\n",
            "2024-04-28 21:14:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint15.pt (epoch 15 @ 435 updates, score 273.845) (writing took 6.737946315000954 seconds)\n",
            "2024-04-28 21:14:59 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)\n",
            "2024-04-28 21:14:59 | INFO | train | epoch 015 | loss 31.38 | l1_loss 6 | mse_loss 25.321 | eos_loss 0.055 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 323.9 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 435 | lr 2.18457e-05 | gnorm 0.002 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.4 | wall 11911\n",
            "2024-04-28 21:14:59 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 21:14:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 016:   0% 0/29 [00:00<?, ?it/s]2024-04-28 21:14:59 | INFO | fairseq.trainer | begin training epoch 16\n",
            "2024-04-28 21:14:59 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 016:  97% 28/29 [00:29<00:00,  1.07it/s]2024-04-28 21:15:29 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 21:15:29 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 016 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 016 | valid on 'dev' subset:  10% 1/10 [00:53<08:02, 53.63s/it]\u001b[A\n",
            "epoch 016 | valid on 'dev' subset:  20% 2/10 [01:53<07:37, 57.22s/it]\u001b[A\n",
            "epoch 016 | valid on 'dev' subset:  30% 3/10 [03:03<07:21, 63.11s/it]\u001b[A\n",
            "epoch 016 | valid on 'dev' subset:  40% 4/10 [04:16<06:42, 67.07s/it]\u001b[A\n",
            "epoch 016 | valid on 'dev' subset:  50% 5/10 [05:36<05:58, 71.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'dev' subset:  60% 6/10 [07:04<05:09, 77.29s/it]\u001b[A\n",
            "epoch 016 | valid on 'dev' subset:  70% 7/10 [08:34<04:03, 81.28s/it]\u001b[A\n",
            "epoch 016 | valid on 'dev' subset:  80% 8/10 [10:09<02:51, 85.68s/it]\u001b[A\n",
            "epoch 016 | valid on 'dev' subset:  90% 9/10 [12:04<01:34, 94.92s/it]\u001b[A\n",
            "epoch 016 | valid on 'dev' subset: 100% 10/10 [12:45<00:00, 78.29s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 21:28:15 | INFO | dev | epoch 016 | valid on 'dev' subset | loss 45.744 | l1_loss 7.752 | mse_loss 37.943 | eos_loss 0.047 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 260.533 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 34.2 | wpb 2604.4 | bsz 14 | num_updates 464 | best_mcd_loss 260.533\n",
            "2024-04-28 21:28:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 464 updates\n",
            "2024-04-28 21:28:15 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint16.pt\n",
            "2024-04-28 21:28:17 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint16.pt\n",
            "2024-04-28 21:28:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint16.pt (epoch 16 @ 464 updates, score 260.533) (writing took 8.10947440199925 seconds)\n",
            "2024-04-28 21:28:23 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)\n",
            "2024-04-28 21:28:23 | INFO | train | epoch 016 | loss 27.781 | l1_loss 5.543 | mse_loss 22.19 | eos_loss 0.048 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 327.3 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 464 | lr 2.32954e-05 | gnorm 0.002 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.3 | wall 12716\n",
            "2024-04-28 21:28:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 21:28:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 017:   0% 0/29 [00:00<?, ?it/s]2024-04-28 21:28:24 | INFO | fairseq.trainer | begin training epoch 17\n",
            "2024-04-28 21:28:24 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 017:  97% 28/29 [00:28<00:01,  1.04s/it]2024-04-28 21:28:53 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 21:28:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 017 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 017 | valid on 'dev' subset:  10% 1/10 [00:53<08:02, 53.63s/it]\u001b[A\n",
            "epoch 017 | valid on 'dev' subset:  20% 2/10 [01:52<07:35, 56.97s/it]\u001b[A\n",
            "epoch 017 | valid on 'dev' subset:  30% 3/10 [03:02<07:20, 62.88s/it]\u001b[A\n",
            "epoch 017 | valid on 'dev' subset:  40% 4/10 [04:15<06:40, 66.77s/it]\u001b[A\n",
            "epoch 017 | valid on 'dev' subset:  50% 5/10 [05:34<05:56, 71.26s/it]\u001b[A\n",
            "epoch 017 | valid on 'dev' subset:  60% 6/10 [07:03<05:08, 77.14s/it]\u001b[A\n",
            "epoch 017 | valid on 'dev' subset:  70% 7/10 [08:35<04:05, 81.93s/it]\u001b[A\n",
            "epoch 017 | valid on 'dev' subset:  80% 8/10 [10:12<02:53, 86.97s/it]\u001b[A\n",
            "epoch 017 | valid on 'dev' subset:  90% 9/10 [12:09<01:36, 96.21s/it]\u001b[A\n",
            "epoch 017 | valid on 'dev' subset: 100% 10/10 [12:50<00:00, 79.22s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 21:41:44 | INFO | dev | epoch 017 | valid on 'dev' subset | loss 41.378 | l1_loss 7.268 | mse_loss 34.063 | eos_loss 0.042 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 238.87 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 34 | wpb 2604.4 | bsz 14 | num_updates 493 | best_mcd_loss 238.87\n",
            "2024-04-28 21:41:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 493 updates\n",
            "2024-04-28 21:41:44 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint17.pt\n",
            "2024-04-28 21:41:46 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint17.pt\n",
            "2024-04-28 21:41:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint17.pt (epoch 17 @ 493 updates, score 238.87) (writing took 8.301514466000299 seconds)\n",
            "2024-04-28 21:41:52 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)\n",
            "2024-04-28 21:41:52 | INFO | train | epoch 017 | loss 24.319 | l1_loss 5.083 | mse_loss 19.193 | eos_loss 0.043 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 325.5 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 493 | lr 2.47451e-05 | gnorm 0.002 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.3 | wall 13525\n",
            "2024-04-28 21:41:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 21:41:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 018:   0% 0/29 [00:00<?, ?it/s]2024-04-28 21:41:53 | INFO | fairseq.trainer | begin training epoch 18\n",
            "2024-04-28 21:41:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 018:  97% 28/29 [00:28<00:01,  1.02s/it, loss=27.714, l1_loss=5.528, mse_loss=22.135, eos_loss=0.049, attn_loss=0, ctc_loss=0, sample_size=9086.8, wps=281.4, ups=0.03, wpb=9086.8, bsz=41.7, num_updates=500, lr=2.5095e-05, gnorm=0.002, clip=0, loss_scale=128, train_wall=72, gb_free=6.2, wall=13533]2024-04-28 21:42:22 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 21:42:22 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 018 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 018 | valid on 'dev' subset:  10% 1/10 [00:53<07:59, 53.28s/it]\u001b[A\n",
            "epoch 018 | valid on 'dev' subset:  20% 2/10 [01:52<07:34, 56.81s/it]\u001b[A\n",
            "epoch 018 | valid on 'dev' subset:  30% 3/10 [03:03<07:21, 63.06s/it]\u001b[A\n",
            "epoch 018 | valid on 'dev' subset:  40% 4/10 [04:16<06:43, 67.22s/it]\u001b[A\n",
            "epoch 018 | valid on 'dev' subset:  50% 5/10 [05:36<05:58, 71.70s/it]\u001b[A\n",
            "epoch 018 | valid on 'dev' subset:  60% 6/10 [07:05<05:10, 77.53s/it]\u001b[A\n",
            "epoch 018 | valid on 'dev' subset:  70% 7/10 [08:37<04:06, 82.31s/it]\u001b[A\n",
            "epoch 018 | valid on 'dev' subset:  80% 8/10 [10:15<02:54, 87.49s/it]\u001b[A\n",
            "epoch 018 | valid on 'dev' subset:  90% 9/10 [12:14<01:37, 97.13s/it]\u001b[A\n",
            "epoch 018 | valid on 'dev' subset: 100% 10/10 [12:55<00:00, 79.99s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 21:55:18 | INFO | dev | epoch 018 | valid on 'dev' subset | loss 37.284 | l1_loss 6.797 | mse_loss 30.445 | eos_loss 0.039 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 220.114 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 33.7 | wpb 2604.4 | bsz 14 | num_updates 522 | best_mcd_loss 220.114\n",
            "2024-04-28 21:55:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 522 updates\n",
            "2024-04-28 21:55:18 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint18.pt\n",
            "2024-04-28 21:55:20 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint18.pt\n",
            "2024-04-28 21:55:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint18.pt (epoch 18 @ 522 updates, score 220.114) (writing took 6.663532958998985 seconds)\n",
            "2024-04-28 21:55:25 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)\n",
            "2024-04-28 21:55:25 | INFO | train | epoch 018 | loss 21.242 | l1_loss 4.657 | mse_loss 16.547 | eos_loss 0.038 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 324 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 522 | lr 2.61948e-05 | gnorm 0.001 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 5.5 | wall 14338\n",
            "2024-04-28 21:55:25 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 21:55:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 019:   0% 0/29 [00:00<?, ?it/s]2024-04-28 21:55:25 | INFO | fairseq.trainer | begin training epoch 19\n",
            "2024-04-28 21:55:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 019:  97% 28/29 [00:29<00:01,  1.09s/it]2024-04-28 21:55:55 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 21:55:55 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 019 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 019 | valid on 'dev' subset:  10% 1/10 [00:53<08:05, 53.96s/it]\u001b[A\n",
            "epoch 019 | valid on 'dev' subset:  20% 2/10 [01:53<07:39, 57.38s/it]\u001b[A\n",
            "epoch 019 | valid on 'dev' subset:  30% 3/10 [03:03<07:22, 63.16s/it]\u001b[A\n",
            "epoch 019 | valid on 'dev' subset:  40% 4/10 [04:18<06:47, 67.84s/it]\u001b[A\n",
            "epoch 019 | valid on 'dev' subset:  50% 5/10 [05:39<06:02, 72.50s/it]\u001b[A\n",
            "epoch 019 | valid on 'dev' subset:  60% 6/10 [07:07<05:11, 77.87s/it]\u001b[A\n",
            "epoch 019 | valid on 'dev' subset:  70% 7/10 [08:39<04:06, 82.31s/it]\u001b[A\n",
            "epoch 019 | valid on 'dev' subset:  80% 8/10 [10:18<02:55, 87.73s/it]\u001b[A\n",
            "epoch 019 | valid on 'dev' subset:  90% 9/10 [12:14<01:36, 96.46s/it]\u001b[A\n",
            "epoch 019 | valid on 'dev' subset: 100% 10/10 [12:56<00:00, 79.60s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 22:08:52 | INFO | dev | epoch 019 | valid on 'dev' subset | loss 33.55 | l1_loss 6.354 | mse_loss 27.157 | eos_loss 0.036 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 202.785 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 33.8 | wpb 2604.4 | bsz 14 | num_updates 551 | best_mcd_loss 202.785\n",
            "2024-04-28 22:08:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 551 updates\n",
            "2024-04-28 22:08:52 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint19.pt\n",
            "2024-04-28 22:08:53 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint19.pt\n",
            "2024-04-28 22:09:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint19.pt (epoch 19 @ 551 updates, score 202.785) (writing took 10.778364853998937 seconds)\n",
            "2024-04-28 22:09:02 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)\n",
            "2024-04-28 22:09:02 | INFO | train | epoch 019 | loss 18.468 | l1_loss 4.255 | mse_loss 14.178 | eos_loss 0.035 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 322.2 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 551 | lr 2.76445e-05 | gnorm 0.001 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.9 | wall 15155\n",
            "2024-04-28 22:09:02 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 22:09:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 020:   0% 0/29 [00:00<?, ?it/s]2024-04-28 22:09:03 | INFO | fairseq.trainer | begin training epoch 20\n",
            "2024-04-28 22:09:03 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 020:  97% 28/29 [00:29<00:01,  1.06s/it]2024-04-28 22:09:34 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 22:09:34 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 020 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 020 | valid on 'dev' subset:  10% 1/10 [00:55<08:19, 55.47s/it]\u001b[A\n",
            "epoch 020 | valid on 'dev' subset:  20% 2/10 [01:56<07:48, 58.61s/it]\u001b[A\n",
            "epoch 020 | valid on 'dev' subset:  30% 3/10 [03:06<07:28, 64.12s/it]\u001b[A\n",
            "epoch 020 | valid on 'dev' subset:  40% 4/10 [04:21<06:48, 68.10s/it]\u001b[A\n",
            "epoch 020 | valid on 'dev' subset:  50% 5/10 [05:43<06:06, 73.28s/it]\u001b[A\n",
            "epoch 020 | valid on 'dev' subset:  60% 6/10 [07:14<05:16, 79.11s/it]\u001b[A\n",
            "epoch 020 | valid on 'dev' subset:  70% 7/10 [08:47<04:10, 83.64s/it]\u001b[A\n",
            "epoch 020 | valid on 'dev' subset:  80% 8/10 [10:25<02:56, 88.48s/it]\u001b[A\n",
            "epoch 020 | valid on 'dev' subset:  90% 9/10 [12:23<01:37, 97.66s/it]\u001b[A\n",
            "epoch 020 | valid on 'dev' subset: 100% 10/10 [13:04<00:00, 80.24s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 22:22:39 | INFO | dev | epoch 020 | valid on 'dev' subset | loss 30.086 | l1_loss 5.928 | mse_loss 24.123 | eos_loss 0.036 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 185.557 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 33.4 | wpb 2604.4 | bsz 14 | num_updates 580 | best_mcd_loss 185.557\n",
            "2024-04-28 22:22:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 580 updates\n",
            "2024-04-28 22:22:39 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint20.pt\n",
            "2024-04-28 22:22:41 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint20.pt\n",
            "2024-04-28 22:22:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint20.pt (epoch 20 @ 580 updates, score 185.557) (writing took 13.899959385998955 seconds)\n",
            "2024-04-28 22:22:53 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)\n",
            "2024-04-28 22:22:53 | INFO | train | epoch 020 | loss 16.114 | l1_loss 3.902 | mse_loss 12.178 | eos_loss 0.032 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 317.2 | ups 0.03 | wpb 9081.6 | bsz 41.9 | num_updates 580 | lr 2.90942e-05 | gnorm 0.001 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.4 | wall 15985\n",
            "2024-04-28 22:22:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 22:22:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 021:   0% 0/29 [00:00<?, ?it/s]2024-04-28 22:22:53 | INFO | fairseq.trainer | begin training epoch 21\n",
            "2024-04-28 22:22:53 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 021:  97% 28/29 [00:28<00:00,  1.03it/s, loss=17.508, l1_loss=4.104, mse_loss=13.369, eos_loss=0.034, attn_loss=0, ctc_loss=0, sample_size=9058.37, wps=366.2, ups=0.04, wpb=9058.4, bsz=41.8, num_updates=600, lr=3.0094e-05, gnorm=0.001, clip=0, loss_scale=128, train_wall=71, gb_free=6.3, wall=16007]2024-04-28 22:23:23 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 22:23:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 021 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 021 | valid on 'dev' subset:  10% 1/10 [00:54<08:06, 54.00s/it]\u001b[A\n",
            "epoch 021 | valid on 'dev' subset:  20% 2/10 [01:54<07:41, 57.63s/it]\u001b[A\n",
            "epoch 021 | valid on 'dev' subset:  30% 3/10 [03:05<07:28, 64.06s/it]\u001b[A\n",
            "epoch 021 | valid on 'dev' subset:  40% 4/10 [04:17<06:43, 67.21s/it]\u001b[A\n",
            "epoch 021 | valid on 'dev' subset:  50% 5/10 [05:34<05:53, 70.74s/it]\u001b[A\n",
            "epoch 021 | valid on 'dev' subset:  60% 6/10 [07:02<05:06, 76.60s/it]\u001b[A\n",
            "epoch 021 | valid on 'dev' subset:  70% 7/10 [08:31<04:02, 80.68s/it]\u001b[A\n",
            "epoch 021 | valid on 'dev' subset:  80% 8/10 [10:08<02:51, 85.80s/it]\u001b[A\n",
            "epoch 021 | valid on 'dev' subset:  90% 9/10 [12:05<01:35, 95.47s/it]\u001b[A\n",
            "epoch 021 | valid on 'dev' subset: 100% 10/10 [12:47<00:00, 79.09s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 22:36:11 | INFO | dev | epoch 021 | valid on 'dev' subset | loss 27.017 | l1_loss 5.543 | mse_loss 21.441 | eos_loss 0.033 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 169.517 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 34.1 | wpb 2604.4 | bsz 14 | num_updates 609 | best_mcd_loss 169.517\n",
            "2024-04-28 22:36:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 609 updates\n",
            "2024-04-28 22:36:11 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint21.pt\n",
            "2024-04-28 22:36:13 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint21.pt\n",
            "2024-04-28 22:36:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint21.pt (epoch 21 @ 609 updates, score 169.517) (writing took 8.555414567999833 seconds)\n",
            "2024-04-28 22:36:20 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)\n",
            "2024-04-28 22:36:20 | INFO | train | epoch 021 | loss 14.099 | l1_loss 3.586 | mse_loss 10.482 | eos_loss 0.031 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 326.4 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 609 | lr 3.05439e-05 | gnorm 0.001 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.1 | wall 16792\n",
            "2024-04-28 22:36:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 22:36:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 022:   0% 0/29 [00:00<?, ?it/s]2024-04-28 22:36:20 | INFO | fairseq.trainer | begin training epoch 22\n",
            "2024-04-28 22:36:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 022:  97% 28/29 [00:29<00:01,  1.03s/it]2024-04-28 22:36:51 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 22:36:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 022 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 022 | valid on 'dev' subset:  10% 1/10 [00:55<08:23, 55.91s/it]\u001b[A\n",
            "epoch 022 | valid on 'dev' subset:  20% 2/10 [01:56<07:51, 58.92s/it]\u001b[A\n",
            "epoch 022 | valid on 'dev' subset:  30% 3/10 [03:08<07:31, 64.55s/it]\u001b[A\n",
            "epoch 022 | valid on 'dev' subset:  40% 4/10 [04:21<06:48, 68.13s/it]\u001b[A\n",
            "epoch 022 | valid on 'dev' subset:  50% 5/10 [05:42<06:02, 72.58s/it]\u001b[A\n",
            "epoch 022 | valid on 'dev' subset:  60% 6/10 [07:12<05:13, 78.42s/it]\u001b[A\n",
            "epoch 022 | valid on 'dev' subset:  70% 7/10 [08:45<04:09, 83.25s/it]\u001b[A\n",
            "epoch 022 | valid on 'dev' subset:  80% 8/10 [10:22<02:55, 87.66s/it]\u001b[A\n",
            "epoch 022 | valid on 'dev' subset:  90% 9/10 [12:18<01:36, 96.61s/it]\u001b[A\n",
            "epoch 022 | valid on 'dev' subset: 100% 10/10 [13:00<00:00, 79.77s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 22:49:52 | INFO | dev | epoch 022 | valid on 'dev' subset | loss 24.305 | l1_loss 5.196 | mse_loss 19.076 | eos_loss 0.034 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 153.85 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 33.6 | wpb 2604.4 | bsz 14 | num_updates 638 | best_mcd_loss 153.85\n",
            "2024-04-28 22:49:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 638 updates\n",
            "2024-04-28 22:49:52 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint22.pt\n",
            "2024-04-28 22:49:54 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint22.pt\n",
            "2024-04-28 22:49:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint22.pt (epoch 22 @ 638 updates, score 153.85) (writing took 7.281655213999329 seconds)\n",
            "2024-04-28 22:49:59 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)\n",
            "2024-04-28 22:49:59 | INFO | train | epoch 022 | loss 12.511 | l1_loss 3.33 | mse_loss 9.152 | eos_loss 0.03 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 321.4 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 638 | lr 3.19936e-05 | gnorm 0.001 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 5.6 | wall 17612\n",
            "2024-04-28 22:49:59 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 22:50:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 023:   0% 0/29 [00:00<?, ?it/s]2024-04-28 22:50:00 | INFO | fairseq.trainer | begin training epoch 23\n",
            "2024-04-28 22:50:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 023:  97% 28/29 [00:29<00:00,  1.04it/s]2024-04-28 22:50:30 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 22:50:30 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 023 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 023 | valid on 'dev' subset:  10% 1/10 [00:54<08:11, 54.62s/it]\u001b[A\n",
            "epoch 023 | valid on 'dev' subset:  20% 2/10 [01:54<07:43, 57.98s/it]\u001b[A\n",
            "epoch 023 | valid on 'dev' subset:  30% 3/10 [03:06<07:30, 64.33s/it]\u001b[A\n",
            "epoch 023 | valid on 'dev' subset:  40% 4/10 [04:21<06:49, 68.27s/it]\u001b[A\n",
            "epoch 023 | valid on 'dev' subset:  50% 5/10 [05:42<06:04, 72.94s/it]\u001b[A\n",
            "epoch 023 | valid on 'dev' subset:  60% 6/10 [07:10<05:12, 78.08s/it]\u001b[A\n",
            "epoch 023 | valid on 'dev' subset:  70% 7/10 [08:42<04:07, 82.66s/it]\u001b[A\n",
            "epoch 023 | valid on 'dev' subset:  80% 8/10 [10:21<02:56, 88.01s/it]\u001b[A\n",
            "epoch 023 | valid on 'dev' subset:  90% 9/10 [12:20<01:37, 97.60s/it]\u001b[A\n",
            "epoch 023 | valid on 'dev' subset: 100% 10/10 [13:02<00:00, 80.37s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 23:03:33 | INFO | dev | epoch 023 | valid on 'dev' subset | loss 13.936 | l1_loss 3.76 | mse_loss 10.143 | eos_loss 0.034 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 65.729 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 33.5 | wpb 2604.4 | bsz 14 | num_updates 667 | best_mcd_loss 65.729\n",
            "2024-04-28 23:03:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 667 updates\n",
            "2024-04-28 23:03:33 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint23.pt\n",
            "2024-04-28 23:03:35 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint23.pt\n",
            "2024-04-28 23:03:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint23.pt (epoch 23 @ 667 updates, score 65.729) (writing took 9.974915833998239 seconds)\n",
            "2024-04-28 23:03:43 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)\n",
            "2024-04-28 23:03:43 | INFO | train | epoch 023 | loss 11.262 | l1_loss 3.123 | mse_loss 8.108 | eos_loss 0.03 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 319.7 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 667 | lr 3.34433e-05 | gnorm 0.001 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.4 | wall 18435\n",
            "2024-04-28 23:03:43 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 23:03:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 024:   0% 0/29 [00:00<?, ?it/s]2024-04-28 23:03:43 | INFO | fairseq.trainer | begin training epoch 24\n",
            "2024-04-28 23:03:43 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 024:  97% 28/29 [00:30<00:01,  1.14s/it]2024-04-28 23:04:14 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 23:04:14 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 024 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 024 | valid on 'dev' subset:  10% 1/10 [00:56<08:27, 56.41s/it]\u001b[A\n",
            "epoch 024 | valid on 'dev' subset:  20% 2/10 [01:56<07:49, 58.66s/it]\u001b[A\n",
            "epoch 024 | valid on 'dev' subset:  30% 3/10 [03:06<07:25, 63.59s/it]\u001b[A\n",
            "epoch 024 | valid on 'dev' subset:  40% 4/10 [04:18<06:42, 67.11s/it]\u001b[A\n",
            "epoch 024 | valid on 'dev' subset:  50% 5/10 [05:36<05:55, 71.17s/it]\u001b[A\n",
            "epoch 024 | valid on 'dev' subset:  60% 6/10 [07:07<05:10, 77.63s/it]\u001b[A\n",
            "epoch 024 | valid on 'dev' subset:  70% 7/10 [08:40<04:08, 82.80s/it]\u001b[A\n",
            "epoch 024 | valid on 'dev' subset:  80% 8/10 [10:16<02:54, 87.07s/it]\u001b[A\n",
            "epoch 024 | valid on 'dev' subset:  90% 9/10 [12:15<01:36, 96.91s/it]\u001b[A\n",
            "epoch 024 | valid on 'dev' subset: 100% 10/10 [12:57<00:00, 80.04s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 23:17:12 | INFO | dev | epoch 024 | valid on 'dev' subset | loss 11.419 | l1_loss 3.246 | mse_loss 8.143 | eos_loss 0.032 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 46.764 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 33.8 | wpb 2604.4 | bsz 14 | num_updates 696 | best_mcd_loss 46.764\n",
            "2024-04-28 23:17:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 696 updates\n",
            "2024-04-28 23:17:12 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint24.pt\n",
            "2024-04-28 23:17:14 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint24.pt\n",
            "2024-04-28 23:17:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint24.pt (epoch 24 @ 696 updates, score 46.764) (writing took 7.120699174000038 seconds)\n",
            "2024-04-28 23:17:19 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)\n",
            "2024-04-28 23:17:19 | INFO | train | epoch 024 | loss 10.311 | l1_loss 2.96 | mse_loss 7.321 | eos_loss 0.029 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 322.6 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 696 | lr 3.4893e-05 | gnorm 0.001 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.9 | wall 19252\n",
            "2024-04-28 23:17:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 23:17:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 025:   0% 0/29 [00:00<?, ?it/s]2024-04-28 23:17:20 | INFO | fairseq.trainer | begin training epoch 25\n",
            "2024-04-28 23:17:20 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 025:  97% 28/29 [00:30<00:01,  1.04s/it, loss=11.509, l1_loss=3.162, mse_loss=8.317, eos_loss=0.03, attn_loss=0, ctc_loss=0, sample_size=9096.3, wps=279.8, ups=0.03, wpb=9096.3, bsz=42, num_updates=700, lr=3.5093e-05, gnorm=0.001, clip=0, loss_scale=128, train_wall=72, gb_free=6.2, wall=19257]2024-04-28 23:17:51 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 23:17:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 025 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 025 | valid on 'dev' subset:  10% 1/10 [00:54<08:11, 54.64s/it]\u001b[A\n",
            "epoch 025 | valid on 'dev' subset:  20% 2/10 [01:54<07:39, 57.49s/it]\u001b[A\n",
            "epoch 025 | valid on 'dev' subset:  30% 3/10 [03:03<07:21, 63.12s/it]\u001b[A\n",
            "epoch 025 | valid on 'dev' subset:  40% 4/10 [04:15<06:38, 66.48s/it]\u001b[A\n",
            "epoch 025 | valid on 'dev' subset:  50% 5/10 [05:33<05:53, 70.65s/it]\u001b[A\n",
            "epoch 025 | valid on 'dev' subset:  60% 6/10 [07:03<05:08, 77.09s/it]\u001b[A\n",
            "epoch 025 | valid on 'dev' subset:  70% 7/10 [08:37<04:08, 82.73s/it]\u001b[A\n",
            "epoch 025 | valid on 'dev' subset:  80% 8/10 [10:14<02:54, 87.27s/it]\u001b[A\n",
            "epoch 025 | valid on 'dev' subset:  90% 9/10 [12:11<01:36, 96.70s/it]\u001b[A\n",
            "epoch 025 | valid on 'dev' subset: 100% 10/10 [12:53<00:00, 79.59s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 23:30:44 | INFO | dev | epoch 025 | valid on 'dev' subset | loss 10.625 | l1_loss 3.104 | mse_loss 7.488 | eos_loss 0.033 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 45.689 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 33.9 | wpb 2604.4 | bsz 14 | num_updates 725 | best_mcd_loss 45.689\n",
            "2024-04-28 23:30:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 725 updates\n",
            "2024-04-28 23:30:44 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint25.pt\n",
            "2024-04-28 23:30:46 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint25.pt\n",
            "2024-04-28 23:30:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint25.pt (epoch 25 @ 725 updates, score 45.689) (writing took 7.662106186999154 seconds)\n",
            "2024-04-28 23:30:52 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)\n",
            "2024-04-28 23:30:52 | INFO | train | epoch 025 | loss 9.497 | l1_loss 2.815 | mse_loss 6.653 | eos_loss 0.029 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 324.1 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 725 | lr 3.63428e-05 | gnorm 0.001 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.1 | wall 20064\n",
            "2024-04-28 23:30:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 23:30:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 026:   0% 0/29 [00:00<?, ?it/s]2024-04-28 23:30:52 | INFO | fairseq.trainer | begin training epoch 26\n",
            "2024-04-28 23:30:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 026:  97% 28/29 [00:28<00:01,  1.02s/it]2024-04-28 23:31:22 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 23:31:22 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 026 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 026 | valid on 'dev' subset:  10% 1/10 [00:53<08:01, 53.45s/it]\u001b[A\n",
            "epoch 026 | valid on 'dev' subset:  20% 2/10 [01:53<07:40, 57.61s/it]\u001b[A\n",
            "epoch 026 | valid on 'dev' subset:  30% 3/10 [03:05<07:28, 64.07s/it]\u001b[A\n",
            "epoch 026 | valid on 'dev' subset:  40% 4/10 [04:20<06:49, 68.32s/it]\u001b[A\n",
            "epoch 026 | valid on 'dev' subset:  50% 5/10 [05:38<05:59, 71.96s/it]\u001b[A\n",
            "epoch 026 | valid on 'dev' subset:  60% 6/10 [07:08<05:11, 77.97s/it]\u001b[A\n",
            "epoch 026 | valid on 'dev' subset:  70% 7/10 [08:41<04:08, 82.94s/it]\u001b[A\n",
            "epoch 026 | valid on 'dev' subset:  80% 8/10 [10:21<02:56, 88.16s/it]\u001b[A\n",
            "epoch 026 | valid on 'dev' subset:  90% 9/10 [12:19<01:37, 97.60s/it]\u001b[A\n",
            "epoch 026 | valid on 'dev' subset: 100% 10/10 [13:01<00:00, 80.43s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 23:44:24 | INFO | dev | epoch 026 | valid on 'dev' subset | loss 7.885 | l1_loss 2.574 | mse_loss 5.276 | eos_loss 0.034 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 45.917 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 33.5 | wpb 2604.4 | bsz 14 | num_updates 754 | best_mcd_loss 45.689\n",
            "2024-04-28 23:44:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 754 updates\n",
            "2024-04-28 23:44:24 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint26.pt\n",
            "2024-04-28 23:44:25 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint26.pt\n",
            "2024-04-28 23:44:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint26.pt (epoch 26 @ 754 updates, score 45.917) (writing took 4.16504021199944 seconds)\n",
            "2024-04-28 23:44:28 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)\n",
            "2024-04-28 23:44:28 | INFO | train | epoch 026 | loss 8.322 | l1_loss 2.576 | mse_loss 5.716 | eos_loss 0.03 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 322.8 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 754 | lr 3.77925e-05 | gnorm 0.001 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 5.6 | wall 20880\n",
            "2024-04-28 23:44:28 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 23:44:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 027:   0% 0/29 [00:00<?, ?it/s]2024-04-28 23:44:28 | INFO | fairseq.trainer | begin training epoch 27\n",
            "2024-04-28 23:44:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 027:  97% 28/29 [00:30<00:01,  1.13s/it]2024-04-28 23:44:59 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 23:44:59 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 027 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 027 | valid on 'dev' subset:  10% 1/10 [00:56<08:32, 56.93s/it]\u001b[A\n",
            "epoch 027 | valid on 'dev' subset:  20% 2/10 [02:00<08:04, 60.59s/it]\u001b[A\n",
            "epoch 027 | valid on 'dev' subset:  30% 3/10 [03:12<07:41, 65.87s/it]\u001b[A\n",
            "epoch 027 | valid on 'dev' subset:  40% 4/10 [04:26<06:55, 69.23s/it]\u001b[A\n",
            "epoch 027 | valid on 'dev' subset:  50% 5/10 [05:46<06:05, 73.08s/it]\u001b[A\n",
            "epoch 027 | valid on 'dev' subset:  60% 6/10 [07:13<05:11, 77.92s/it]\u001b[A\n",
            "epoch 027 | valid on 'dev' subset:  70% 7/10 [08:45<04:07, 82.42s/it]\u001b[A\n",
            "epoch 027 | valid on 'dev' subset:  80% 8/10 [10:24<02:55, 87.63s/it]\u001b[A\n",
            "epoch 027 | valid on 'dev' subset:  90% 9/10 [12:18<01:35, 95.93s/it]\u001b[A\n",
            "epoch 027 | valid on 'dev' subset: 100% 10/10 [12:58<00:00, 78.74s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-28 23:57:58 | INFO | dev | epoch 027 | valid on 'dev' subset | loss 7.683 | l1_loss 2.536 | mse_loss 5.113 | eos_loss 0.035 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 45.461 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 33.8 | wpb 2604.4 | bsz 14 | num_updates 783 | best_mcd_loss 45.461\n",
            "2024-04-28 23:57:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 783 updates\n",
            "2024-04-28 23:57:58 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint27.pt\n",
            "2024-04-28 23:58:00 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint27.pt\n",
            "2024-04-28 23:58:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint27.pt (epoch 27 @ 783 updates, score 45.461) (writing took 8.117558269997971 seconds)\n",
            "2024-04-28 23:58:06 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)\n",
            "2024-04-28 23:58:06 | INFO | train | epoch 027 | loss 7.442 | l1_loss 2.402 | mse_loss 5.01 | eos_loss 0.03 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 321.8 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 783 | lr 3.92422e-05 | gnorm 0.001 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.7 | wall 21699\n",
            "2024-04-28 23:58:06 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-28 23:58:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 028:   0% 0/29 [00:00<?, ?it/s]2024-04-28 23:58:07 | INFO | fairseq.trainer | begin training epoch 28\n",
            "2024-04-28 23:58:07 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 028:  97% 28/29 [00:28<00:01,  1.02s/it, loss=8.102, l1_loss=2.532, mse_loss=5.54, eos_loss=0.03, attn_loss=0, ctc_loss=0, sample_size=9135.14, wps=371.4, ups=0.04, wpb=9135.1, bsz=42.2, num_updates=800, lr=4.0092e-05, gnorm=0.001, clip=0, loss_scale=128, train_wall=72, gb_free=6.4, wall=21717]2024-04-28 23:58:36 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-28 23:58:36 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 028 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 028 | valid on 'dev' subset:  10% 1/10 [00:52<07:50, 52.29s/it]\u001b[A\n",
            "epoch 028 | valid on 'dev' subset:  20% 2/10 [01:51<07:33, 56.64s/it]\u001b[A\n",
            "epoch 028 | valid on 'dev' subset:  30% 3/10 [03:00<07:13, 61.93s/it]\u001b[A\n",
            "epoch 028 | valid on 'dev' subset:  40% 4/10 [04:10<06:32, 65.43s/it]\u001b[A\n",
            "epoch 028 | valid on 'dev' subset:  50% 5/10 [05:28<05:48, 69.65s/it]\u001b[A\n",
            "epoch 028 | valid on 'dev' subset:  60% 6/10 [06:56<05:03, 75.98s/it]\u001b[A\n",
            "epoch 028 | valid on 'dev' subset:  70% 7/10 [08:27<04:02, 80.84s/it]\u001b[A\n",
            "epoch 028 | valid on 'dev' subset:  80% 8/10 [10:04<02:52, 86.17s/it]\u001b[A\n",
            "epoch 028 | valid on 'dev' subset:  90% 9/10 [12:03<01:36, 96.29s/it]\u001b[A\n",
            "epoch 028 | valid on 'dev' subset: 100% 10/10 [12:45<00:00, 79.55s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-29 00:11:21 | INFO | dev | epoch 028 | valid on 'dev' subset | loss 7.45 | l1_loss 2.543 | mse_loss 4.873 | eos_loss 0.034 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 54.111 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 34.2 | wpb 2604.4 | bsz 14 | num_updates 812 | best_mcd_loss 45.461\n",
            "2024-04-29 00:11:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 812 updates\n",
            "2024-04-29 00:11:21 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint28.pt\n",
            "2024-04-29 00:11:23 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint28.pt\n",
            "2024-04-29 00:11:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint28.pt (epoch 28 @ 812 updates, score 54.111) (writing took 3.595808643996861 seconds)\n",
            "2024-04-29 00:11:25 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)\n",
            "2024-04-29 00:11:25 | INFO | train | epoch 028 | loss 6.883 | l1_loss 2.293 | mse_loss 4.559 | eos_loss 0.03 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 329.7 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 812 | lr 4.06919e-05 | gnorm 0.001 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.1 | wall 22498\n",
            "2024-04-29 00:11:25 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-29 00:11:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 029:   0% 0/29 [00:00<?, ?it/s]2024-04-29 00:11:25 | INFO | fairseq.trainer | begin training epoch 29\n",
            "2024-04-29 00:11:25 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 029:  97% 28/29 [00:29<00:00,  1.18it/s]2024-04-29 00:11:56 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-29 00:11:56 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 029 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 029 | valid on 'dev' subset:  10% 1/10 [00:53<07:59, 53.24s/it]\u001b[A\n",
            "epoch 029 | valid on 'dev' subset:  20% 2/10 [01:51<07:30, 56.35s/it]\u001b[A\n",
            "epoch 029 | valid on 'dev' subset:  30% 3/10 [03:02<07:19, 62.82s/it]\u001b[A\n",
            "epoch 029 | valid on 'dev' subset:  40% 4/10 [04:14<06:39, 66.51s/it]\u001b[A\n",
            "epoch 029 | valid on 'dev' subset:  50% 5/10 [05:33<05:54, 70.90s/it]\u001b[A\n",
            "epoch 029 | valid on 'dev' subset:  60% 6/10 [07:00<05:06, 76.65s/it]\u001b[A\n",
            "epoch 029 | valid on 'dev' subset:  70% 7/10 [08:31<04:03, 81.32s/it]\u001b[A\n",
            "epoch 029 | valid on 'dev' subset:  80% 8/10 [10:10<02:53, 86.87s/it]\u001b[A\n",
            "epoch 029 | valid on 'dev' subset:  90% 9/10 [12:11<01:37, 97.57s/it]\u001b[A\n",
            "epoch 029 | valid on 'dev' subset: 100% 10/10 [12:55<00:00, 80.97s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-29 00:24:52 | INFO | dev | epoch 029 | valid on 'dev' subset | loss 6.268 | l1_loss 2.248 | mse_loss 3.986 | eos_loss 0.034 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 56.462 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 33.7 | wpb 2604.4 | bsz 14 | num_updates 841 | best_mcd_loss 45.461\n",
            "2024-04-29 00:24:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 841 updates\n",
            "2024-04-29 00:24:52 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint29.pt\n",
            "2024-04-29 00:24:53 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint29.pt\n",
            "2024-04-29 00:24:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint29.pt (epoch 29 @ 841 updates, score 56.462) (writing took 3.5921903099988413 seconds)\n",
            "2024-04-29 00:24:55 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)\n",
            "2024-04-29 00:24:55 | INFO | train | epoch 029 | loss 6.462 | l1_loss 2.212 | mse_loss 4.22 | eos_loss 0.03 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 325.1 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 841 | lr 4.21416e-05 | gnorm 0.002 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.4 | wall 23308\n",
            "2024-04-29 00:24:55 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-29 00:24:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 030:   0% 0/29 [00:00<?, ?it/s]2024-04-29 00:24:56 | INFO | fairseq.trainer | begin training epoch 30\n",
            "2024-04-29 00:24:56 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 030:  97% 28/29 [00:30<00:01,  1.16s/it]2024-04-29 00:25:27 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-29 00:25:27 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 030 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 030 | valid on 'dev' subset:  10% 1/10 [00:53<08:05, 53.98s/it]\u001b[A\n",
            "epoch 030 | valid on 'dev' subset:  20% 2/10 [01:54<07:41, 57.66s/it]\u001b[A\n",
            "epoch 030 | valid on 'dev' subset:  30% 3/10 [03:05<07:27, 64.00s/it]\u001b[A\n",
            "epoch 030 | valid on 'dev' subset:  40% 4/10 [04:19<06:45, 67.66s/it]\u001b[A\n",
            "epoch 030 | valid on 'dev' subset:  50% 5/10 [05:37<05:58, 71.70s/it]\u001b[A\n",
            "epoch 030 | valid on 'dev' subset:  60% 6/10 [07:07<05:11, 77.85s/it]\u001b[A\n",
            "epoch 030 | valid on 'dev' subset:  70% 7/10 [08:39<04:07, 82.55s/it]\u001b[A\n",
            "epoch 030 | valid on 'dev' subset:  80% 8/10 [10:19<02:56, 88.04s/it]\u001b[A\n",
            "epoch 030 | valid on 'dev' subset:  90% 9/10 [12:16<01:37, 97.18s/it]\u001b[A\n",
            "epoch 030 | valid on 'dev' subset: 100% 10/10 [12:57<00:00, 79.76s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-29 00:38:25 | INFO | dev | epoch 030 | valid on 'dev' subset | loss 8.691 | l1_loss 2.803 | mse_loss 5.852 | eos_loss 0.034 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 59.907 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 33.7 | wpb 2604.4 | bsz 14 | num_updates 870 | best_mcd_loss 45.461\n",
            "2024-04-29 00:38:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 870 updates\n",
            "2024-04-29 00:38:25 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint30.pt\n",
            "2024-04-29 00:38:27 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint30.pt\n",
            "2024-04-29 00:38:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint30.pt (epoch 30 @ 870 updates, score 59.907) (writing took 3.6782608069988783 seconds)\n",
            "2024-04-29 00:38:28 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)\n",
            "2024-04-29 00:38:28 | INFO | train | epoch 030 | loss 6.139 | l1_loss 2.15 | mse_loss 3.96 | eos_loss 0.03 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 323.8 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 870 | lr 4.35913e-05 | gnorm 0.001 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.3 | wall 24121\n",
            "2024-04-29 00:38:28 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-29 00:38:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 031:   0% 0/29 [00:00<?, ?it/s]2024-04-29 00:38:29 | INFO | fairseq.trainer | begin training epoch 31\n",
            "2024-04-29 00:38:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 031:  97% 28/29 [00:28<00:01,  1.00s/it]2024-04-29 00:38:58 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-29 00:38:58 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 031 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 031 | valid on 'dev' subset:  10% 1/10 [00:53<07:58, 53.17s/it]\u001b[A\n",
            "epoch 031 | valid on 'dev' subset:  20% 2/10 [01:53<07:37, 57.13s/it]\u001b[A\n",
            "epoch 031 | valid on 'dev' subset:  30% 3/10 [03:02<07:17, 62.55s/it]\u001b[A\n",
            "epoch 031 | valid on 'dev' subset:  40% 4/10 [04:14<06:38, 66.45s/it]\u001b[A\n",
            "epoch 031 | valid on 'dev' subset:  50% 5/10 [05:34<05:56, 71.36s/it]\u001b[A\n",
            "epoch 031 | valid on 'dev' subset:  60% 6/10 [07:01<05:06, 76.54s/it]\u001b[A\n",
            "epoch 031 | valid on 'dev' subset:  70% 7/10 [08:29<04:01, 80.52s/it]\u001b[A\n",
            "epoch 031 | valid on 'dev' subset:  80% 8/10 [10:05<02:50, 85.17s/it]\u001b[A\n",
            "epoch 031 | valid on 'dev' subset:  90% 9/10 [11:59<01:34, 94.21s/it]\u001b[A\n",
            "epoch 031 | valid on 'dev' subset: 100% 10/10 [12:39<00:00, 77.56s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-29 00:51:38 | INFO | dev | epoch 031 | valid on 'dev' subset | loss 6.147 | l1_loss 2.209 | mse_loss 3.905 | eos_loss 0.034 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 58.414 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 34.5 | wpb 2604.4 | bsz 14 | num_updates 899 | best_mcd_loss 45.461\n",
            "2024-04-29 00:51:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 899 updates\n",
            "2024-04-29 00:51:38 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint31.pt\n",
            "2024-04-29 00:51:40 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint31.pt\n",
            "2024-04-29 00:51:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint31.pt (epoch 31 @ 899 updates, score 58.414) (writing took 3.6808413800026756 seconds)\n",
            "2024-04-29 00:51:42 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)\n",
            "2024-04-29 00:51:42 | INFO | train | epoch 031 | loss 5.941 | l1_loss 2.111 | mse_loss 3.801 | eos_loss 0.029 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 332.1 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 899 | lr 4.5041e-05 | gnorm 0.002 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 4.5 | wall 24914\n",
            "2024-04-29 00:51:42 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-29 00:51:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 032:   0% 0/29 [00:00<?, ?it/s]2024-04-29 00:51:42 | INFO | fairseq.trainer | begin training epoch 32\n",
            "2024-04-29 00:51:42 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 032:  97% 28/29 [00:28<00:00,  1.01it/s, loss=6.244, l1_loss=2.171, mse_loss=4.043, eos_loss=0.03, attn_loss=0, ctc_loss=0, sample_size=9019.58, wps=281.9, ups=0.03, wpb=9019.6, bsz=41.5, num_updates=900, lr=4.5091e-05, gnorm=0.002, clip=0, loss_scale=128, train_wall=72, gb_free=6.2, wall=24916]2024-04-29 00:52:11 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-29 00:52:11 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 032 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 032 | valid on 'dev' subset:  10% 1/10 [00:52<07:54, 52.71s/it]\u001b[A\n",
            "epoch 032 | valid on 'dev' subset:  20% 2/10 [01:50<07:25, 55.67s/it]\u001b[A\n",
            "epoch 032 | valid on 'dev' subset:  30% 3/10 [03:00<07:14, 62.13s/it]\u001b[A\n",
            "epoch 032 | valid on 'dev' subset:  40% 4/10 [04:12<06:35, 65.94s/it]\u001b[A\n",
            "epoch 032 | valid on 'dev' subset:  50% 5/10 [05:29<05:50, 70.11s/it]\u001b[A\n",
            "epoch 032 | valid on 'dev' subset:  60% 6/10 [06:57<05:04, 76.01s/it]\u001b[A\n",
            "epoch 032 | valid on 'dev' subset:  70% 7/10 [08:28<04:03, 81.12s/it]\u001b[A\n",
            "epoch 032 | valid on 'dev' subset:  80% 8/10 [10:05<02:52, 86.10s/it]\u001b[A\n",
            "epoch 032 | valid on 'dev' subset:  90% 9/10 [12:01<01:35, 95.54s/it]\u001b[A\n",
            "epoch 032 | valid on 'dev' subset: 100% 10/10 [12:44<00:00, 79.22s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-29 01:04:56 | INFO | dev | epoch 032 | valid on 'dev' subset | loss 5.71 | l1_loss 2.132 | mse_loss 3.544 | eos_loss 0.034 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 69.054 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 34.3 | wpb 2604.4 | bsz 14 | num_updates 928 | best_mcd_loss 45.461\n",
            "2024-04-29 01:04:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 928 updates\n",
            "2024-04-29 01:04:56 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint32.pt\n",
            "2024-04-29 01:04:57 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint32.pt\n",
            "2024-04-29 01:05:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint32.pt (epoch 32 @ 928 updates, score 69.054) (writing took 8.832889167002577 seconds)\n",
            "2024-04-29 01:05:04 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)\n",
            "2024-04-29 01:05:04 | INFO | train | epoch 032 | loss 5.829 | l1_loss 2.092 | mse_loss 3.708 | eos_loss 0.029 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 328.1 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 928 | lr 4.64907e-05 | gnorm 0.002 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6 | wall 25717\n",
            "2024-04-29 01:05:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-29 01:05:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 033:   0% 0/29 [00:00<?, ?it/s]2024-04-29 01:05:05 | INFO | fairseq.trainer | begin training epoch 33\n",
            "2024-04-29 01:05:05 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 033:  97% 28/29 [00:30<00:01,  1.15s/it]2024-04-29 01:05:36 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-29 01:05:36 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 033 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 033 | valid on 'dev' subset:  10% 1/10 [00:53<08:05, 53.99s/it]\u001b[A\n",
            "epoch 033 | valid on 'dev' subset:  20% 2/10 [01:52<07:35, 56.91s/it]\u001b[A\n",
            "epoch 033 | valid on 'dev' subset:  30% 3/10 [03:03<07:23, 63.32s/it]\u001b[A\n",
            "epoch 033 | valid on 'dev' subset:  40% 4/10 [04:16<06:42, 67.05s/it]\u001b[A\n",
            "epoch 033 | valid on 'dev' subset:  50% 5/10 [05:36<05:58, 71.71s/it]\u001b[A\n",
            "epoch 033 | valid on 'dev' subset:  60% 6/10 [07:05<05:10, 77.60s/it]\u001b[A\n",
            "epoch 033 | valid on 'dev' subset:  70% 7/10 [08:34<04:03, 81.32s/it]\u001b[A\n",
            "epoch 033 | valid on 'dev' subset:  80% 8/10 [10:11<02:52, 86.20s/it]\u001b[A\n",
            "epoch 033 | valid on 'dev' subset:  90% 9/10 [12:05<01:35, 95.00s/it]\u001b[A\n",
            "epoch 033 | valid on 'dev' subset: 100% 10/10 [12:45<00:00, 78.08s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-29 01:18:22 | INFO | dev | epoch 033 | valid on 'dev' subset | loss 5.649 | l1_loss 2.097 | mse_loss 3.52 | eos_loss 0.033 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 68.25 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 34.2 | wpb 2604.4 | bsz 14 | num_updates 957 | best_mcd_loss 45.461\n",
            "2024-04-29 01:18:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 957 updates\n",
            "2024-04-29 01:18:22 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint33.pt\n",
            "2024-04-29 01:18:24 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint33.pt\n",
            "2024-04-29 01:18:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint33.pt (epoch 33 @ 957 updates, score 68.25) (writing took 3.704136574000586 seconds)\n",
            "2024-04-29 01:18:25 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)\n",
            "2024-04-29 01:18:25 | INFO | train | epoch 033 | loss 5.7 | l1_loss 2.062 | mse_loss 3.608 | eos_loss 0.029 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 328.8 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 957 | lr 4.79404e-05 | gnorm 0.003 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.7 | wall 26518\n",
            "2024-04-29 01:18:25 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-29 01:18:26 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 034:   0% 0/29 [00:00<?, ?it/s]2024-04-29 01:18:26 | INFO | fairseq.trainer | begin training epoch 34\n",
            "2024-04-29 01:18:26 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 034:  97% 28/29 [00:27<00:00,  1.03it/s]2024-04-29 01:18:55 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-29 01:18:55 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 034 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 034 | valid on 'dev' subset:  10% 1/10 [00:52<07:53, 52.63s/it]\u001b[A\n",
            "epoch 034 | valid on 'dev' subset:  20% 2/10 [01:52<07:37, 57.14s/it]\u001b[A\n",
            "epoch 034 | valid on 'dev' subset:  30% 3/10 [03:03<07:23, 63.34s/it]\u001b[A\n",
            "epoch 034 | valid on 'dev' subset:  40% 4/10 [04:15<06:39, 66.50s/it]\u001b[A\n",
            "epoch 034 | valid on 'dev' subset:  50% 5/10 [05:32<05:52, 70.46s/it]\u001b[A\n",
            "epoch 034 | valid on 'dev' subset:  60% 6/10 [07:01<05:06, 76.67s/it]\u001b[A\n",
            "epoch 034 | valid on 'dev' subset:  70% 7/10 [08:31<04:03, 81.18s/it]\u001b[A\n",
            "epoch 034 | valid on 'dev' subset:  80% 8/10 [10:09<02:52, 86.43s/it]\u001b[A\n",
            "epoch 034 | valid on 'dev' subset:  90% 9/10 [12:07<01:36, 96.43s/it]\u001b[A\n",
            "epoch 034 | valid on 'dev' subset: 100% 10/10 [12:50<00:00, 79.93s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-29 01:31:46 | INFO | dev | epoch 034 | valid on 'dev' subset | loss 6.018 | l1_loss 2.208 | mse_loss 3.777 | eos_loss 0.033 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 81.931 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 33.9 | wpb 2604.4 | bsz 14 | num_updates 986 | best_mcd_loss 45.461\n",
            "2024-04-29 01:31:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 986 updates\n",
            "2024-04-29 01:31:46 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint34.pt\n",
            "2024-04-29 01:31:48 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint34.pt\n",
            "2024-04-29 01:31:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint34.pt (epoch 34 @ 986 updates, score 81.931) (writing took 5.8963479719968745 seconds)\n",
            "2024-04-29 01:31:52 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)\n",
            "2024-04-29 01:31:52 | INFO | train | epoch 034 | loss 5.675 | l1_loss 2.06 | mse_loss 3.586 | eos_loss 0.029 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 326.7 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 986 | lr 4.93901e-05 | gnorm 0.003 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.4 | wall 27324\n",
            "2024-04-29 01:31:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-29 01:31:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 035:   0% 0/29 [00:00<?, ?it/s]2024-04-29 01:31:52 | INFO | fairseq.trainer | begin training epoch 35\n",
            "2024-04-29 01:31:52 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 035:  97% 28/29 [00:28<00:00,  1.05it/s, loss=5.719, l1_loss=2.068, mse_loss=3.621, eos_loss=0.029, attn_loss=0, ctc_loss=0, sample_size=9157.95, wps=377.9, ups=0.04, wpb=9158, bsz=42.5, num_updates=1000, lr=5.009e-05, gnorm=0.002, clip=0, loss_scale=128, train_wall=72, gb_free=6, wall=27340]2024-04-29 01:32:22 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-29 01:32:22 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 035 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 035 | valid on 'dev' subset:  10% 1/10 [00:52<07:52, 52.52s/it]\u001b[A\n",
            "epoch 035 | valid on 'dev' subset:  20% 2/10 [01:50<07:27, 55.96s/it]\u001b[A\n",
            "epoch 035 | valid on 'dev' subset:  30% 3/10 [03:01<07:18, 62.63s/it]\u001b[A\n",
            "epoch 035 | valid on 'dev' subset:  40% 4/10 [04:13<06:38, 66.43s/it]\u001b[A\n",
            "epoch 035 | valid on 'dev' subset:  50% 5/10 [05:33<05:55, 71.15s/it]\u001b[A\n",
            "epoch 035 | valid on 'dev' subset:  60% 6/10 [07:02<05:09, 77.47s/it]\u001b[A\n",
            "epoch 035 | valid on 'dev' subset:  70% 7/10 [08:34<04:06, 82.05s/it]\u001b[A\n",
            "epoch 035 | valid on 'dev' subset:  80% 8/10 [10:12<02:54, 87.26s/it]\u001b[A\n",
            "epoch 035 | valid on 'dev' subset:  90% 9/10 [12:10<01:36, 96.77s/it]\u001b[A\n",
            "epoch 035 | valid on 'dev' subset: 100% 10/10 [12:52<00:00, 79.96s/it]\u001b[A\n",
            "                                                                      \u001b[A2024-04-29 01:45:15 | INFO | dev | epoch 035 | valid on 'dev' subset | loss 5.694 | l1_loss 2.125 | mse_loss 3.537 | eos_loss 0.033 | attn_loss 0 | ctc_loss 0 | sample_size 2604.4 | mcd_loss 89.473 | pred_ratio 16.134 | ins_rate 10.555 | del_rate -4.579 | wps 33.8 | wpb 2604.4 | bsz 14 | num_updates 1015 | best_mcd_loss 45.461\n",
            "2024-04-29 01:45:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 1015 updates\n",
            "2024-04-29 01:45:15 | INFO | fairseq.trainer | Saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint35.pt\n",
            "2024-04-29 01:45:17 | INFO | fairseq.trainer | Finished saving checkpoint to /content/SAVE_DIR_TRAINING/checkpoint35.pt\n",
            "2024-04-29 01:45:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/SAVE_DIR_TRAINING/checkpoint35.pt (epoch 35 @ 1015 updates, score 89.473) (writing took 3.587527478000993 seconds)\n",
            "2024-04-29 01:45:19 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)\n",
            "2024-04-29 01:45:19 | INFO | train | epoch 035 | loss 5.54 | l1_loss 2.027 | mse_loss 3.484 | eos_loss 0.029 | attn_loss 0 | ctc_loss 0 | sample_size 9081.62 | wps 326.4 | ups 0.04 | wpb 9081.6 | bsz 41.9 | num_updates 1015 | lr 5.08399e-05 | gnorm 0.002 | clip 0 | loss_scale 128 | train_wall 21 | gb_free 6.4 | wall 28131\n",
            "2024-04-29 01:45:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "2024-04-29 01:45:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 29\n",
            "epoch 036:   0% 0/29 [00:00<?, ?it/s]2024-04-29 01:45:19 | INFO | fairseq.trainer | begin training epoch 36\n",
            "2024-04-29 01:45:19 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 036:  97% 28/29 [00:29<00:01,  1.04s/it]2024-04-29 01:45:49 | INFO | fairseq_cli.train | begin validation on \"dev\" subset\n",
            "2024-04-29 01:45:49 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True\n",
            "\n",
            "epoch 036 | valid on 'dev' subset:   0% 0/10 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 036 | valid on 'dev' subset:  10% 1/10 [00:54<08:06, 54.09s/it]\u001b[AException ignored in: <generator object tqdm.__iter__ at 0x7e861d6468f0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1196, in __iter__\n",
            "    self.close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 1275, in close\n",
            "    self._decr_instances(self)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 696, in _decr_instances\n",
            "    with cls._lock:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 111, in __enter__\n",
            "    self.acquire()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tqdm/std.py\", line 104, in acquire\n",
            "    lock.acquire(*a, **k)\n",
            "KeyboardInterrupt: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-train\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 574, in cli_main\n",
            "    distributed_utils.call_main(cfg, main)\n",
            "  File \"/content/fairseq/fairseq/distributed/utils.py\", line 404, in call_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 205, in main\n",
            "    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 345, in train\n",
            "    valid_losses, should_stop = validate_and_save(\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 436, in validate_and_save\n",
            "    valid_losses = validate(cfg, trainer, task, epoch_itr, valid_subsets)\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 522, in validate\n",
            "    trainer.valid_step(sample)\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 1152, in valid_step\n",
            "    _loss, sample_size, logging_output = self.task.valid_step(\n",
            "  File \"/content/fairseq/fairseq/tasks/speech_to_speech.py\", line 516, in valid_step\n",
            "    hypos, inference_losses = self.valid_step_with_inference(\n",
            "  File \"/content/fairseq/fairseq/tasks/speech_to_speech.py\", line 547, in valid_step_with_inference\n",
            "    [hypo] for hypo in generator.generate(model, sample, has_targ=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/speech_generator.py\", line 73, in generate\n",
            "    _, cur_eos_out, cur_extra = model.forward_decoder(\n",
            "  File \"/content/fairseq/fairseq/models/fairseq_model.py\", line 334, in forward_decoder\n",
            "    return self.decoder(prev_output_tokens, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/models/text_to_speech/tts_transformer.py\", line 271, in forward\n",
            "    x, extra = self.extract_features(\n",
            "  File \"/content/fairseq/fairseq/models/text_to_speech/tts_transformer.py\", line 228, in extract_features\n",
            "    x, layer_attn, _ = transformer_layer(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/modules/transformer_layer.py\", line 504, in forward\n",
            "    x = self.final_layer_norm(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/normalization.py\", line 201, in forward\n",
            "    return F.layer_norm(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 2546, in layer_norm\n",
            "    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/backends/__init__.py\", line 36, in __get__\n",
            "    def __get__(self, obj, objtype):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# training\n",
        "!cd /content/fairseq && fairseq-train /content/DATA_ROOT  --config-yaml config.yaml --task speech_to_speech --n-frames-per-step 5 --criterion speech_to_spectrogram --arch s2spect_transformer --decoder-normalize-before --dropout 0.1 --attention-dropout 0.1 --relu-dropout 0.1 --train-subset train --valid-subset dev --save-dir /content/SAVE_DIR_TRAINING --eval-inference --best-checkpoint-metric mcd_loss --lr 0.0005 --lr-scheduler inverse_sqrt --warmup-init-lr 1e-7 --warmup-updates 10000 --optimizer adam --adam-betas \"(0.9,0.98)\" --clip-norm 10.0 --weight-decay 1e-6 --max-update 400000 --max-tokens 80000 --max-tokens-valid 30000  --required-batch-size-multiple 1 --max-target-positions 3000 --update-freq 1 --seed 1 --fp16 --num-workers 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-CbLHPwyQn0",
        "outputId": "33d32064-dff0-4496-b677-c792b5be8f29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2024-04-29 02:09:32.426186: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-29 02:09:32.426248: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-29 02:09:32.427675: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-29 02:09:32.435241: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-29 02:09:33.510255: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX\n",
            "INFO:__main__:Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', simul_type=None, scoring='bleu', task='speech_to_speech', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, path='/content/SAVE_DIR_TRAINING/checkpoint34.pt', post_process=None, quiet=False, model_overrides='{}', results_path='/content/RESULT_PATH_3', eos_prob_threshold=0.5, dump_features=False, dump_waveforms=True, dump_attentions=False, dump_eos_probs=False, dump_plots=False, dump_target=False, output_sample_rate=16000, teacher_forcing=False, audio_format='wav', data='/content/DATA_ROOT', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, target_is_code=False, target_code_size=None, n_frames_per_step=5, eval_inference=False, eval_args='{}', mcd_normalize_type='targ', vocoder='griffin_lim', spec_bwd_max_iter=8, infer_target_lang='', force_anneal=None, lr_shrink=0.1, warmup_updates=0, pad=1, eos=2, unk=3, no_seed_provided=False)\n",
            "WARNING:fairseq.data.audio.data_cfg:Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.\n",
            "INFO:fairseq.data.audio.speech_to_text_dataset:SpeechToSpeechDataset(split=\"test\", n_samples=292, prepend_tgt_lang_tag=False, n_frames_per_step=5, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(\n",
            "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
            "    DeltaDeltas\n",
            "), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
            "))\n",
            "INFO:fairseq.data.audio.speech_to_speech_dataset:SpeechToSpeechDataset(split=\"test\", n_samples=292, prepend_tgt_lang_tag=False, n_frames_per_step=5, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(\n",
            "    UtteranceCMVN(norm_means=True, norm_vars=True)\n",
            "    DeltaDeltas\n",
            "), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(\n",
            "))\n",
            "INFO:__main__:resampling to 16000Hz\n",
            "INFO:fairseq.tasks.fairseq_task:can_reuse_epoch_itr = True\n",
            "INFO:fairseq.tasks.fairseq_task:reuse_dataloader = True\n",
            "INFO:fairseq.tasks.fairseq_task:rebuild_batches = False\n",
            "INFO:fairseq.tasks.fairseq_task:creating new batches for epoch 1\n",
            "  0% 0/14 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        }
      ],
      "source": [
        "# assume using a default Griffin-Lim vocoder\n",
        "\n",
        "!cd /content/fairseq && python examples/speech_synthesis/generate_waveform.py /content/DATA_ROOT  --config-yaml config.yaml --task speech_to_speech --n-frames-per-step 5 --path /content/SAVE_DIR_TRAINING/checkpoint34.pt  --gen-subset test --max-tokens 50000 --results-path /content/RESULT_PATH_3 --dump-waveforms --output-sample-rate 16000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfCXac_1OJPY"
      },
      "outputs": [],
      "source": [
        "# /usr/local/lib/python3.10/dist-packages/omegaconf-2.0.6.dist-info/METADATA\n",
        "/content/fairseq/examples/speech_to_speech/preprocessing/prep_s2spect_data.py line 157 80 to 230"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw1q2nss8ZpA"
      },
      "source": [
        "this seems to be an issue with the pyyaml and omegaconf\n",
        "https://github.com/omry/omegaconf/issues/758"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
